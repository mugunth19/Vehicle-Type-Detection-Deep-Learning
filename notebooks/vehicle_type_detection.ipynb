{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7hFrSbfDQ-7S",
        "outputId": "44323c52-06e1-43b8-f025-eace9e482860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-22 09:04:22--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/r7bthvstxw-2.zip\n",
            "Resolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 3.5.71.77, 3.5.71.230, 3.5.70.82, ...\n",
            "Connecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|3.5.71.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41450910 (40M) [application/zip]\n",
            "Saving to: ‘r7bthvstxw-2.zip’\n",
            "\n",
            "r7bthvstxw-2.zip    100%[===================>]  39.53M  11.0MB/s    in 3.6s    \n",
            "\n",
            "2025-12-22 09:04:26 (11.0 MB/s) - ‘r7bthvstxw-2.zip’ saved [41450910/41450910]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/r7bthvstxw-2.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip r7bthvstxw-2.zip  && mv r7bthvstxw-2 vehicle-type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4jzW0xBdRqoS",
        "outputId": "f70ef6ed-8289-4f25-f3a7-6cbd1db4e17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  r7bthvstxw-2.zip\n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_157.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_141.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_166.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_163.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_161.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_112.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_18.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_25.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_2.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_42.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_100.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_38.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_74.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_154.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_22.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_101.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_149.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_36.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_49.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_129.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_50.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_114.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_30.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_98.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_116.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_16.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_180.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_33.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_133.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_80.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_47.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_91.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_164.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_79.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_6.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_72.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_110.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_94.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_95.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_26.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_174.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_125.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_55.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_179.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_103.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_93.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_90.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_170.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_97.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_51.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_134.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_83.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_14.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_34.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_39.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_13.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_41.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_155.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_176.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_126.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_70.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_108.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_63.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_53.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_162.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_81.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_17.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_85.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_167.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_68.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_52.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_92.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_156.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_23.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_118.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_4.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_107.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_29.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_124.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_15.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_88.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_139.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_21.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_69.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_150.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_71.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_171.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_113.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_77.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_151.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_45.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_20.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_56.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_99.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_127.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_0.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_61.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_76.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_3.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_44.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_35.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_54.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_152.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_7.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_106.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_168.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_121.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_123.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_73.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_84.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_31.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_147.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_173.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_57.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_138.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_46.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_178.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_172.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_12.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_169.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_115.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_175.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_109.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_37.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_160.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_87.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_135.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_137.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_82.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_143.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_140.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_48.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_11.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_142.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_27.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_32.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_132.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_144.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_89.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_10.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_130.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_120.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_122.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_136.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_165.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_66.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_128.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_86.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_1.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_40.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_119.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_67.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_111.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_64.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_96.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_104.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_24.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_43.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_148.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_58.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_159.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_19.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_158.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_60.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_153.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_177.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_75.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_145.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_5.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_59.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_146.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_131.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_78.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_8.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_65.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_102.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_28.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_62.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_9.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_117.jpg  \n",
            "  inflating: r7bthvstxw-2/hatchback/PIC_105.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_25.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_112.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_2.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_18.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_141.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_157.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_22.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_42.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_38.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_101.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_74.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_154.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_149.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_49.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_50.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_129.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_36.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_98.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_114.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_80.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_30.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_116.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_6.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_91.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_79.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_55.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_125.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_26.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_72.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_93.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_97.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_134.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_103.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_83.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_39.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_155.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_34.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_41.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_126.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_63.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_108.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_81.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_156.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_70.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_118.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_68.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_23.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_107.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_139.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_124.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_4.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_88.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_69.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_71.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_150.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_21.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_151.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_113.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_45.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_20.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_56.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_127.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_76.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_61.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_0.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_3.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_54.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_7.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_44.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_106.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_73.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_152.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_46.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_147.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_123.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_121.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_84.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_100.JPG  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_31.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_12.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_115.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_37.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_109.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_87.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_135.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_143.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_137.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_142.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_48.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_27.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_132.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_144.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_10.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_89.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_120.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_136.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_130.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_86.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_67.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_64.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_119.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_159.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_58.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_158.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_104.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_24.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_96.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_60.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_148.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_19.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_153.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_5.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_145.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_8.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_78.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_65.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_75.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_102.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_146.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_62.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_105.jpg  \n",
            "  inflating: r7bthvstxw-2/motorcycle/PIC_28.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_25.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_161.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_323.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_186.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_112.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_431.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_2.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_163.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_18.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_443.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_354.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_223.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_460.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_374.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_141.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_453.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_455.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_207.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_269.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_282.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_166.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_355.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_419.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_361.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_352.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_157.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_42.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_270.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_472.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_336.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_271.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_372.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_436.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_100.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_188.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_204.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_360.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_198.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_301.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_375.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_22.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_38.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_101.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_224.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_154.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_74.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_370.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_330.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_447.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_416.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_377.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_149.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_313.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_293.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_328.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_412.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_49.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_36.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_129.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_50.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_98.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_114.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_181.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_30.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_386.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_222.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_303.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_116.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_325.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_322.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_210.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_16.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_241.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_180.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_326.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_451.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_368.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_47.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_33.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_193.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_435.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_133.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_80.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_415.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_91.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_208.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_392.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_200.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_390.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_164.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_6.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_430.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_243.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_457.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_72.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_79.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_408.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_110.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_471.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_94.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_319.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_95.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_346.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_347.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_444.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_298.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_292.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_342.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_379.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_26.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_468.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_233.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_369.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_394.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_442.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_348.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_249.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_247.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_456.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_184.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_363.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_174.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_316.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_311.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_125.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_55.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_179.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_365.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_391.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_90.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_402.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_225.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_310.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_97.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_103.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_308.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_256.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_476.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_250.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_371.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_383.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_93.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_215.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_51.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_236.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_170.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_134.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_190.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_317.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_331.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_426.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_473.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_203.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_262.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_445.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_83.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_34.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_176.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_287.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_267.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_39.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_14.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_235.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_155.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_70.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_108.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_126.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_332.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_446.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_411.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_399.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_41.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_253.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_167.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_477.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_63.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_53.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_162.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_362.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_366.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_85.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_13.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_295.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_68.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_294.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_52.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_409.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_281.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_17.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_92.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_81.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_405.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_156.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_437.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_118.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_423.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_356.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_334.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_23.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_107.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_312.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_307.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_29.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_196.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_475.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_139.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_216.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_4.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_398.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_466.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_373.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_219.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_299.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_424.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_341.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_15.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_88.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_320.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_191.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_21.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_124.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_329.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_397.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_230.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_69.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_150.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_151.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_194.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_171.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_388.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_71.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_404.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_56.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_321.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_278.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_77.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_45.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_113.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_407.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_20.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_187.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_450.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_454.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_277.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_99.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_127.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_251.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_76.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_288.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_440.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_61.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_381.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_221.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_261.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_0.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_3.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_382.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_54.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_268.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_231.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_44.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_237.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_192.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_283.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_7.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_279.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_258.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_290.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_285.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_35.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_168.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_263.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_152.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_73.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_396.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_406.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_421.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_106.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_376.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_123.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_458.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_121.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_461.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_217.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_351.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_338.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_84.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_275.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_173.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_147.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_344.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_403.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_138.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_242.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_57.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_31.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_229.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_274.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_359.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_350.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_46.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_343.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_178.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_452.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_264.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_259.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_227.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_12.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_172.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_260.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_296.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_169.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_115.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_441.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_448.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_240.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_175.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_286.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_272.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_109.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_206.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_433.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_339.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_291.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_37.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_469.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_160.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_140.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_462.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_135.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_474.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_137.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_213.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_82.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_246.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_87.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_418.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_11.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_387.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_143.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_201.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_309.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_142.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_27.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_209.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_327.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_48.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_302.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_384.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_413.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_32.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_197.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_306.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_254.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_318.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_432.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_132.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_144.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_10.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_89.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_182.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_304.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_252.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_465.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_120.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_130.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_226.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_427.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_165.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_136.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_122.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_463.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_185.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_305.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_66.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_1.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_353.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_128.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_86.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_400.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_395.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_202.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_40.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_111.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_67.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_358.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_211.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_349.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_393.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_239.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_64.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_410.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_280.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_96.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_119.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_245.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_104.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_24.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_276.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_314.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_214.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_58.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_43.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_389.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_333.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_148.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_248.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_159.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_414.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_335.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_266.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_265.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_367.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_60.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_220.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_297.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_158.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_19.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_177.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_153.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_5.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_420.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_75.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_401.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_378.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_273.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_459.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_340.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_189.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_59.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_422.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_218.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_255.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_145.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_212.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_232.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_449.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_78.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_131.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_195.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_146.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_199.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_315.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_284.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_8.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_205.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_65.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_228.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_428.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_300.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_183.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_234.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_244.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_467.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_102.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_238.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_380.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_439.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_417.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_425.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_345.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_464.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_28.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_324.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_385.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_470.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_429.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_289.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_337.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_364.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_357.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_434.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_62.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_257.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_117.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_9.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_438.jpg  \n",
            "  inflating: r7bthvstxw-2/pickup/PIC_105.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_323.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_25.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_161.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_186.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_112.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_2.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_18.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_354.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_141.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_269.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_355.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_223.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_374.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_207.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_282.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_166.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_352.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_271.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_270.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_336.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_361.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_157.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_42.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_372.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_301.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_375.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_100.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_204.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_360.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_198.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_38.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_188.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_22.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_154.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_330.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_224.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_101.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_370.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_293.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_313.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_377.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_74.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_114.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_49.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_181.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_129.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_149.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_50.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_36.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_98.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_328.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_163.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_322.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_325.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_210.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_386.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_30.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_116.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_222.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_16.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_303.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_326.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_241.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_180.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_368.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_33.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_47.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_133.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_193.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_208.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_91.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_80.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_392.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_200.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_164.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_390.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_6.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_110.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_79.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_72.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_243.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_94.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_319.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_95.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_347.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_292.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_346.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_342.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_26.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_379.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_298.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_233.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_369.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_394.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_348.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_249.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_184.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_125.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_247.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_174.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_363.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_316.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_311.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_55.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_179.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_225.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_391.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_310.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_365.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_90.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_250.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_371.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_383.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_103.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_93.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_308.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_215.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_256.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_236.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_97.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_170.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_134.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_190.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_51.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_317.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_331.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_34.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_203.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_39.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_262.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_14.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_83.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_267.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_41.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_176.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_287.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_155.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_332.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_126.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_235.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_70.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_108.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_362.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_366.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_13.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_85.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_253.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_162.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_399.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_167.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_63.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_53.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_295.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_294.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_281.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_81.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_68.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_312.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_356.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_17.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_92.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_52.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_334.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_307.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_156.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_23.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_216.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_118.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_107.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_373.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_398.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_4.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_196.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_29.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_219.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_139.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_299.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_88.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_191.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_329.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_15.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_320.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_124.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_21.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_341.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_230.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_171.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_150.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_71.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_113.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_194.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_69.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_151.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_388.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_397.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_77.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_20.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_56.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_321.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_45.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_278.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_187.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_99.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_277.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_251.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_127.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_76.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_288.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_381.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_221.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_261.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_61.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_0.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_3.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_382.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_231.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_54.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_237.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_192.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_268.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_290.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_44.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_279.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_283.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_258.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_35.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_285.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_376.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_7.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_152.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_396.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_106.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_263.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_123.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_73.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_168.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_173.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_84.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_121.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_217.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_351.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_344.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_275.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_147.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_338.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_31.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_57.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_242.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_138.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_350.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_359.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_274.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_46.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_178.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_229.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_343.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_264.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_172.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_227.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_12.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_259.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_260.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_296.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_169.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_115.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_175.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_240.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_272.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_286.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_206.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_339.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_109.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_160.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_291.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_37.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_140.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_135.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_246.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_213.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_87.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_387.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_143.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_48.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_309.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_137.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_201.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_82.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_327.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_209.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_27.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_11.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_142.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_384.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_302.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_32.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_197.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_144.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_306.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_89.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_10.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_130.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_254.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_318.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_304.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_182.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_132.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_120.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_252.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_226.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_122.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_165.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_136.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_353.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_66.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_185.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_305.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_1.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_128.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_86.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_40.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_395.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_202.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_211.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_67.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_111.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_358.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_349.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_393.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_239.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_64.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_119.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_280.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_96.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_104.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_245.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_276.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_24.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_314.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_43.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_214.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_333.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_148.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_248.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_389.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_58.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_265.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_159.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_158.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_60.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_266.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_367.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_335.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_297.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_220.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_19.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_177.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_153.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_5.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_273.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_378.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_75.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_340.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_145.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_189.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_59.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_255.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_232.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_212.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_218.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_78.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_315.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_195.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_131.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_199.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_284.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_8.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_205.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_146.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_228.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_300.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_244.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_183.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_65.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_234.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_102.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_238.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_345.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_380.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_28.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_324.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_385.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_337.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_289.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_364.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_62.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_357.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_257.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_117.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_105.jpg  \n",
            "  inflating: r7bthvstxw-2/sedan/PIC_9.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_25.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_112.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_2.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_18.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_42.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_100.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_22.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_74.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_49.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_101.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_50.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_38.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_36.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_30.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_114.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_98.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_16.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_116.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_80.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_79.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_72.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_33.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_110.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_91.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_95.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_94.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_6.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_90.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_125.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_55.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_103.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_26.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_93.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_47.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_97.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_51.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_34.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_39.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_83.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_14.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_41.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_70.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_53.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_85.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_63.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_13.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_81.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_17.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_126.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_68.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_52.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_108.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_23.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_118.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_92.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_107.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_88.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_15.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_4.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_29.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_124.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_21.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_113.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_71.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_20.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_45.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_56.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_77.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_127.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_99.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_69.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_76.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_61.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_3.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_0.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_54.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_44.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_35.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_7.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_123.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_106.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_73.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_121.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_84.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_31.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_57.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_46.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_115.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_109.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_12.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_37.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_87.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_48.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_82.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_11.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_27.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_32.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_10.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_122.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_89.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_120.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_1.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_86.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_66.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_128.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_67.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_40.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_64.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_111.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_96.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_24.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_104.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_119.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_43.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_60.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_19.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_58.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_5.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_75.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_59.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_8.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_78.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_102.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_65.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_28.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_117.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_62.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_9.jpg  \n",
            "  inflating: r7bthvstxw-2/suv/PIC_105.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "jeNl7rx7RyJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q_UIE7F3R2jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "58_fgC4ifAen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img= Image.open('vehicle-type/sedan/PIC_0.jpg')\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "AWbznMkwSY5e",
        "outputId": "ff38868c-3fb8-4e62-c022-00866a3b8f0e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=196x155>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(img.resize((224, 224))) # all images in the dataset by default 244 * 244"
      ],
      "metadata": {
        "id": "JZFIclrKSsP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using pre-trained imagemnet model for training as the dataset is very small\n",
        "model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oLKQtViIS2P7",
        "outputId": "f6f313a7-87c5-4c1b-8b0e-c67ff3b04fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 214MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    #transforms.Resize(256),\n",
        "    #transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    #imagenet normalization\n",
        "])"
      ],
      "metadata": {
        "id": "jPgttvl5TIlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = preprocess(img)\n",
        "\n",
        "batch_t = torch.unsqueeze(x, 0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(batch_t)\n",
        "\n",
        "_, indices = torch.sort(output, descending=True)"
      ],
      "metadata": {
        "id": "qjpSfsMyAjCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt -O imagenet_classes.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iUI23F8XAwNz",
        "outputId": "db54111a-e270-483f-e3ff-4aeefc9263c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-22 09:04:37--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-22 09:04:37 (98.8 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "\n",
        "# Get top 5 predictions\n",
        "top5_indices = indices[0, :5].tolist()\n",
        "top5_classes = [categories[i] for i in top5_indices]\n",
        "\n",
        "print(\"Top 5 predictions:\")\n",
        "for i, class_name in enumerate(top5_classes):\n",
        "    print(f\"{i+1}: {class_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMA2OexvA2Vo",
        "outputId": "6a454f36-2e8f-4aed-9626-e381c5928404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 predictions:\n",
            "1: minivan\n",
            "2: sports car\n",
            "3: racer\n",
            "4: amphibian\n",
            "5: bullet train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Configuration ---\n",
        "# Set this to the path where your dataset folders (Sedan, Pickup, etc.) are located\n",
        "DATA_DIR = './vehicle-type/'\n",
        "\n",
        "# --- Data Collection ---\n",
        "class_counts = {}\n",
        "total_samples = 0\n",
        "\n",
        "# Loop through all items in the main data directory\n",
        "for class_name in os.listdir(DATA_DIR):\n",
        "    class_path = os.path.join(DATA_DIR, class_name)\n",
        "\n",
        "    # Check if the item is a directory (i.e., a class folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        # Count the number of files (images) in that directory\n",
        "        count = len(os.listdir(class_path))\n",
        "        class_counts[class_name] = count\n",
        "        total_samples += count\n",
        "\n",
        "# --- Data Preparation for Plotting ---\n",
        "class_names = list(class_counts.keys())\n",
        "counts = list(class_counts.values())\n",
        "\n",
        "# Sort the classes by their counts (optional, but helpful for visual clarity)\n",
        "sorted_classes = sorted(class_counts.items(), key=lambda item: item[1], reverse=True)\n",
        "class_names = [item[0] for item in sorted_classes]\n",
        "counts = [item[1] for item in sorted_classes]\n",
        "\n",
        "# --- Visualization (Bar Chart) ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(class_names, counts, color=['skyblue', 'salmon', 'lightgreen', 'gold', 'lightcoral'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(f'Vehicle Dataset Class Distribution (Total Samples: {total_samples})', fontsize=16)\n",
        "plt.xlabel('Vehicle Class', fontsize=12)\n",
        "plt.ylabel('Number of Samples', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right') # Rotate class names for readability\n",
        "\n",
        "# Add the count on top of each bar\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 10, yval, ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout() # Adjust layout to prevent labels from being cut off\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "4CgOHXnGBVT5",
        "outputId": "a4656c15-3427-41bc-efb2-73e1777171c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMBALANCE IN DATA**\n",
        "## As per the above analysis, both the pickup and sedan class samples are high compared to other classes and there is an imbalance. In order to rectify this, we need to use **weighted cross-entropy loss function**"
      ],
      "metadata": {
        "id": "cxrssBCt1evQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# Define a custom Dataset class for loading vehicle images\n",
        "class VehicleDataset(Dataset):\n",
        "    # Initialize the dataset\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir  # Root directory containing class folders\n",
        "        self.transform = transform  # Transformations to apply to images (e.g., resizing, normalization)\n",
        "        self.image_paths = []     # List to store full paths to all images\n",
        "        self.labels = []          # List to store integer labels corresponding to each image\n",
        "\n",
        "        # Get class names from subdirectories and sort them for consistent indexing\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        # Create a mapping from class name (string) to integer index\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        # Populate image_paths and labels lists\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)  # Path to the current class's directory\n",
        "            # Iterate through all image files in the class directory\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))  # Add image path\n",
        "                self.labels.append(self.class_to_idx[label_name])           # Add corresponding integer label\n",
        "\n",
        "    # Return the total number of samples in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    # Return a single sample (image and its label) given an index\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]  # Get the path of the image at the given index\n",
        "        image = Image.open(img_path).convert('RGB')  # Open and convert image to RGB format\n",
        "        label = self.labels[idx]          # Get the label for the image\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "8ObmBCDW2QSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HYPER-PARAMETER TUNING**\n",
        "\n",
        "Let's try with multiple Learning rate to see which one is good."
      ],
      "metadata": {
        "id": "gis-XQUzqTrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 224\n",
        "\n",
        "# ImageNet normalization values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Simple transforms - just resize and normalize\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    #transforms.RandomRotation(10),           # Rotate up to 10 degrees\n",
        "    #transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),  # Zoom\n",
        "    #transforms.RandomHorizontalFlip(),       # Horizontal flip\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "7RxUYTRJ2-nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL0nbhSltZQy",
        "outputId": "081e93ff-5bad-4dff-c304-ad58a2396e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "# Path to your current unsplit folder\n",
        "input_folder = 'vehicle-type'\n",
        "\n",
        "# Split with a ratio: 80% Train, 10% Val, 10% Test\n",
        "# Seed ensures the split is reproducible every time you run it\n",
        "splitfolders.ratio(input_folder, output=\"vehicle_data_split\",\n",
        "                   seed=1337, ratio=(.8, .1, .1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBTK0wUku1TK",
        "outputId": "b3862ba0-6d42-45ea-a622-2920c9638b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 1310 files [00:00, 6788.15 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = VehicleDataset(\n",
        "    data_dir='./vehicle_data_split/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "val_dataset = VehicleDataset(\n",
        "    data_dir='./vehicle_data_split/val',\n",
        "    transform=val_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "BB3i62lo1VAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VehicleClassifierModel(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(VehicleClassifierModel, self).__init__()\n",
        "\n",
        "        # Load pre-trained MobileNetV2\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.output_layer = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "KIu72rN7vtqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = VehicleClassifierModel(num_classes=5)\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "Se2LZQnTxUsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Path to your main training directory\n",
        "DATA_DIR = 'vehicle-type'\n",
        "\n",
        "# Dynamically get counts from folders\n",
        "class_names = sorted(os.listdir(DATA_DIR))\n",
        "counts = [len(os.listdir(os.path.join(DATA_DIR, c))) for c in class_names]\n",
        "\n",
        "total = sum(counts)\n",
        "num_classes = len(counts)\n",
        "\n",
        "# Calculate weights: Total / (num_classes * class_count)\n",
        "weights = [total / (num_classes * c) for c in counts]\n",
        "\n",
        "# Convert to a FloatTensor for PyTorch\n",
        "class_weights = torch.FloatTensor(weights)\n",
        "\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Counts: {counts}\")\n",
        "print(f\"Calculated Weights: {weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfAEn6BWy5hD",
        "outputId": "57ad55a9-a548-4f5c-9266-036815232468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['hatchback', 'motorcycle', 'pickup', 'sedan', 'suv']\n",
            "Counts: [181, 122, 478, 400, 129]\n",
            "Calculated Weights: [1.4475138121546962, 2.1475409836065573, 0.5481171548117155, 0.655, 2.0310077519379846]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Define the loss function with your calculated weights\n",
        "# If you are using a GPU, make sure the weights are on the same device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pPdO6WhFxb25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over the training data\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to the specified device (GPU or CPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients to prevent accumulation\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate training loss\n",
        "        running_loss += loss.item()\n",
        "        # Get predictions\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # Update total and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average training loss and accuracy\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    # Disable gradient calculation for validation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the validation data\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move data to the specified device (GPU or CPU)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Accumulate validation loss\n",
        "            val_loss += loss.item()\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # Update total and correct predictions\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "    print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkdHoIkY0mGT",
        "outputId": "0c102605-3862-45f0-8dac-62e097135e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  Train Loss: 1.8593, Train Acc: 0.4474\n",
            "  Val Loss: 0.7743, Val Acc: 0.8062\n",
            "Epoch 2/10\n",
            "  Train Loss: 0.4622, Train Acc: 0.8260\n",
            "  Val Loss: 0.3593, Val Acc: 0.8760\n",
            "Epoch 3/10\n",
            "  Train Loss: 0.3407, Train Acc: 0.8738\n",
            "  Val Loss: 0.3269, Val Acc: 0.8140\n",
            "Epoch 4/10\n",
            "  Train Loss: 0.2911, Train Acc: 0.8815\n",
            "  Val Loss: 0.3821, Val Acc: 0.8527\n",
            "Epoch 5/10\n",
            "  Train Loss: 0.3192, Train Acc: 0.8700\n",
            "  Val Loss: 0.2499, Val Acc: 0.8605\n",
            "Epoch 6/10\n",
            "  Train Loss: 0.2725, Train Acc: 0.9034\n",
            "  Val Loss: 0.3087, Val Acc: 0.8527\n",
            "Epoch 7/10\n",
            "  Train Loss: 0.2085, Train Acc: 0.9149\n",
            "  Val Loss: 0.2819, Val Acc: 0.8527\n",
            "Epoch 8/10\n",
            "  Train Loss: 0.2790, Train Acc: 0.8881\n",
            "  Val Loss: 0.8453, Val Acc: 0.7442\n",
            "Epoch 9/10\n",
            "  Train Loss: 0.2531, Train Acc: 0.8891\n",
            "  Val Loss: 0.3017, Val Acc: 0.9147\n",
            "Epoch 10/10\n",
            "  Train Loss: 0.3400, Train Acc: 0.8910\n",
            "  Val Loss: 0.5252, Val Acc: 0.7829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def  train_and_val(model, optimizer, train_loader, val_loader, criterion, num_epochs, device) :\n",
        "  # Training loop\n",
        "  num_epochs =  10\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      # Training phase\n",
        "      model.train()  # Set the model to training mode\n",
        "      running_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      # Iterate over the training data\n",
        "      for inputs, labels in train_loader:\n",
        "          # Move data to the specified device (GPU or CPU)\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # Zero the parameter gradients to prevent accumulation\n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          outputs = model(inputs)\n",
        "          # Calculate the loss\n",
        "          loss = criterion(outputs, labels)\n",
        "          # Backward pass and optimize\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Accumulate training loss\n",
        "          running_loss += loss.item()\n",
        "          # Get predictions\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          # Update total and correct predictions\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # Calculate average training loss and accuracy\n",
        "      train_loss = running_loss / len(train_loader)\n",
        "      train_acc = correct / total\n",
        "\n",
        "      # Validation phase\n",
        "      model.eval()  # Set the model to evaluation mode\n",
        "      val_loss = 0.0\n",
        "      val_correct = 0\n",
        "      val_total = 0\n",
        "\n",
        "      # Disable gradient calculation for validation\n",
        "      with torch.no_grad():\n",
        "          # Iterate over the validation data\n",
        "          for inputs, labels in val_loader:\n",
        "              # Move data to the specified device (GPU or CPU)\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              # Forward pass\n",
        "              outputs = model(inputs)\n",
        "              # Calculate the loss\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              # Accumulate validation loss\n",
        "              val_loss += loss.item()\n",
        "              # Get predictions\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              # Update total and correct predictions\n",
        "              val_total += labels.size(0)\n",
        "              val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # Calculate average validation loss and accuracy\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc = val_correct / val_total\n",
        "\n",
        "      # Print epoch results\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "      print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "      print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')"
      ],
      "metadata": {
        "id": "FVumiExe7Kuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(learning_rate=0.01, class_weights=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = VehicleClassifierModel(num_classes=5)\n",
        "    model.to(device) # Move the model to the correct device\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # 1. Define the loss function with your calculated weights\n",
        "    # If you are using a GPU, make sure the weights are on the same device\n",
        "    if class_weights is not None:\n",
        "      class_weights = class_weights.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    return model, optimizer, criterion"
      ],
      "metadata": {
        "id": "iOk0gtvFRub9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in [0.001, 0.01, 0.1, 0.1]:\n",
        "  print(\"learning rate =\", lr)\n",
        "  model, optimizer, criterion = make_model(learning_rate=lr, class_weights=class_weights)\n",
        "  train_and_val(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8J6KpJqSv0_",
        "outputId": "e5609be5-40f8-4e89-b278-2c07d0f6cb17",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning rate = 0.001\n",
            "Epoch 1/10\n",
            "  Train Loss: 1.2038, Train Acc: 0.5382\n",
            "  Val Loss: 0.9562, Val Acc: 0.7674\n",
            "Epoch 2/10\n",
            "  Train Loss: 0.7443, Train Acc: 0.7820\n",
            "  Val Loss: 0.7818, Val Acc: 0.7519\n",
            "Epoch 3/10\n",
            "  Train Loss: 0.6043, Train Acc: 0.8231\n",
            "  Val Loss: 0.5801, Val Acc: 0.8140\n",
            "Epoch 4/10\n",
            "  Train Loss: 0.5196, Train Acc: 0.8423\n",
            "  Val Loss: 0.6209, Val Acc: 0.8217\n",
            "Epoch 5/10\n",
            "  Train Loss: 0.4676, Train Acc: 0.8585\n",
            "  Val Loss: 0.5584, Val Acc: 0.7674\n",
            "Epoch 6/10\n",
            "  Train Loss: 0.4293, Train Acc: 0.8738\n",
            "  Val Loss: 0.4505, Val Acc: 0.8527\n",
            "Epoch 7/10\n",
            "  Train Loss: 0.3903, Train Acc: 0.8853\n",
            "  Val Loss: 0.4603, Val Acc: 0.7597\n",
            "Epoch 8/10\n",
            "  Train Loss: 0.3529, Train Acc: 0.8987\n",
            "  Val Loss: 0.4008, Val Acc: 0.8682\n",
            "Epoch 9/10\n",
            "  Train Loss: 0.3354, Train Acc: 0.8996\n",
            "  Val Loss: 0.4026, Val Acc: 0.8372\n",
            "Epoch 10/10\n",
            "  Train Loss: 0.3080, Train Acc: 0.9130\n",
            "  Val Loss: 0.3694, Val Acc: 0.8605\n",
            "learning rate = 0.01\n",
            "Epoch 1/10\n",
            "  Train Loss: 1.9424, Train Acc: 0.4799\n",
            "  Val Loss: 0.8617, Val Acc: 0.7519\n",
            "Epoch 2/10\n",
            "  Train Loss: 0.5990, Train Acc: 0.7533\n",
            "  Val Loss: 0.6792, Val Acc: 0.8372\n",
            "Epoch 3/10\n",
            "  Train Loss: 0.4080, Train Acc: 0.8432\n",
            "  Val Loss: 0.7664, Val Acc: 0.6899\n",
            "Epoch 4/10\n",
            "  Train Loss: 0.3595, Train Acc: 0.8442\n",
            "  Val Loss: 0.4023, Val Acc: 0.8605\n",
            "Epoch 5/10\n",
            "  Train Loss: 0.2700, Train Acc: 0.9034\n",
            "  Val Loss: 0.3009, Val Acc: 0.8682\n",
            "Epoch 6/10\n",
            "  Train Loss: 0.2346, Train Acc: 0.8987\n",
            "  Val Loss: 0.4925, Val Acc: 0.8605\n",
            "Epoch 7/10\n",
            "  Train Loss: 0.2263, Train Acc: 0.9034\n",
            "  Val Loss: 0.3874, Val Acc: 0.8527\n",
            "Epoch 8/10\n",
            "  Train Loss: 0.2160, Train Acc: 0.9159\n",
            "  Val Loss: 0.3808, Val Acc: 0.8140\n",
            "Epoch 9/10\n",
            "  Train Loss: 0.2013, Train Acc: 0.9130\n",
            "  Val Loss: 0.2469, Val Acc: 0.9380\n",
            "Epoch 10/10\n",
            "  Train Loss: 0.2303, Train Acc: 0.9130\n",
            "  Val Loss: 0.2946, Val Acc: 0.8992\n",
            "learning rate = 0.1\n",
            "Epoch 1/10\n",
            "  Train Loss: 11.8447, Train Acc: 0.5373\n",
            "  Val Loss: 2.2887, Val Acc: 0.7752\n",
            "Epoch 2/10\n",
            "  Train Loss: 2.0003, Train Acc: 0.8107\n",
            "  Val Loss: 5.3298, Val Acc: 0.8527\n",
            "Epoch 3/10\n",
            "  Train Loss: 2.2889, Train Acc: 0.8059\n",
            "  Val Loss: 2.8401, Val Acc: 0.6589\n",
            "Epoch 4/10\n",
            "  Train Loss: 2.8032, Train Acc: 0.7973\n",
            "  Val Loss: 1.4208, Val Acc: 0.8915\n",
            "Epoch 5/10\n",
            "  Train Loss: 1.5940, Train Acc: 0.8690\n",
            "  Val Loss: 3.5724, Val Acc: 0.8450\n",
            "Epoch 6/10\n",
            "  Train Loss: 3.7965, Train Acc: 0.7868\n",
            "  Val Loss: 4.2145, Val Acc: 0.7907\n",
            "Epoch 7/10\n",
            "  Train Loss: 2.3366, Train Acc: 0.8279\n",
            "  Val Loss: 2.7457, Val Acc: 0.8915\n",
            "Epoch 8/10\n",
            "  Train Loss: 2.2763, Train Acc: 0.8423\n",
            "  Val Loss: 2.0297, Val Acc: 0.8760\n",
            "Epoch 9/10\n",
            "  Train Loss: 1.2588, Train Acc: 0.9044\n",
            "  Val Loss: 2.0817, Val Acc: 0.8760\n",
            "Epoch 10/10\n",
            "  Train Loss: 1.7230, Train Acc: 0.8872\n",
            "  Val Loss: 7.6934, Val Acc: 0.6899\n",
            "learning rate = 0.1\n",
            "Epoch 1/10\n",
            "  Train Loss: 12.4529, Train Acc: 0.5258\n",
            "  Val Loss: 3.4356, Val Acc: 0.7907\n",
            "Epoch 2/10\n",
            "  Train Loss: 2.6102, Train Acc: 0.8069\n",
            "  Val Loss: 1.8646, Val Acc: 0.7907\n",
            "Epoch 3/10\n",
            "  Train Loss: 1.9136, Train Acc: 0.7964\n",
            "  Val Loss: 1.0054, Val Acc: 0.8605\n",
            "Epoch 4/10\n",
            "  Train Loss: 2.4073, Train Acc: 0.8117\n",
            "  Val Loss: 2.1561, Val Acc: 0.8760\n",
            "Epoch 5/10\n",
            "  Train Loss: 1.2384, Train Acc: 0.8709\n",
            "  Val Loss: 2.0636, Val Acc: 0.8527\n",
            "Epoch 6/10\n",
            "  Train Loss: 0.9531, Train Acc: 0.8901\n",
            "  Val Loss: 2.7114, Val Acc: 0.8295\n",
            "Epoch 7/10\n",
            "  Train Loss: 1.6490, Train Acc: 0.8681\n",
            "  Val Loss: 1.5748, Val Acc: 0.8372\n",
            "Epoch 8/10\n",
            "  Train Loss: 2.7978, Train Acc: 0.8308\n",
            "  Val Loss: 1.6857, Val Acc: 0.8605\n",
            "Epoch 9/10\n",
            "  Train Loss: 2.5539, Train Acc: 0.8423\n",
            "  Val Loss: 2.7518, Val Acc: 0.8372\n",
            "Epoch 10/10\n",
            "  Train Loss: 1.5976, Train Acc: 0.8939\n",
            "  Val Loss: 2.9005, Val Acc: 0.7674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the hyper-parameter tuning, we could see the learning rate 0.01 is giving a very good accuracy amoung the tested learning rate.It gives **Train Acc: 0.9130 & Val Acc: 0.9380** . We can choose** 0.01** as our Learning rate for this model\n",
        "\n",
        "Let's experiment with inner layer size."
      ],
      "metadata": {
        "id": "GGu8FBJgWbzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VehicleClassifierModel(nn.Module):\n",
        "    def __init__(self, num_classes=5,size_inner=100):\n",
        "        super(VehicleClassifierModel, self).__init__()\n",
        "\n",
        "        # Load pre-trained MobileNetV2\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.inner = nn.Linear(1280, size_inner)  # New inner layer\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.inner(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iBg2O74UWzR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(learning_rate=0.01, class_weights=None,size_inner=100):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = VehicleClassifierModel(num_classes=5, size_inner=size_inner)\n",
        "    model.to(device) # Move the model to the correct device\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # 1. Define the loss function with your calculated weights\n",
        "    # If you are using a GPU, make sure the weights are on the same device\n",
        "    if class_weights is not None:\n",
        "      class_weights = class_weights.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    return model, optimizer, criterion"
      ],
      "metadata": {
        "id": "0IFDC1L_cH_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for size in [100,250,500,750,1000]:\n",
        "  print(\"Inner layer size =\", size)\n",
        "  model, optimizer, criterion = make_model(size, class_weights=class_weights)\n",
        "  train_and_val(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx2Hb3QUch5T",
        "outputId": "c070df44-33a1-49f4-867c-7269f43aabbc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner layer size = 100\n",
            "Epoch 1/10\n",
            "  Train Loss: 24722324.1699, Train Acc: 0.2075\n",
            "  Val Loss: 35.4266, Val Acc: 0.0930\n",
            "Epoch 2/10\n",
            "  Train Loss: 4902.1927, Train Acc: 0.2151\n",
            "  Val Loss: 25.4957, Val Acc: 0.0930\n",
            "Epoch 3/10\n",
            "  Train Loss: 27.9412, Train Acc: 0.1855\n",
            "  Val Loss: 28.2842, Val Acc: 0.3643\n",
            "Epoch 4/10\n",
            "  Train Loss: 2124.7040, Train Acc: 0.1960\n",
            "  Val Loss: 17.5210, Val Acc: 0.0930\n",
            "Epoch 5/10\n",
            "  Train Loss: 35.6926, Train Acc: 0.2008\n",
            "  Val Loss: 52.4089, Val Acc: 0.1395\n",
            "Epoch 6/10\n",
            "  Train Loss: 40.2599, Train Acc: 0.1912\n",
            "  Val Loss: 28.0231, Val Acc: 0.0930\n",
            "Epoch 7/10\n",
            "  Train Loss: 35.0727, Train Acc: 0.2122\n",
            "  Val Loss: 43.1886, Val Acc: 0.3643\n",
            "Epoch 8/10\n",
            "  Train Loss: 38.6565, Train Acc: 0.2161\n",
            "  Val Loss: 49.0287, Val Acc: 0.3643\n",
            "Epoch 9/10\n",
            "  Train Loss: 34.7292, Train Acc: 0.2333\n",
            "  Val Loss: 32.6903, Val Acc: 0.0930\n",
            "Epoch 10/10\n",
            "  Train Loss: 30.7387, Train Acc: 0.2075\n",
            "  Val Loss: 23.9536, Val Acc: 0.3101\n",
            "Inner layer size = 250\n",
            "Epoch 1/10\n",
            "  Train Loss: 128460590.2306, Train Acc: 0.2103\n",
            "  Val Loss: 138.3075, Val Acc: 0.3101\n",
            "Epoch 2/10\n",
            "  Train Loss: 1388582.5694, Train Acc: 0.1979\n",
            "  Val Loss: 117.6540, Val Acc: 0.0930\n",
            "Epoch 3/10\n",
            "  Train Loss: 975025.9496, Train Acc: 0.1797\n",
            "  Val Loss: 79.3740, Val Acc: 0.0930\n",
            "Epoch 4/10\n",
            "  Train Loss: 88.8181, Train Acc: 0.2027\n",
            "  Val Loss: 114.4049, Val Acc: 0.0930\n",
            "Epoch 5/10\n",
            "  Train Loss: 95.6534, Train Acc: 0.2151\n",
            "  Val Loss: 118.7578, Val Acc: 0.1395\n",
            "Epoch 6/10\n",
            "  Train Loss: 93.4862, Train Acc: 0.2285\n",
            "  Val Loss: 83.6664, Val Acc: 0.0930\n",
            "Epoch 7/10\n",
            "  Train Loss: 72.7219, Train Acc: 0.2008\n",
            "  Val Loss: 72.5425, Val Acc: 0.1395\n",
            "Epoch 8/10\n",
            "  Train Loss: 55.5756, Train Acc: 0.1788\n",
            "  Val Loss: 107.1870, Val Acc: 0.1395\n",
            "Epoch 9/10\n",
            "  Train Loss: 78.8218, Train Acc: 0.2170\n",
            "  Val Loss: 83.2496, Val Acc: 0.0930\n",
            "Epoch 10/10\n",
            "  Train Loss: 55.4877, Train Acc: 0.2055\n",
            "  Val Loss: 107.0162, Val Acc: 0.0930\n",
            "Inner layer size = 500\n",
            "Epoch 1/10\n",
            "  Train Loss: 462597035.0582, Train Acc: 0.2036\n",
            "  Val Loss: 172.8163, Val Acc: 0.3643\n",
            "Epoch 2/10\n",
            "  Train Loss: 3674201.7311, Train Acc: 0.2122\n",
            "  Val Loss: 76.2573, Val Acc: 0.0930\n",
            "Epoch 3/10\n",
            "  Train Loss: 173.4856, Train Acc: 0.1750\n",
            "  Val Loss: 138.1207, Val Acc: 0.1395\n",
            "Epoch 4/10\n",
            "  Train Loss: 174.0260, Train Acc: 0.2294\n",
            "  Val Loss: 161.4687, Val Acc: 0.0930\n",
            "Epoch 5/10\n",
            "  Train Loss: 220.6615, Train Acc: 0.2161\n",
            "  Val Loss: 139.8433, Val Acc: 0.3101\n",
            "Epoch 6/10\n",
            "  Train Loss: 150.6796, Train Acc: 0.1989\n",
            "  Val Loss: 226.4839, Val Acc: 0.3643\n",
            "Epoch 7/10\n",
            "  Train Loss: 166.4362, Train Acc: 0.2180\n",
            "  Val Loss: 112.1864, Val Acc: 0.3101\n",
            "Epoch 8/10\n",
            "  Train Loss: 111.2563, Train Acc: 0.1998\n",
            "  Val Loss: 78.3458, Val Acc: 0.0930\n",
            "Epoch 9/10\n",
            "  Train Loss: 173.0972, Train Acc: 0.1912\n",
            "  Val Loss: 287.2912, Val Acc: 0.3101\n",
            "Epoch 10/10\n",
            "  Train Loss: 194.1920, Train Acc: 0.2017\n",
            "  Val Loss: 230.4012, Val Acc: 0.3101\n",
            "Inner layer size = 750\n",
            "Epoch 1/10\n",
            "  Train Loss: 1310575474.2842, Train Acc: 0.2428\n",
            "  Val Loss: 487.2552, Val Acc: 0.0930\n",
            "Epoch 2/10\n",
            "  Train Loss: 373.8419, Train Acc: 0.1969\n",
            "  Val Loss: 321.0234, Val Acc: 0.0930\n",
            "Epoch 3/10\n",
            "  Train Loss: 258.4038, Train Acc: 0.2180\n",
            "  Val Loss: 558.1776, Val Acc: 0.1395\n",
            "Epoch 4/10\n",
            "  Train Loss: 272.0228, Train Acc: 0.1969\n",
            "  Val Loss: 304.7883, Val Acc: 0.1395\n",
            "Epoch 5/10\n",
            "  Train Loss: 198.1226, Train Acc: 0.1950\n",
            "  Val Loss: 194.2219, Val Acc: 0.0930\n",
            "Epoch 6/10\n",
            "  Train Loss: 201.0175, Train Acc: 0.2218\n",
            "  Val Loss: 106.1122, Val Acc: 0.0930\n",
            "Epoch 7/10\n",
            "  Train Loss: 314.8888, Train Acc: 0.2008\n",
            "  Val Loss: 295.9748, Val Acc: 0.0930\n",
            "Epoch 8/10\n",
            "  Train Loss: 354.2333, Train Acc: 0.1874\n",
            "  Val Loss: 358.5953, Val Acc: 0.3101\n",
            "Epoch 9/10\n",
            "  Train Loss: 198.0139, Train Acc: 0.2266\n",
            "  Val Loss: 111.0505, Val Acc: 0.0930\n",
            "Epoch 10/10\n",
            "  Train Loss: 170.5560, Train Acc: 0.2103\n",
            "  Val Loss: 91.7770, Val Acc: 0.3101\n",
            "Inner layer size = 1000\n",
            "Epoch 1/10\n",
            "  Train Loss: 2203356119.5027, Train Acc: 0.2046\n",
            "  Val Loss: 5436393.3311, Val Acc: 0.3488\n",
            "Epoch 2/10\n",
            "  Train Loss: 2031328.3059, Train Acc: 0.1845\n",
            "  Val Loss: 351.5301, Val Acc: 0.3643\n",
            "Epoch 3/10\n",
            "  Train Loss: 442.4294, Train Acc: 0.2199\n",
            "  Val Loss: 443.6428, Val Acc: 0.0930\n",
            "Epoch 4/10\n",
            "  Train Loss: 40988.3461, Train Acc: 0.1874\n",
            "  Val Loss: 566.3024, Val Acc: 0.3643\n",
            "Epoch 5/10\n",
            "  Train Loss: 440.7095, Train Acc: 0.2017\n",
            "  Val Loss: 337.6790, Val Acc: 0.3643\n",
            "Epoch 6/10\n",
            "  Train Loss: 998437.9886, Train Acc: 0.2294\n",
            "  Val Loss: 288.4176, Val Acc: 0.0930\n",
            "Epoch 7/10\n",
            "  Train Loss: 210.2225, Train Acc: 0.2027\n",
            "  Val Loss: 450.9572, Val Acc: 0.3101\n",
            "Epoch 8/10\n",
            "  Train Loss: 366.0945, Train Acc: 0.2275\n",
            "  Val Loss: 235.7227, Val Acc: 0.3643\n",
            "Epoch 9/10\n",
            "  Train Loss: 399.9879, Train Acc: 0.1902\n",
            "  Val Loss: 294.1763, Val Acc: 0.1395\n",
            "Epoch 10/10\n",
            "  Train Loss: 314.8591, Train Acc: 0.1902\n",
            "  Val Loss: 261.2609, Val Acc: 0.3643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like adding an inner layer is not improving the model. lets stick with only output layer.\n",
        "\n",
        "Now, lets experiment with dropout"
      ],
      "metadata": {
        "id": "EvJ8i86Ffddq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VehicleClassifierModel(nn.Module):\n",
        "    def __init__(self, num_classes=5,dropout_p=0.0):\n",
        "        super(VehicleClassifierModel, self).__init__()\n",
        "\n",
        "        # Load pre-trained MobileNetV2\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "        self.output_layer = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # removed the previously added inner layer\n",
        "        # added dropout layer\n",
        "        x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ftnu0aE-gfZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  train_and_val(model, optimizer, train_loader, val_loader, criterion, num_epochs, device) :\n",
        "  best_val_accuracy = 0.0  # Initialize variable to track the best validation accuracy\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      # Training phase\n",
        "      model.train()  # Set the model to training mode\n",
        "      running_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      # Iterate over the training data\n",
        "      for inputs, labels in train_loader:\n",
        "          # Move data to the specified device (GPU or CPU)\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # Zero the parameter gradients to prevent accumulation\n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          outputs = model(inputs)\n",
        "          # Calculate the loss\n",
        "          loss = criterion(outputs, labels)\n",
        "          # Backward pass and optimize\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Accumulate training loss\n",
        "          running_loss += loss.item()\n",
        "          # Get predictions\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          # Update total and correct predictions\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # Calculate average training loss and accuracy\n",
        "      train_loss = running_loss / len(train_loader)\n",
        "      train_acc = correct / total\n",
        "\n",
        "      # Validation phase\n",
        "      model.eval()  # Set the model to evaluation mode\n",
        "      val_loss = 0.0\n",
        "      val_correct = 0\n",
        "      val_total = 0\n",
        "\n",
        "      # Disable gradient calculation for validation\n",
        "      with torch.no_grad():\n",
        "          # Iterate over the validation data\n",
        "          for inputs, labels in val_loader:\n",
        "              # Move data to the specified device (GPU or CPU)\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              # Forward pass\n",
        "              outputs = model(inputs)\n",
        "              # Calculate the loss\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              # Accumulate validation loss\n",
        "              val_loss += loss.item()\n",
        "              # Get predictions\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              # Update total and correct predictions\n",
        "              val_total += labels.size(0)\n",
        "              val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # Calculate average validation loss and accuracy\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc = val_correct / val_total\n",
        "\n",
        "      # Print epoch results\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "      print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "      print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "      if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            checkpoint_path = f'vehicleclassifier_WDO_{epoch+1:02d}_{val_acc:.3f}.pth'\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f'Checkpoint saved: {checkpoint_path}')"
      ],
      "metadata": {
        "id": "I4jvSgtXg_F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(learning_rate=0.01, class_weights=None,dropout_p=0.0):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = VehicleClassifierModel(num_classes=5,dropout_p=dropout_p)\n",
        "    model.to(device) # Move the model to the correct device\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # 1. Define the loss function with your calculated weights\n",
        "    # If you are using a GPU, make sure the weights are on the same device\n",
        "    if class_weights is not None:\n",
        "      class_weights = class_weights.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    return model, optimizer, criterion"
      ],
      "metadata": {
        "id": "9Uz4aNOshnYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch=50\n",
        "for drop_out in [0.2,0.4,0.5,0.7]:\n",
        "  print(\"Dropout =\", drop_out)\n",
        "  model, optimizer, criterion = make_model(dropout_p=drop_out,class_weights=class_weights)\n",
        "\n",
        "  train_and_val(model, optimizer, train_loader, val_loader, criterion, num_epoch, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdMBpWebiSgE",
        "outputId": "0986cb73-1833-45ce-bb57-302ac71768a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropout = 0.2\n",
            "Epoch 1/50\n",
            "  Train Loss: 1.3676, Train Acc: 0.5382\n",
            "  Val Loss: 0.6529, Val Acc: 0.8605\n",
            "Checkpoint saved: vehicleclassifier_WDO_01_0.860.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 0.6426, Train Acc: 0.7600\n",
            "  Val Loss: 0.4123, Val Acc: 0.8450\n",
            "Epoch 3/50\n",
            "  Train Loss: 0.4892, Train Acc: 0.8298\n",
            "  Val Loss: 0.5515, Val Acc: 0.7907\n",
            "Epoch 4/50\n",
            "  Train Loss: 0.4920, Train Acc: 0.8356\n",
            "  Val Loss: 0.3107, Val Acc: 0.8372\n",
            "Epoch 5/50\n",
            "  Train Loss: 0.3721, Train Acc: 0.8509\n",
            "  Val Loss: 0.3054, Val Acc: 0.8605\n",
            "Epoch 6/50\n",
            "  Train Loss: 0.3489, Train Acc: 0.8470\n",
            "  Val Loss: 0.2655, Val Acc: 0.8837\n",
            "Checkpoint saved: vehicleclassifier_WDO_06_0.884.pth\n",
            "Epoch 7/50\n",
            "  Train Loss: 0.3565, Train Acc: 0.8623\n",
            "  Val Loss: 0.2801, Val Acc: 0.8915\n",
            "Checkpoint saved: vehicleclassifier_WDO_07_0.891.pth\n",
            "Epoch 8/50\n",
            "  Train Loss: 0.2591, Train Acc: 0.8910\n",
            "  Val Loss: 0.2879, Val Acc: 0.9070\n",
            "Checkpoint saved: vehicleclassifier_WDO_08_0.907.pth\n",
            "Epoch 9/50\n",
            "  Train Loss: 0.2109, Train Acc: 0.9140\n",
            "  Val Loss: 0.3200, Val Acc: 0.8682\n",
            "Epoch 10/50\n",
            "  Train Loss: 0.2688, Train Acc: 0.8929\n",
            "  Val Loss: 0.9423, Val Acc: 0.7519\n",
            "Epoch 11/50\n",
            "  Train Loss: 0.3078, Train Acc: 0.8709\n",
            "  Val Loss: 0.6052, Val Acc: 0.8295\n",
            "Epoch 12/50\n",
            "  Train Loss: 0.4424, Train Acc: 0.8356\n",
            "  Val Loss: 0.3286, Val Acc: 0.8760\n",
            "Epoch 13/50\n",
            "  Train Loss: 0.2609, Train Acc: 0.8977\n",
            "  Val Loss: 0.3751, Val Acc: 0.8605\n",
            "Epoch 14/50\n",
            "  Train Loss: 0.3018, Train Acc: 0.8948\n",
            "  Val Loss: 0.8544, Val Acc: 0.7287\n",
            "Epoch 15/50\n",
            "  Train Loss: 0.3529, Train Acc: 0.8709\n",
            "  Val Loss: 0.3295, Val Acc: 0.8992\n",
            "Epoch 16/50\n",
            "  Train Loss: 0.2327, Train Acc: 0.9149\n",
            "  Val Loss: 0.3703, Val Acc: 0.8450\n",
            "Epoch 17/50\n",
            "  Train Loss: 0.1751, Train Acc: 0.9388\n",
            "  Val Loss: 0.4726, Val Acc: 0.8372\n",
            "Epoch 18/50\n",
            "  Train Loss: 0.2263, Train Acc: 0.9101\n",
            "  Val Loss: 0.5819, Val Acc: 0.8837\n",
            "Epoch 19/50\n",
            "  Train Loss: 0.3615, Train Acc: 0.8862\n",
            "  Val Loss: 0.4641, Val Acc: 0.8915\n",
            "Epoch 20/50\n",
            "  Train Loss: 0.2705, Train Acc: 0.9063\n",
            "  Val Loss: 0.3765, Val Acc: 0.8682\n",
            "Epoch 21/50\n",
            "  Train Loss: 0.2753, Train Acc: 0.9034\n",
            "  Val Loss: 0.5049, Val Acc: 0.8605\n",
            "Epoch 22/50\n",
            "  Train Loss: 0.2459, Train Acc: 0.9025\n",
            "  Val Loss: 0.3347, Val Acc: 0.9070\n",
            "Epoch 23/50\n",
            "  Train Loss: 0.3052, Train Acc: 0.9054\n",
            "  Val Loss: 0.2592, Val Acc: 0.9147\n",
            "Checkpoint saved: vehicleclassifier_WDO_23_0.915.pth\n",
            "Epoch 24/50\n",
            "  Train Loss: 0.3944, Train Acc: 0.8853\n",
            "  Val Loss: 0.5891, Val Acc: 0.8992\n",
            "Epoch 25/50\n",
            "  Train Loss: 0.4535, Train Acc: 0.8690\n",
            "  Val Loss: 0.3347, Val Acc: 0.8605\n",
            "Epoch 26/50\n",
            "  Train Loss: 0.2761, Train Acc: 0.9111\n",
            "  Val Loss: 0.4006, Val Acc: 0.8915\n",
            "Epoch 27/50\n",
            "  Train Loss: 0.4247, Train Acc: 0.8862\n",
            "  Val Loss: 0.6910, Val Acc: 0.8450\n",
            "Epoch 28/50\n",
            "  Train Loss: 0.3391, Train Acc: 0.8939\n",
            "  Val Loss: 0.3776, Val Acc: 0.9147\n",
            "Epoch 29/50\n",
            "  Train Loss: 0.3545, Train Acc: 0.9044\n",
            "  Val Loss: 0.3893, Val Acc: 0.8605\n",
            "Epoch 30/50\n",
            "  Train Loss: 0.2178, Train Acc: 0.9283\n",
            "  Val Loss: 0.4486, Val Acc: 0.9225\n",
            "Checkpoint saved: vehicleclassifier_WDO_30_0.922.pth\n",
            "Epoch 31/50\n",
            "  Train Loss: 0.2853, Train Acc: 0.9149\n",
            "  Val Loss: 0.4126, Val Acc: 0.8605\n",
            "Epoch 32/50\n",
            "  Train Loss: 0.2422, Train Acc: 0.9207\n",
            "  Val Loss: 0.3508, Val Acc: 0.8915\n",
            "Epoch 33/50\n",
            "  Train Loss: 0.2369, Train Acc: 0.9302\n",
            "  Val Loss: 0.5776, Val Acc: 0.8992\n",
            "Epoch 34/50\n",
            "  Train Loss: 0.2507, Train Acc: 0.9283\n",
            "  Val Loss: 0.3856, Val Acc: 0.9147\n",
            "Epoch 35/50\n",
            "  Train Loss: 0.3471, Train Acc: 0.9025\n",
            "  Val Loss: 0.3187, Val Acc: 0.9070\n",
            "Epoch 36/50\n",
            "  Train Loss: 0.1849, Train Acc: 0.9273\n",
            "  Val Loss: 0.3267, Val Acc: 0.9070\n",
            "Epoch 37/50\n",
            "  Train Loss: 0.2451, Train Acc: 0.9120\n",
            "  Val Loss: 0.6432, Val Acc: 0.8605\n",
            "Epoch 38/50\n",
            "  Train Loss: 0.3176, Train Acc: 0.9063\n",
            "  Val Loss: 0.5302, Val Acc: 0.8605\n",
            "Epoch 39/50\n",
            "  Train Loss: 0.2479, Train Acc: 0.9254\n",
            "  Val Loss: 0.4213, Val Acc: 0.8760\n",
            "Epoch 40/50\n",
            "  Train Loss: 0.2164, Train Acc: 0.9417\n",
            "  Val Loss: 0.4239, Val Acc: 0.9070\n",
            "Epoch 41/50\n",
            "  Train Loss: 0.1617, Train Acc: 0.9465\n",
            "  Val Loss: 0.4439, Val Acc: 0.9147\n",
            "Epoch 42/50\n",
            "  Train Loss: 0.1945, Train Acc: 0.9312\n",
            "  Val Loss: 0.4956, Val Acc: 0.8915\n",
            "Epoch 43/50\n",
            "  Train Loss: 0.2051, Train Acc: 0.9350\n",
            "  Val Loss: 0.5068, Val Acc: 0.8760\n",
            "Epoch 44/50\n",
            "  Train Loss: 0.2065, Train Acc: 0.9407\n",
            "  Val Loss: 0.3578, Val Acc: 0.8837\n",
            "Epoch 45/50\n",
            "  Train Loss: 0.3260, Train Acc: 0.9073\n",
            "  Val Loss: 0.6228, Val Acc: 0.8217\n",
            "Epoch 46/50\n",
            "  Train Loss: 0.2261, Train Acc: 0.9273\n",
            "  Val Loss: 0.6767, Val Acc: 0.8760\n",
            "Epoch 47/50\n",
            "  Train Loss: 0.3353, Train Acc: 0.9187\n",
            "  Val Loss: 0.5448, Val Acc: 0.9070\n",
            "Epoch 48/50\n",
            "  Train Loss: 0.1735, Train Acc: 0.9359\n",
            "  Val Loss: 0.5670, Val Acc: 0.8760\n",
            "Epoch 49/50\n",
            "  Train Loss: 0.3848, Train Acc: 0.9025\n",
            "  Val Loss: 1.9745, Val Acc: 0.8760\n",
            "Epoch 50/50\n",
            "  Train Loss: 0.6425, Train Acc: 0.8776\n",
            "  Val Loss: 1.1510, Val Acc: 0.8140\n",
            "Dropout = 0.4\n",
            "Epoch 1/50\n",
            "  Train Loss: 1.4473, Train Acc: 0.5392\n",
            "  Val Loss: 0.5925, Val Acc: 0.6899\n",
            "Checkpoint saved: vehicleclassifier_WDO_01_0.690.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 0.6543, Train Acc: 0.7505\n",
            "  Val Loss: 0.3833, Val Acc: 0.8605\n",
            "Checkpoint saved: vehicleclassifier_WDO_02_0.860.pth\n",
            "Epoch 3/50\n",
            "  Train Loss: 0.6009, Train Acc: 0.7983\n",
            "  Val Loss: 0.5148, Val Acc: 0.8062\n",
            "Epoch 4/50\n",
            "  Train Loss: 0.7837, Train Acc: 0.7543\n",
            "  Val Loss: 0.4541, Val Acc: 0.8372\n",
            "Epoch 5/50\n",
            "  Train Loss: 0.5519, Train Acc: 0.8078\n",
            "  Val Loss: 0.3741, Val Acc: 0.8992\n",
            "Checkpoint saved: vehicleclassifier_WDO_05_0.899.pth\n",
            "Epoch 6/50\n",
            "  Train Loss: 0.4874, Train Acc: 0.8308\n",
            "  Val Loss: 0.5023, Val Acc: 0.7829\n",
            "Epoch 7/50\n",
            "  Train Loss: 0.6378, Train Acc: 0.7935\n",
            "  Val Loss: 1.0397, Val Acc: 0.7054\n",
            "Epoch 8/50\n",
            "  Train Loss: 0.5895, Train Acc: 0.8203\n",
            "  Val Loss: 0.3773, Val Acc: 0.8837\n",
            "Epoch 9/50\n",
            "  Train Loss: 0.4924, Train Acc: 0.8432\n",
            "  Val Loss: 0.6547, Val Acc: 0.8992\n",
            "Epoch 10/50\n",
            "  Train Loss: 0.4562, Train Acc: 0.8317\n",
            "  Val Loss: 0.4560, Val Acc: 0.8295\n",
            "Epoch 11/50\n",
            "  Train Loss: 0.4282, Train Acc: 0.8489\n",
            "  Val Loss: 0.3513, Val Acc: 0.8760\n",
            "Epoch 12/50\n",
            "  Train Loss: 0.5636, Train Acc: 0.8069\n",
            "  Val Loss: 0.4816, Val Acc: 0.8450\n",
            "Epoch 13/50\n",
            "  Train Loss: 0.4503, Train Acc: 0.8547\n",
            "  Val Loss: 0.4508, Val Acc: 0.8915\n",
            "Epoch 14/50\n",
            "  Train Loss: 0.5418, Train Acc: 0.8451\n",
            "  Val Loss: 0.6804, Val Acc: 0.7364\n",
            "Epoch 15/50\n",
            "  Train Loss: 0.6643, Train Acc: 0.8231\n",
            "  Val Loss: 0.4589, Val Acc: 0.8760\n",
            "Epoch 16/50\n",
            "  Train Loss: 0.5681, Train Acc: 0.8451\n",
            "  Val Loss: 0.4755, Val Acc: 0.8295\n",
            "Epoch 17/50\n",
            "  Train Loss: 0.4748, Train Acc: 0.8461\n",
            "  Val Loss: 0.4238, Val Acc: 0.8682\n",
            "Epoch 18/50\n",
            "  Train Loss: 0.5133, Train Acc: 0.8231\n",
            "  Val Loss: 0.5156, Val Acc: 0.8527\n",
            "Epoch 19/50\n",
            "  Train Loss: 0.5420, Train Acc: 0.8375\n",
            "  Val Loss: 0.3723, Val Acc: 0.8682\n",
            "Epoch 20/50\n",
            "  Train Loss: 0.6521, Train Acc: 0.8308\n",
            "  Val Loss: 0.3687, Val Acc: 0.8760\n",
            "Epoch 21/50\n",
            "  Train Loss: 0.4815, Train Acc: 0.8614\n",
            "  Val Loss: 0.4726, Val Acc: 0.8062\n",
            "Epoch 22/50\n",
            "  Train Loss: 0.4576, Train Acc: 0.8690\n",
            "  Val Loss: 0.5213, Val Acc: 0.8372\n",
            "Epoch 23/50\n",
            "  Train Loss: 0.7039, Train Acc: 0.8327\n",
            "  Val Loss: 0.7226, Val Acc: 0.6899\n",
            "Epoch 24/50\n",
            "  Train Loss: 0.6728, Train Acc: 0.8212\n",
            "  Val Loss: 0.6291, Val Acc: 0.8217\n",
            "Epoch 25/50\n",
            "  Train Loss: 0.7156, Train Acc: 0.8289\n",
            "  Val Loss: 0.4050, Val Acc: 0.8837\n",
            "Epoch 26/50\n",
            "  Train Loss: 0.5343, Train Acc: 0.8499\n",
            "  Val Loss: 0.8119, Val Acc: 0.7984\n",
            "Epoch 27/50\n",
            "  Train Loss: 0.5437, Train Acc: 0.8681\n",
            "  Val Loss: 0.4869, Val Acc: 0.8450\n",
            "Epoch 28/50\n",
            "  Train Loss: 0.5351, Train Acc: 0.8623\n",
            "  Val Loss: 0.6228, Val Acc: 0.8760\n",
            "Epoch 29/50\n",
            "  Train Loss: 0.7385, Train Acc: 0.8241\n",
            "  Val Loss: 0.6047, Val Acc: 0.8527\n",
            "Epoch 30/50\n",
            "  Train Loss: 0.7120, Train Acc: 0.8222\n",
            "  Val Loss: 0.3651, Val Acc: 0.9070\n",
            "Checkpoint saved: vehicleclassifier_WDO_30_0.907.pth\n",
            "Epoch 31/50\n",
            "  Train Loss: 0.6747, Train Acc: 0.8537\n",
            "  Val Loss: 0.5102, Val Acc: 0.8450\n",
            "Epoch 32/50\n",
            "  Train Loss: 0.6252, Train Acc: 0.8499\n",
            "  Val Loss: 1.1474, Val Acc: 0.7054\n",
            "Epoch 33/50\n",
            "  Train Loss: 0.7177, Train Acc: 0.8203\n",
            "  Val Loss: 0.8920, Val Acc: 0.7287\n",
            "Epoch 34/50\n",
            "  Train Loss: 0.6743, Train Acc: 0.8327\n",
            "  Val Loss: 0.5435, Val Acc: 0.8605\n",
            "Epoch 35/50\n",
            "  Train Loss: 0.6585, Train Acc: 0.8489\n",
            "  Val Loss: 0.4526, Val Acc: 0.8760\n",
            "Epoch 36/50\n",
            "  Train Loss: 0.7372, Train Acc: 0.8547\n",
            "  Val Loss: 0.6543, Val Acc: 0.8837\n",
            "Epoch 37/50\n",
            "  Train Loss: 0.6196, Train Acc: 0.8576\n",
            "  Val Loss: 0.4055, Val Acc: 0.8605\n",
            "Epoch 38/50\n",
            "  Train Loss: 0.5437, Train Acc: 0.8767\n",
            "  Val Loss: 0.4392, Val Acc: 0.8760\n",
            "Epoch 39/50\n",
            "  Train Loss: 0.6146, Train Acc: 0.8451\n",
            "  Val Loss: 0.9060, Val Acc: 0.8217\n",
            "Epoch 40/50\n",
            "  Train Loss: 0.6963, Train Acc: 0.8403\n",
            "  Val Loss: 0.4421, Val Acc: 0.8837\n",
            "Epoch 41/50\n",
            "  Train Loss: 0.5173, Train Acc: 0.8805\n",
            "  Val Loss: 0.5753, Val Acc: 0.8372\n",
            "Epoch 42/50\n",
            "  Train Loss: 0.6706, Train Acc: 0.8595\n",
            "  Val Loss: 0.4457, Val Acc: 0.8915\n",
            "Epoch 43/50\n",
            "  Train Loss: 0.6674, Train Acc: 0.8499\n",
            "  Val Loss: 0.7745, Val Acc: 0.8760\n",
            "Epoch 44/50\n",
            "  Train Loss: 0.6369, Train Acc: 0.8604\n",
            "  Val Loss: 0.2928, Val Acc: 0.9070\n",
            "Epoch 45/50\n",
            "  Train Loss: 0.5486, Train Acc: 0.8853\n",
            "  Val Loss: 0.5477, Val Acc: 0.8450\n",
            "Epoch 46/50\n",
            "  Train Loss: 0.7369, Train Acc: 0.8566\n",
            "  Val Loss: 0.5789, Val Acc: 0.8837\n",
            "Epoch 47/50\n",
            "  Train Loss: 0.6524, Train Acc: 0.8547\n",
            "  Val Loss: 0.4500, Val Acc: 0.8372\n",
            "Epoch 48/50\n",
            "  Train Loss: 0.6920, Train Acc: 0.8509\n",
            "  Val Loss: 0.4950, Val Acc: 0.8837\n",
            "Epoch 49/50\n",
            "  Train Loss: 0.6175, Train Acc: 0.8881\n",
            "  Val Loss: 0.4913, Val Acc: 0.8605\n",
            "Epoch 50/50\n",
            "  Train Loss: 0.5693, Train Acc: 0.8681\n",
            "  Val Loss: 0.4992, Val Acc: 0.8682\n",
            "Dropout = 0.5\n",
            "Epoch 1/50\n",
            "  Train Loss: 1.7229, Train Acc: 0.5019\n",
            "  Val Loss: 0.5334, Val Acc: 0.7442\n",
            "Checkpoint saved: vehicleclassifier_WDO_01_0.744.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 0.8211, Train Acc: 0.7122\n",
            "  Val Loss: 0.7762, Val Acc: 0.7984\n",
            "Checkpoint saved: vehicleclassifier_WDO_02_0.798.pth\n",
            "Epoch 3/50\n",
            "  Train Loss: 0.6870, Train Acc: 0.7648\n",
            "  Val Loss: 0.5045, Val Acc: 0.7984\n",
            "Epoch 4/50\n",
            "  Train Loss: 0.7890, Train Acc: 0.7533\n",
            "  Val Loss: 0.4930, Val Acc: 0.8140\n",
            "Checkpoint saved: vehicleclassifier_WDO_04_0.814.pth\n",
            "Epoch 5/50\n",
            "  Train Loss: 0.8787, Train Acc: 0.7658\n",
            "  Val Loss: 0.5376, Val Acc: 0.8527\n",
            "Checkpoint saved: vehicleclassifier_WDO_05_0.853.pth\n",
            "Epoch 6/50\n",
            "  Train Loss: 0.6864, Train Acc: 0.7868\n",
            "  Val Loss: 0.3100, Val Acc: 0.8837\n",
            "Checkpoint saved: vehicleclassifier_WDO_06_0.884.pth\n",
            "Epoch 7/50\n",
            "  Train Loss: 0.7507, Train Acc: 0.7572\n",
            "  Val Loss: 0.4350, Val Acc: 0.8140\n",
            "Epoch 8/50\n",
            "  Train Loss: 0.6211, Train Acc: 0.8040\n",
            "  Val Loss: 0.6673, Val Acc: 0.8760\n",
            "Epoch 9/50\n",
            "  Train Loss: 0.7110, Train Acc: 0.7925\n",
            "  Val Loss: 0.3996, Val Acc: 0.8372\n",
            "Epoch 10/50\n",
            "  Train Loss: 0.6075, Train Acc: 0.8050\n",
            "  Val Loss: 0.5393, Val Acc: 0.8372\n",
            "Epoch 11/50\n",
            "  Train Loss: 0.6672, Train Acc: 0.7973\n",
            "  Val Loss: 0.4211, Val Acc: 0.8450\n",
            "Epoch 12/50\n",
            "  Train Loss: 0.6679, Train Acc: 0.8088\n",
            "  Val Loss: 0.5751, Val Acc: 0.8372\n",
            "Epoch 13/50\n",
            "  Train Loss: 0.7604, Train Acc: 0.7992\n",
            "  Val Loss: 0.3762, Val Acc: 0.8527\n",
            "Epoch 14/50\n",
            "  Train Loss: 0.7192, Train Acc: 0.7916\n",
            "  Val Loss: 0.5790, Val Acc: 0.8760\n",
            "Epoch 15/50\n",
            "  Train Loss: 0.6689, Train Acc: 0.8069\n",
            "  Val Loss: 0.5987, Val Acc: 0.8682\n",
            "Epoch 16/50\n",
            "  Train Loss: 0.6501, Train Acc: 0.8164\n",
            "  Val Loss: 0.6087, Val Acc: 0.8605\n",
            "Epoch 17/50\n",
            "  Train Loss: 0.7624, Train Acc: 0.8193\n",
            "  Val Loss: 0.3787, Val Acc: 0.8992\n",
            "Checkpoint saved: vehicleclassifier_WDO_17_0.899.pth\n",
            "Epoch 18/50\n",
            "  Train Loss: 0.7357, Train Acc: 0.8031\n",
            "  Val Loss: 0.4930, Val Acc: 0.8062\n",
            "Epoch 19/50\n",
            "  Train Loss: 0.7607, Train Acc: 0.8088\n",
            "  Val Loss: 0.5915, Val Acc: 0.8450\n",
            "Epoch 20/50\n",
            "  Train Loss: 0.7676, Train Acc: 0.8164\n",
            "  Val Loss: 0.5367, Val Acc: 0.8760\n",
            "Epoch 21/50\n",
            "  Train Loss: 0.6990, Train Acc: 0.8556\n",
            "  Val Loss: 0.4256, Val Acc: 0.8605\n",
            "Epoch 22/50\n",
            "  Train Loss: 0.9722, Train Acc: 0.7839\n",
            "  Val Loss: 0.4996, Val Acc: 0.8682\n",
            "Epoch 23/50\n",
            "  Train Loss: 1.2293, Train Acc: 0.7591\n",
            "  Val Loss: 1.0353, Val Acc: 0.7829\n",
            "Epoch 24/50\n",
            "  Train Loss: 0.7754, Train Acc: 0.8317\n",
            "  Val Loss: 0.5128, Val Acc: 0.8372\n",
            "Epoch 25/50\n",
            "  Train Loss: 0.9046, Train Acc: 0.8117\n",
            "  Val Loss: 0.5111, Val Acc: 0.8682\n",
            "Epoch 26/50\n",
            "  Train Loss: 1.1457, Train Acc: 0.7820\n",
            "  Val Loss: 1.1009, Val Acc: 0.8217\n",
            "Epoch 27/50\n",
            "  Train Loss: 0.9892, Train Acc: 0.8002\n",
            "  Val Loss: 0.8498, Val Acc: 0.8217\n",
            "Epoch 28/50\n",
            "  Train Loss: 0.7998, Train Acc: 0.8337\n",
            "  Val Loss: 0.6591, Val Acc: 0.8605\n",
            "Epoch 29/50\n",
            "  Train Loss: 0.7596, Train Acc: 0.8423\n",
            "  Val Loss: 0.4629, Val Acc: 0.8682\n",
            "Epoch 30/50\n",
            "  Train Loss: 0.7212, Train Acc: 0.8222\n",
            "  Val Loss: 0.6119, Val Acc: 0.8992\n",
            "Epoch 31/50\n",
            "  Train Loss: 0.8738, Train Acc: 0.8346\n",
            "  Val Loss: 0.5696, Val Acc: 0.8837\n",
            "Epoch 32/50\n",
            "  Train Loss: 0.7753, Train Acc: 0.8222\n",
            "  Val Loss: 0.5649, Val Acc: 0.8605\n",
            "Epoch 33/50\n",
            "  Train Loss: 0.6423, Train Acc: 0.8384\n",
            "  Val Loss: 0.5308, Val Acc: 0.9070\n",
            "Checkpoint saved: vehicleclassifier_WDO_33_0.907.pth\n",
            "Epoch 34/50\n",
            "  Train Loss: 0.7441, Train Acc: 0.8298\n",
            "  Val Loss: 0.5337, Val Acc: 0.8915\n",
            "Epoch 35/50\n",
            "  Train Loss: 0.8281, Train Acc: 0.8432\n",
            "  Val Loss: 0.6743, Val Acc: 0.8217\n",
            "Epoch 36/50\n",
            "  Train Loss: 0.8898, Train Acc: 0.8002\n",
            "  Val Loss: 0.6554, Val Acc: 0.8450\n",
            "Epoch 37/50\n",
            "  Train Loss: 0.7810, Train Acc: 0.8317\n",
            "  Val Loss: 0.6279, Val Acc: 0.8450\n",
            "Epoch 38/50\n",
            "  Train Loss: 0.9014, Train Acc: 0.8346\n",
            "  Val Loss: 0.8392, Val Acc: 0.8450\n",
            "Epoch 39/50\n",
            "  Train Loss: 0.9307, Train Acc: 0.8069\n",
            "  Val Loss: 0.5167, Val Acc: 0.8450\n",
            "Epoch 40/50\n",
            "  Train Loss: 1.0408, Train Acc: 0.8184\n",
            "  Val Loss: 0.5630, Val Acc: 0.8527\n",
            "Epoch 41/50\n",
            "  Train Loss: 1.0279, Train Acc: 0.8222\n",
            "  Val Loss: 0.7345, Val Acc: 0.7519\n",
            "Epoch 42/50\n",
            "  Train Loss: 0.9407, Train Acc: 0.8365\n",
            "  Val Loss: 0.5196, Val Acc: 0.8682\n",
            "Epoch 43/50\n",
            "  Train Loss: 0.8097, Train Acc: 0.8337\n",
            "  Val Loss: 0.7368, Val Acc: 0.7907\n",
            "Epoch 44/50\n",
            "  Train Loss: 0.6953, Train Acc: 0.8442\n",
            "  Val Loss: 0.5353, Val Acc: 0.8837\n",
            "Epoch 45/50\n",
            "  Train Loss: 0.6787, Train Acc: 0.8671\n",
            "  Val Loss: 0.5446, Val Acc: 0.8527\n",
            "Epoch 46/50\n",
            "  Train Loss: 0.7365, Train Acc: 0.8489\n",
            "  Val Loss: 0.6905, Val Acc: 0.8217\n",
            "Epoch 47/50\n",
            "  Train Loss: 0.8327, Train Acc: 0.8289\n",
            "  Val Loss: 0.6260, Val Acc: 0.8450\n",
            "Epoch 48/50\n",
            "  Train Loss: 0.9233, Train Acc: 0.8231\n",
            "  Val Loss: 0.8401, Val Acc: 0.7984\n",
            "Epoch 49/50\n",
            "  Train Loss: 0.8199, Train Acc: 0.8394\n",
            "  Val Loss: 0.5511, Val Acc: 0.8372\n",
            "Epoch 50/50\n",
            "  Train Loss: 0.8162, Train Acc: 0.8375\n",
            "  Val Loss: 0.5137, Val Acc: 0.8605\n",
            "Dropout = 0.7\n",
            "Epoch 1/50\n",
            "  Train Loss: 1.5643, Train Acc: 0.4818\n",
            "  Val Loss: 0.7131, Val Acc: 0.6202\n",
            "Checkpoint saved: vehicleclassifier_WDO_01_0.620.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 1.2215, Train Acc: 0.6597\n",
            "  Val Loss: 0.6611, Val Acc: 0.7364\n",
            "Checkpoint saved: vehicleclassifier_WDO_02_0.736.pth\n",
            "Epoch 3/50\n",
            "  Train Loss: 1.1011, Train Acc: 0.6902\n",
            "  Val Loss: 0.4211, Val Acc: 0.7907\n",
            "Checkpoint saved: vehicleclassifier_WDO_03_0.791.pth\n",
            "Epoch 4/50\n",
            "  Train Loss: 1.1618, Train Acc: 0.6845\n",
            "  Val Loss: 0.5652, Val Acc: 0.8295\n",
            "Checkpoint saved: vehicleclassifier_WDO_04_0.829.pth\n",
            "Epoch 5/50\n",
            "  Train Loss: 1.2829, Train Acc: 0.7027\n",
            "  Val Loss: 0.7291, Val Acc: 0.6899\n",
            "Epoch 6/50\n",
            "  Train Loss: 1.3043, Train Acc: 0.6845\n",
            "  Val Loss: 0.4498, Val Acc: 0.8295\n",
            "Epoch 7/50\n",
            "  Train Loss: 1.4098, Train Acc: 0.6816\n",
            "  Val Loss: 0.4618, Val Acc: 0.8450\n",
            "Checkpoint saved: vehicleclassifier_WDO_07_0.845.pth\n",
            "Epoch 8/50\n",
            "  Train Loss: 1.4484, Train Acc: 0.6950\n",
            "  Val Loss: 0.5927, Val Acc: 0.8372\n",
            "Epoch 9/50\n",
            "  Train Loss: 1.4882, Train Acc: 0.6902\n",
            "  Val Loss: 0.4342, Val Acc: 0.8605\n",
            "Checkpoint saved: vehicleclassifier_WDO_09_0.860.pth\n",
            "Epoch 10/50\n",
            "  Train Loss: 1.3294, Train Acc: 0.7103\n",
            "  Val Loss: 0.7886, Val Acc: 0.8295\n",
            "Epoch 11/50\n",
            "  Train Loss: 1.3909, Train Acc: 0.7371\n",
            "  Val Loss: 0.9902, Val Acc: 0.7519\n",
            "Epoch 12/50\n",
            "  Train Loss: 1.4099, Train Acc: 0.7285\n",
            "  Val Loss: 0.3935, Val Acc: 0.8837\n",
            "Checkpoint saved: vehicleclassifier_WDO_12_0.884.pth\n",
            "Epoch 13/50\n",
            "  Train Loss: 1.4031, Train Acc: 0.7467\n",
            "  Val Loss: 0.5302, Val Acc: 0.7907\n",
            "Epoch 14/50\n",
            "  Train Loss: 1.5233, Train Acc: 0.7027\n",
            "  Val Loss: 1.2394, Val Acc: 0.8062\n",
            "Epoch 15/50\n",
            "  Train Loss: 1.4127, Train Acc: 0.7247\n",
            "  Val Loss: 0.5415, Val Acc: 0.8682\n",
            "Epoch 16/50\n",
            "  Train Loss: 1.6562, Train Acc: 0.7151\n",
            "  Val Loss: 0.5004, Val Acc: 0.8295\n",
            "Epoch 17/50\n",
            "  Train Loss: 1.6861, Train Acc: 0.7189\n",
            "  Val Loss: 0.7190, Val Acc: 0.7054\n",
            "Epoch 18/50\n",
            "  Train Loss: 1.5772, Train Acc: 0.7132\n",
            "  Val Loss: 0.7726, Val Acc: 0.7984\n",
            "Epoch 19/50\n",
            "  Train Loss: 1.3791, Train Acc: 0.7304\n",
            "  Val Loss: 0.6600, Val Acc: 0.8295\n",
            "Epoch 20/50\n",
            "  Train Loss: 1.6135, Train Acc: 0.7208\n",
            "  Val Loss: 0.6444, Val Acc: 0.8295\n",
            "Epoch 21/50\n",
            "  Train Loss: 1.4415, Train Acc: 0.7600\n",
            "  Val Loss: 0.5734, Val Acc: 0.8682\n",
            "Epoch 22/50\n",
            "  Train Loss: 1.4255, Train Acc: 0.7352\n",
            "  Val Loss: 0.8305, Val Acc: 0.7829\n",
            "Epoch 23/50\n",
            "  Train Loss: 1.7161, Train Acc: 0.7294\n",
            "  Val Loss: 0.5137, Val Acc: 0.8527\n",
            "Epoch 24/50\n",
            "  Train Loss: 1.4833, Train Acc: 0.7371\n",
            "  Val Loss: 0.5316, Val Acc: 0.8605\n",
            "Epoch 25/50\n",
            "  Train Loss: 1.7661, Train Acc: 0.7409\n",
            "  Val Loss: 1.2132, Val Acc: 0.7442\n",
            "Epoch 26/50\n",
            "  Train Loss: 1.8365, Train Acc: 0.7180\n",
            "  Val Loss: 0.6814, Val Acc: 0.8372\n",
            "Epoch 27/50\n",
            "  Train Loss: 1.8005, Train Acc: 0.7467\n",
            "  Val Loss: 0.6769, Val Acc: 0.8217\n",
            "Epoch 28/50\n",
            "  Train Loss: 1.7504, Train Acc: 0.7151\n",
            "  Val Loss: 0.8186, Val Acc: 0.7984\n",
            "Epoch 29/50\n",
            "  Train Loss: 2.0763, Train Acc: 0.6931\n",
            "  Val Loss: 0.7536, Val Acc: 0.8217\n",
            "Epoch 30/50\n",
            "  Train Loss: 1.8750, Train Acc: 0.7294\n",
            "  Val Loss: 0.5328, Val Acc: 0.8450\n",
            "Epoch 31/50\n",
            "  Train Loss: 1.8333, Train Acc: 0.7333\n",
            "  Val Loss: 0.5814, Val Acc: 0.8217\n",
            "Epoch 32/50\n",
            "  Train Loss: 1.6252, Train Acc: 0.7486\n",
            "  Val Loss: 0.5365, Val Acc: 0.8760\n",
            "Epoch 33/50\n",
            "  Train Loss: 1.5096, Train Acc: 0.7667\n",
            "  Val Loss: 0.6392, Val Acc: 0.8605\n",
            "Epoch 34/50\n",
            "  Train Loss: 1.7252, Train Acc: 0.7199\n",
            "  Val Loss: 0.7743, Val Acc: 0.8372\n",
            "Epoch 35/50\n",
            "  Train Loss: 2.0359, Train Acc: 0.7075\n",
            "  Val Loss: 0.6614, Val Acc: 0.8140\n",
            "Epoch 36/50\n",
            "  Train Loss: 1.6555, Train Acc: 0.7314\n",
            "  Val Loss: 0.6090, Val Acc: 0.8062\n",
            "Epoch 37/50\n",
            "  Train Loss: 1.6538, Train Acc: 0.7572\n",
            "  Val Loss: 0.5735, Val Acc: 0.8295\n",
            "Epoch 38/50\n",
            "  Train Loss: 1.7238, Train Acc: 0.7505\n",
            "  Val Loss: 0.6981, Val Acc: 0.8527\n",
            "Epoch 39/50\n",
            "  Train Loss: 2.0117, Train Acc: 0.7218\n",
            "  Val Loss: 0.7734, Val Acc: 0.8217\n",
            "Epoch 40/50\n",
            "  Train Loss: 1.4551, Train Acc: 0.7591\n",
            "  Val Loss: 0.6437, Val Acc: 0.8140\n",
            "Epoch 41/50\n",
            "  Train Loss: 1.6125, Train Acc: 0.7419\n",
            "  Val Loss: 0.5980, Val Acc: 0.8837\n",
            "Epoch 42/50\n",
            "  Train Loss: 2.1278, Train Acc: 0.7237\n",
            "  Val Loss: 0.5568, Val Acc: 0.8682\n",
            "Epoch 43/50\n",
            "  Train Loss: 1.5953, Train Acc: 0.7620\n",
            "  Val Loss: 0.5508, Val Acc: 0.8682\n",
            "Epoch 44/50\n",
            "  Train Loss: 1.7406, Train Acc: 0.7438\n",
            "  Val Loss: 0.5445, Val Acc: 0.8605\n",
            "Epoch 45/50\n",
            "  Train Loss: 1.8559, Train Acc: 0.7132\n",
            "  Val Loss: 0.5516, Val Acc: 0.8760\n",
            "Epoch 46/50\n",
            "  Train Loss: 1.5731, Train Acc: 0.7495\n",
            "  Val Loss: 0.5878, Val Acc: 0.8915\n",
            "Checkpoint saved: vehicleclassifier_WDO_46_0.891.pth\n",
            "Epoch 47/50\n",
            "  Train Loss: 1.6310, Train Acc: 0.7629\n",
            "  Val Loss: 0.5957, Val Acc: 0.8682\n",
            "Epoch 48/50\n",
            "  Train Loss: 1.6214, Train Acc: 0.7572\n",
            "  Val Loss: 0.5906, Val Acc: 0.8217\n",
            "Epoch 49/50\n",
            "  Train Loss: 2.1039, Train Acc: 0.7237\n",
            "  Val Loss: 0.5106, Val Acc: 0.8682\n",
            "Epoch 50/50\n",
            "  Train Loss: 1.7007, Train Acc: 0.7361\n",
            "  Val Loss: 0.5982, Val Acc: 0.8682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the experimentation\n",
        "dropout: 0.2\n",
        "\n",
        "Epoch 30/50\n",
        "  Train Loss: 0.2178, Train Acc: 0.9283\n",
        "  Val Loss: 0.4486, Val Acc: 0.9225\n",
        "Checkpoint saved: vehicleclassifier_WDO_30_0.922.pth\n",
        "\n",
        "Epoch 8/50\n",
        "  Train Loss: 0.2591, Train Acc: 0.8910\n",
        "  Val Loss: 0.2879, Val Acc: 0.9070"
      ],
      "metadata": {
        "id": "FTb5hYRKp9Dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# Define a custom Dataset class for loading vehicle images\n",
        "class VehicleDataset(Dataset):\n",
        "    # Initialize the dataset\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir  # Root directory containing class folders\n",
        "        self.transform = transform  # Transformations to apply to images (e.g., resizing, normalization)\n",
        "        self.image_paths = []     # List to store full paths to all images\n",
        "        self.labels = []          # List to store integer labels corresponding to each image\n",
        "\n",
        "        # Get class names from subdirectories and sort them for consistent indexing\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        # Create a mapping from class name (string) to integer index\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        # Populate image_paths and labels lists\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)  # Path to the current class's directory\n",
        "            # Iterate through all image files in the class directory\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))  # Add image path\n",
        "                self.labels.append(self.class_to_idx[label_name])           # Add corresponding integer label\n",
        "\n",
        "    # Return the total number of samples in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    # Return a single sample (image and its label) given an index\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]  # Get the path of the image at the given index\n",
        "        image = Image.open(img_path).convert('RGB')  # Open and convert image to RGB format\n",
        "        label = self.labels[idx]          # Get the label for the image\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "JNf_3kWqt_a7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VehicleClassifierModel(nn.Module):\n",
        "    def __init__(self, num_classes=5,dropout_p=0.0):\n",
        "        super(VehicleClassifierModel, self).__init__()\n",
        "\n",
        "        # Load pre-trained MobileNetV2\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "        self.output_layer = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # removed the previously added inner layer\n",
        "        # added dropout layer\n",
        "        x = self.dropout(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nAGzcch7vEhR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  train_and_val(model, optimizer, train_loader, val_loader, criterion, num_epochs, device) :\n",
        "  best_val_accuracy = 0.0  # Initialize variable to track the best validation accuracy\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      # Training phase\n",
        "      model.train()  # Set the model to training mode\n",
        "      running_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      # Iterate over the training data\n",
        "      for inputs, labels in train_loader:\n",
        "          # Move data to the specified device (GPU or CPU)\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # Zero the parameter gradients to prevent accumulation\n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          outputs = model(inputs)\n",
        "          # Calculate the loss\n",
        "          loss = criterion(outputs, labels)\n",
        "          # Backward pass and optimize\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Accumulate training loss\n",
        "          running_loss += loss.item()\n",
        "          # Get predictions\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          # Update total and correct predictions\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # Calculate average training loss and accuracy\n",
        "      train_loss = running_loss / len(train_loader)\n",
        "      train_acc = correct / total\n",
        "\n",
        "      # Validation phase\n",
        "      model.eval()  # Set the model to evaluation mode\n",
        "      val_loss = 0.0\n",
        "      val_correct = 0\n",
        "      val_total = 0\n",
        "\n",
        "      # Disable gradient calculation for validation\n",
        "      with torch.no_grad():\n",
        "          # Iterate over the validation data\n",
        "          for inputs, labels in val_loader:\n",
        "              # Move data to the specified device (GPU or CPU)\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              # Forward pass\n",
        "              outputs = model(inputs)\n",
        "              # Calculate the loss\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              # Accumulate validation loss\n",
        "              val_loss += loss.item()\n",
        "              # Get predictions\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              # Update total and correct predictions\n",
        "              val_total += labels.size(0)\n",
        "              val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # Calculate average validation loss and accuracy\n",
        "      val_loss /= len(val_loader)\n",
        "      val_acc = val_correct / val_total\n",
        "\n",
        "      # Print epoch results\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "      print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "      print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "      if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            checkpoint_path = f'vehicleclassifier_WDA_{epoch+1:02d}_{val_acc:.3f}.pth'\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f'Checkpoint saved: {checkpoint_path}')"
      ],
      "metadata": {
        "id": "KV8E04D6vL3a"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(learning_rate=0.01, class_weights=None,dropout_p=0.0):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = VehicleClassifierModel(num_classes=5,dropout_p=dropout_p)\n",
        "    model.to(device) # Move the model to the correct device\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # 1. Define the loss function with your calculated weights\n",
        "    # If you are using a GPU, make sure the weights are on the same device\n",
        "    if class_weights is not None:\n",
        "      class_weights = class_weights.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    return model, optimizer, criterion"
      ],
      "metadata": {
        "id": "GfPI2TLVvPLK"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transform\tto be applied:**\n",
        "\n",
        "1.RandomHorizontalFlip\tEffectively doubles your dataset size. A \"Left-facing  Sedan\" and a \"Right-facing Sedan\" are identical to the model's logic.\n",
        "\n",
        "2.ColorJitter\tCrucial for surveillance/outdoor data. It prevents the model from associating a specific car color with a class (e.g., \"all SUVs are black\").\n",
        "\n",
        "3.RandomResizedCrop\tHelps the model recognize a \"Pickup\" even if only the front half is visible or if the car is far away in the frame.\n",
        "\n",
        "4.RandomRotation\tUseful for security camera feeds which are often mounted at high, angled positions."
      ],
      "metadata": {
        "id": "o5XXJ9bUyurt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 224\n",
        "\n",
        "# ImageNet normalization values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "E12VwTblzfcr"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "\n",
        "    # 1. Horizontal Flip: A car is still a car if viewed from the other side.\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "    # 2. Random Rotation: Handles cars parked at slight angles or tilted cameras.\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 3. Color Jitter: Simulates different lighting (sunny vs. cloudy) and car colors.\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "\n",
        "    # 4. Random Resized Crop: Simulates the car being closer or further from the camera.\n",
        "    transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0)),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "Vu_9X8vEzO62"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = VehicleDataset(\n",
        "    data_dir='./vehicle_data_split/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "val_dataset = VehicleDataset(\n",
        "    data_dir='./vehicle_data_split/val',\n",
        "    transform=val_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "odA8-G6jzzCZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Jl7j8aJv4IzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "dropout = 0.02\n",
        "epochs = 50\n",
        "#No inner layer needed"
      ],
      "metadata": {
        "id": "sJWVYej-vbYU"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, criterion = make_model(learning_rate=learning_rate,dropout_p=dropout,class_weights=class_weights)\n",
        "train_and_val(model, optimizer, train_loader, val_loader, criterion, epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UiCBLmvmvhqo",
        "outputId": "ba2bce79-fd2d-4cc6-c088-331096c06bec"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  Train Loss: 2.2548, Train Acc: 0.4264\n",
            "  Val Loss: 1.2623, Val Acc: 0.7519\n",
            "Checkpoint saved: vehicleclassifier_WDA_01_0.752.pth\n",
            "Epoch 2/50\n",
            "  Train Loss: 0.7068, Train Acc: 0.7113\n",
            "  Val Loss: 0.6336, Val Acc: 0.7054\n",
            "Epoch 3/50\n",
            "  Train Loss: 0.7105, Train Acc: 0.7189\n",
            "  Val Loss: 0.5623, Val Acc: 0.7364\n",
            "Epoch 4/50\n",
            "  Train Loss: 0.5531, Train Acc: 0.7572\n",
            "  Val Loss: 0.3889, Val Acc: 0.8605\n",
            "Checkpoint saved: vehicleclassifier_WDA_04_0.860.pth\n",
            "Epoch 5/50\n",
            "  Train Loss: 0.6103, Train Acc: 0.7667\n",
            "  Val Loss: 0.4533, Val Acc: 0.7752\n",
            "Epoch 6/50\n",
            "  Train Loss: 0.7545, Train Acc: 0.7208\n",
            "  Val Loss: 0.4779, Val Acc: 0.7907\n",
            "Epoch 7/50\n",
            "  Train Loss: 0.6251, Train Acc: 0.7849\n",
            "  Val Loss: 0.5280, Val Acc: 0.7442\n",
            "Epoch 8/50\n",
            "  Train Loss: 0.4951, Train Acc: 0.8050\n",
            "  Val Loss: 0.4016, Val Acc: 0.8217\n",
            "Epoch 9/50\n",
            "  Train Loss: 0.5405, Train Acc: 0.7973\n",
            "  Val Loss: 0.6447, Val Acc: 0.6977\n",
            "Epoch 10/50\n",
            "  Train Loss: 0.5270, Train Acc: 0.7935\n",
            "  Val Loss: 0.6170, Val Acc: 0.7442\n",
            "Epoch 11/50\n",
            "  Train Loss: 0.5180, Train Acc: 0.8078\n",
            "  Val Loss: 0.7686, Val Acc: 0.6434\n",
            "Epoch 12/50\n",
            "  Train Loss: 0.5343, Train Acc: 0.7992\n",
            "  Val Loss: 0.9459, Val Acc: 0.6822\n",
            "Epoch 13/50\n",
            "  Train Loss: 0.5597, Train Acc: 0.8069\n",
            "  Val Loss: 0.5675, Val Acc: 0.7674\n",
            "Epoch 14/50\n",
            "  Train Loss: 0.4934, Train Acc: 0.8136\n",
            "  Val Loss: 1.1693, Val Acc: 0.8450\n",
            "Epoch 15/50\n",
            "  Train Loss: 0.5658, Train Acc: 0.8174\n",
            "  Val Loss: 0.5249, Val Acc: 0.7132\n",
            "Epoch 16/50\n",
            "  Train Loss: 0.5281, Train Acc: 0.8356\n",
            "  Val Loss: 0.6645, Val Acc: 0.7829\n",
            "Epoch 17/50\n",
            "  Train Loss: 0.4997, Train Acc: 0.8356\n",
            "  Val Loss: 0.8570, Val Acc: 0.6434\n",
            "Epoch 18/50\n",
            "  Train Loss: 0.4430, Train Acc: 0.8403\n",
            "  Val Loss: 1.0613, Val Acc: 0.7364\n",
            "Epoch 19/50\n",
            "  Train Loss: 0.4698, Train Acc: 0.8365\n",
            "  Val Loss: 0.3813, Val Acc: 0.8217\n",
            "Epoch 20/50\n",
            "  Train Loss: 0.4778, Train Acc: 0.8384\n",
            "  Val Loss: 0.6048, Val Acc: 0.8217\n",
            "Epoch 21/50\n",
            "  Train Loss: 0.4636, Train Acc: 0.8423\n",
            "  Val Loss: 0.4149, Val Acc: 0.8682\n",
            "Checkpoint saved: vehicleclassifier_WDA_21_0.868.pth\n",
            "Epoch 22/50\n",
            "  Train Loss: 0.5164, Train Acc: 0.8193\n",
            "  Val Loss: 0.3960, Val Acc: 0.8140\n",
            "Epoch 23/50\n",
            "  Train Loss: 0.4596, Train Acc: 0.8537\n",
            "  Val Loss: 0.4957, Val Acc: 0.8140\n",
            "Epoch 24/50\n",
            "  Train Loss: 0.5609, Train Acc: 0.8164\n",
            "  Val Loss: 0.7583, Val Acc: 0.7519\n",
            "Epoch 25/50\n",
            "  Train Loss: 0.3631, Train Acc: 0.8776\n",
            "  Val Loss: 0.5032, Val Acc: 0.7907\n",
            "Epoch 26/50\n",
            "  Train Loss: 0.3585, Train Acc: 0.8604\n",
            "  Val Loss: 0.3985, Val Acc: 0.8372\n",
            "Epoch 27/50\n",
            "  Train Loss: 0.4404, Train Acc: 0.8509\n",
            "  Val Loss: 0.8848, Val Acc: 0.6512\n",
            "Epoch 28/50\n",
            "  Train Loss: 0.4949, Train Acc: 0.8126\n",
            "  Val Loss: 0.4564, Val Acc: 0.7907\n",
            "Epoch 29/50\n",
            "  Train Loss: 0.4553, Train Acc: 0.8489\n",
            "  Val Loss: 0.4661, Val Acc: 0.8217\n",
            "Epoch 30/50\n",
            "  Train Loss: 0.3834, Train Acc: 0.8719\n",
            "  Val Loss: 0.6071, Val Acc: 0.7519\n",
            "Epoch 31/50\n",
            "  Train Loss: 0.4206, Train Acc: 0.8662\n",
            "  Val Loss: 0.3732, Val Acc: 0.8295\n",
            "Epoch 32/50\n",
            "  Train Loss: 0.7602, Train Acc: 0.7878\n",
            "  Val Loss: 0.3530, Val Acc: 0.8992\n",
            "Checkpoint saved: vehicleclassifier_WDA_32_0.899.pth\n",
            "Epoch 33/50\n",
            "  Train Loss: 0.4459, Train Acc: 0.8633\n",
            "  Val Loss: 0.5020, Val Acc: 0.8062\n",
            "Epoch 34/50\n",
            "  Train Loss: 0.3091, Train Acc: 0.8748\n",
            "  Val Loss: 0.4300, Val Acc: 0.7829\n",
            "Epoch 35/50\n",
            "  Train Loss: 0.4336, Train Acc: 0.8518\n",
            "  Val Loss: 0.6261, Val Acc: 0.8062\n",
            "Epoch 36/50\n",
            "  Train Loss: 0.4479, Train Acc: 0.8394\n",
            "  Val Loss: 0.4993, Val Acc: 0.8062\n",
            "Epoch 37/50\n",
            "  Train Loss: 0.4886, Train Acc: 0.8623\n",
            "  Val Loss: 0.6634, Val Acc: 0.8527\n",
            "Epoch 38/50\n",
            "  Train Loss: 0.3223, Train Acc: 0.8939\n",
            "  Val Loss: 0.5406, Val Acc: 0.7829\n",
            "Epoch 39/50\n",
            "  Train Loss: 0.4638, Train Acc: 0.8518\n",
            "  Val Loss: 0.4009, Val Acc: 0.8295\n",
            "Epoch 40/50\n",
            "  Train Loss: 0.4377, Train Acc: 0.8556\n",
            "  Val Loss: 0.4873, Val Acc: 0.7442\n",
            "Epoch 41/50\n",
            "  Train Loss: 0.4253, Train Acc: 0.8528\n",
            "  Val Loss: 0.4958, Val Acc: 0.7984\n",
            "Epoch 42/50\n",
            "  Train Loss: 0.4912, Train Acc: 0.8413\n",
            "  Val Loss: 0.8360, Val Acc: 0.6744\n",
            "Epoch 43/50\n",
            "  Train Loss: 0.3737, Train Acc: 0.8614\n",
            "  Val Loss: 0.4309, Val Acc: 0.8450\n",
            "Epoch 44/50\n",
            "  Train Loss: 0.4187, Train Acc: 0.8690\n",
            "  Val Loss: 0.5784, Val Acc: 0.7519\n",
            "Epoch 45/50\n",
            "  Train Loss: 0.4132, Train Acc: 0.8681\n",
            "  Val Loss: 0.5001, Val Acc: 0.7984\n",
            "Epoch 46/50\n",
            "  Train Loss: 0.3604, Train Acc: 0.8652\n",
            "  Val Loss: 0.3384, Val Acc: 0.8450\n",
            "Epoch 47/50\n",
            "  Train Loss: 0.4533, Train Acc: 0.8642\n",
            "  Val Loss: 0.6292, Val Acc: 0.7442\n",
            "Epoch 48/50\n",
            "  Train Loss: 0.5479, Train Acc: 0.8442\n",
            "  Val Loss: 0.3722, Val Acc: 0.8605\n",
            "Epoch 49/50\n",
            "  Train Loss: 0.6453, Train Acc: 0.8279\n",
            "  Val Loss: 0.2970, Val Acc: 0.8837\n",
            "Epoch 50/50\n",
            "  Train Loss: 0.5167, Train Acc: 0.8442\n",
            "  Val Loss: 0.7875, Val Acc: 0.8062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the non-augmented model showed a higher peak accuracy (92%), the model trained with Data Augmentation demonstrated superior generalization and a lower cross-entropy loss (89% with less Validation loss), making it the more reliable choice for practical vehicle classification.\n",
        "Hence, we will use the model with Data augmentation having 89% accuracy"
      ],
      "metadata": {
        "id": "ua4dmUPh7aRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Model: vehicleclassifier_WDA_32_0.899.pth\n",
        "\n",
        "Let's delete all the other models and convert this model to onnx for inference and serving."
      ],
      "metadata": {
        "id": "nCFZ0a3c8fnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IUWQibYu9GBq",
        "outputId": "5306d97d-f20f-48c1-b00b-1c99a9909035"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-157           [-1, 1280, 1, 1]               0\n",
            "         Dropout-158                 [-1, 1280]               0\n",
            "          Linear-159                    [-1, 5]           6,405\n",
            "================================================================\n",
            "Total params: 2,230,277\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 2,223,872\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.87\n",
            "Params size (MB): 8.51\n",
            "Estimated Total Size (MB): 161.95\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"/content/vehicleclassifier_WDA_32_0.899.pth\""
      ],
      "metadata": {
        "id": "utwPNxJs9gDH"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VehicleClassifierModel(num_classes=5,dropout_p=0.2)\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4ftUrqKm-PhK",
        "outputId": "6eb6ad75-0279-4331-dc7f-ff961db3771d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VehicleClassifierModel(\n",
              "  (base_model): MobileNetV2(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU6(inplace=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (16): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (17): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (18): Conv2dNormActivation(\n",
              "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (classifier): Identity()\n",
              "  )\n",
              "  (global_avg_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (output_layer): Linear(in_features=1280, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test images for thailand vehices:\n",
        "img1: https://www.shutterstock.com/shutterstock/photos/2670301995/display_1500/stock-photo-kamphaeng-phet-thailand-august-the-ranger-double-cab-sport-l-turbo-at-2670301995.jpg\n",
        "\n",
        "img2 :https://www.shutterstock.com/shutterstock/photos/2615949409/display_1500/stock-photo-bangkok-thailand-apr-tesla-model-electric-car-red-color-2615949409.jpg\n",
        "\n",
        "img3: https://www.shutterstock.com/shutterstock/photos/2143689667/display_1500/stock-photo-paris-france-january-bmw-m-i-xdrive-blue-car-isolated-on-white-background-d-2143689667.jpg"
      ],
      "metadata": {
        "id": "A01Ega84C_RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --user-agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\" https://www.shutterstock.com/shutterstock/photos/2143689667/display_1500/stock-photo-paris-france-january-bmw-m-i-xdrive-blue-car-isolated-on-white-background-d-2143689667.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dZyr6hCk_-A8",
        "outputId": "2087cffd-0eb1-44b8-dc3a-7780bdc10bcc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-22 12:36:48--  https://www.shutterstock.com/shutterstock/photos/2143689667/display_1500/stock-photo-paris-france-january-bmw-m-i-xdrive-blue-car-isolated-on-white-background-d-2143689667.jpg\n",
            "Resolving www.shutterstock.com (www.shutterstock.com)... 65.8.76.24, 65.8.76.57, 65.8.76.85, ...\n",
            "Connecting to www.shutterstock.com (www.shutterstock.com)|65.8.76.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180253 (176K) [image/jpeg]\n",
            "Saving to: ‘stock-photo-paris-france-january-bmw-m-i-xdrive-blue-car-isolated-on-white-background-d-2143689667.jpg’\n",
            "\n",
            "stock-photo-paris-f 100%[===================>] 176.03K   282KB/s    in 0.6s    \n",
            "\n",
            "2025-12-22 12:36:50 (282 KB/s) - ‘stock-photo-paris-france-january-bmw-m-i-xdrive-blue-car-isolated-on-white-background-d-2143689667.jpg’ saved [180253/180253]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img= \"/content/stock-photo-paris-france-january-bmw-m-i-xdrive-blue-car-isolated-on-white-background-d-2143689667.jpg\""
      ],
      "metadata": {
        "id": "HHNobLLg-hmB"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = val_transforms(Image.open(test_img))\n",
        "batch_t = torch.unsqueeze(x, 0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(batch_t)"
      ],
      "metadata": {
        "id": "-JaOfRCU-kEl"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['hatchback', 'motorcycle', 'pickup', 'sedan', 'suv']"
      ],
      "metadata": {
        "id": "cAHs1AuI-2CK"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(classes, output[0].to('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bwidLlm-l9i",
        "outputId": "f583e99a-0027-4c03-b9df-c18838802ddc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hatchback': tensor(7.8249),\n",
              " 'motorcycle': tensor(-7.6293),\n",
              " 'pickup': tensor(3.0024),\n",
              " 'sedan': tensor(2.9588),\n",
              " 'suv': tensor(3.8775)}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "! pip install onnxscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cs-LG1z_-oK-",
        "outputId": "f659dc2a-f5dc-4702-f61c-7a595cfeddf9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.20.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n",
            "Successfully installed onnx_ir-0.1.13 onnxscript-0.5.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_path = \"vehicle_identifier_mobilenet_v2.onnx\"\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    onnx_path,\n",
        "    verbose=True,\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={\n",
        "        'input': {0: 'batch_size'},\n",
        "        'output': {0: 'batch_size'}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O5SC8yShELDC",
        "outputId": "fb48870c-23f3-4aad-ce53-fb634a05b16d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3348169609.py:6: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `VehicleClassifierModel([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `VehicleClassifierModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 105 of general pattern rewrite rules.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 20},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.0+cu126',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"input\"<FLOAT,[s77,3,224,224]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"output\"<FLOAT,[s77,5]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"base_model.features.0.0.weight\"<FLOAT,[32,3,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.1.conv.0.0.weight\"<FLOAT,[32,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.1.conv.1.weight\"<FLOAT,[16,32,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.2.conv.0.0.weight\"<FLOAT,[96,16,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.2.conv.1.0.weight\"<FLOAT,[96,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.2.conv.2.weight\"<FLOAT,[24,96,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.3.conv.0.0.weight\"<FLOAT,[144,24,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.3.conv.1.0.weight\"<FLOAT,[144,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.3.conv.2.weight\"<FLOAT,[24,144,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.4.conv.0.0.weight\"<FLOAT,[144,24,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.4.conv.1.0.weight\"<FLOAT,[144,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.4.conv.2.weight\"<FLOAT,[32,144,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.5.conv.0.0.weight\"<FLOAT,[192,32,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.5.conv.1.0.weight\"<FLOAT,[192,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.5.conv.2.weight\"<FLOAT,[32,192,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.6.conv.0.0.weight\"<FLOAT,[192,32,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.6.conv.1.0.weight\"<FLOAT,[192,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.6.conv.2.weight\"<FLOAT,[32,192,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.7.conv.0.0.weight\"<FLOAT,[192,32,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.7.conv.1.0.weight\"<FLOAT,[192,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.7.conv.2.weight\"<FLOAT,[64,192,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.8.conv.0.0.weight\"<FLOAT,[384,64,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.8.conv.1.0.weight\"<FLOAT,[384,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.8.conv.2.weight\"<FLOAT,[64,384,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.9.conv.0.0.weight\"<FLOAT,[384,64,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.9.conv.1.0.weight\"<FLOAT,[384,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.9.conv.2.weight\"<FLOAT,[64,384,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.10.conv.0.0.weight\"<FLOAT,[384,64,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.10.conv.1.0.weight\"<FLOAT,[384,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.10.conv.2.weight\"<FLOAT,[64,384,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.11.conv.0.0.weight\"<FLOAT,[384,64,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.11.conv.1.0.weight\"<FLOAT,[384,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.11.conv.2.weight\"<FLOAT,[96,384,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.12.conv.0.0.weight\"<FLOAT,[576,96,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.12.conv.1.0.weight\"<FLOAT,[576,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.12.conv.2.weight\"<FLOAT,[96,576,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.13.conv.0.0.weight\"<FLOAT,[576,96,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.13.conv.1.0.weight\"<FLOAT,[576,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.13.conv.2.weight\"<FLOAT,[96,576,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.14.conv.0.0.weight\"<FLOAT,[576,96,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.14.conv.1.0.weight\"<FLOAT,[576,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.14.conv.2.weight\"<FLOAT,[160,576,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.15.conv.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.15.conv.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.15.conv.2.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.16.conv.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.16.conv.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.16.conv.2.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.17.conv.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.17.conv.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
              "                %\"base_model.features.17.conv.2.weight\"<FLOAT,[320,960,1,1]>{Tensor(...)},\n",
              "                %\"base_model.features.18.0.weight\"<FLOAT,[1280,320,1,1]>{Tensor(...)},\n",
              "                %\"output_layer.weight\"<FLOAT,[5,1280]>{TorchTensor(...)},\n",
              "                %\"output_layer.bias\"<FLOAT,[5]>{TorchTensor<FLOAT,[5]>(Parameter containing: tensor([ 0.0187, -0.0862,  0.0082,  0.0380, -0.0271], device='cuda:0', requires_grad=True), name='output_layer.bias')},\n",
              "                %\"min_val_cast\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(0., dtype=float32), name='min_val_cast')},\n",
              "                %\"max_val_cast\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(6., dtype=float32), name='max_val_cast')},\n",
              "                %\"val_474\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_474')},\n",
              "                %\"base_model.features.0.0.weight_bias\"<FLOAT,[32]>{Tensor(...)},\n",
              "                %\"base_model.features.1.conv.0.0.weight_bias\"<FLOAT,[32]>{Tensor(...)},\n",
              "                %\"base_model.features.1.conv.1.weight_bias\"<FLOAT,[16]>{Tensor(...)},\n",
              "                %\"base_model.features.2.conv.0.0.weight_bias\"<FLOAT,[96]>{Tensor(...)},\n",
              "                %\"base_model.features.2.conv.1.0.weight_bias\"<FLOAT,[96]>{Tensor(...)},\n",
              "                %\"base_model.features.2.conv.2.weight_bias\"<FLOAT,[24]>{Tensor(...)},\n",
              "                %\"base_model.features.3.conv.0.0.weight_bias\"<FLOAT,[144]>{Tensor(...)},\n",
              "                %\"base_model.features.3.conv.1.0.weight_bias\"<FLOAT,[144]>{Tensor(...)},\n",
              "                %\"base_model.features.3.conv.2.weight_bias\"<FLOAT,[24]>{Tensor(...)},\n",
              "                %\"base_model.features.4.conv.0.0.weight_bias\"<FLOAT,[144]>{Tensor(...)},\n",
              "                %\"base_model.features.4.conv.1.0.weight_bias\"<FLOAT,[144]>{Tensor(...)},\n",
              "                %\"base_model.features.4.conv.2.weight_bias\"<FLOAT,[32]>{Tensor(...)},\n",
              "                %\"base_model.features.5.conv.0.0.weight_bias\"<FLOAT,[192]>{Tensor(...)},\n",
              "                %\"base_model.features.5.conv.1.0.weight_bias\"<FLOAT,[192]>{Tensor(...)},\n",
              "                %\"base_model.features.5.conv.2.weight_bias\"<FLOAT,[32]>{Tensor(...)},\n",
              "                %\"base_model.features.6.conv.0.0.weight_bias\"<FLOAT,[192]>{Tensor(...)},\n",
              "                %\"base_model.features.6.conv.1.0.weight_bias\"<FLOAT,[192]>{Tensor(...)},\n",
              "                %\"base_model.features.6.conv.2.weight_bias\"<FLOAT,[32]>{Tensor(...)},\n",
              "                %\"base_model.features.7.conv.0.0.weight_bias\"<FLOAT,[192]>{Tensor(...)},\n",
              "                %\"base_model.features.7.conv.1.0.weight_bias\"<FLOAT,[192]>{Tensor(...)},\n",
              "                %\"base_model.features.7.conv.2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"base_model.features.8.conv.0.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.8.conv.1.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.8.conv.2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"base_model.features.9.conv.0.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.9.conv.1.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.9.conv.2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"base_model.features.10.conv.0.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.10.conv.1.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.10.conv.2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"base_model.features.11.conv.0.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.11.conv.1.0.weight_bias\"<FLOAT,[384]>{Tensor(...)},\n",
              "                %\"base_model.features.11.conv.2.weight_bias\"<FLOAT,[96]>{Tensor(...)},\n",
              "                %\"base_model.features.12.conv.0.0.weight_bias\"<FLOAT,[576]>{Tensor(...)},\n",
              "                %\"base_model.features.12.conv.1.0.weight_bias\"<FLOAT,[576]>{Tensor(...)},\n",
              "                %\"base_model.features.12.conv.2.weight_bias\"<FLOAT,[96]>{Tensor(...)},\n",
              "                %\"base_model.features.13.conv.0.0.weight_bias\"<FLOAT,[576]>{Tensor(...)},\n",
              "                %\"base_model.features.13.conv.1.0.weight_bias\"<FLOAT,[576]>{Tensor(...)},\n",
              "                %\"base_model.features.13.conv.2.weight_bias\"<FLOAT,[96]>{Tensor(...)},\n",
              "                %\"base_model.features.14.conv.0.0.weight_bias\"<FLOAT,[576]>{Tensor(...)},\n",
              "                %\"base_model.features.14.conv.1.0.weight_bias\"<FLOAT,[576]>{Tensor(...)},\n",
              "                %\"base_model.features.14.conv.2.weight_bias\"<FLOAT,[160]>{Tensor(...)},\n",
              "                %\"base_model.features.15.conv.0.0.weight_bias\"<FLOAT,[960]>{Tensor(...)},\n",
              "                %\"base_model.features.15.conv.1.0.weight_bias\"<FLOAT,[960]>{Tensor(...)},\n",
              "                %\"base_model.features.15.conv.2.weight_bias\"<FLOAT,[160]>{Tensor(...)},\n",
              "                %\"base_model.features.16.conv.0.0.weight_bias\"<FLOAT,[960]>{Tensor(...)},\n",
              "                %\"base_model.features.16.conv.1.0.weight_bias\"<FLOAT,[960]>{Tensor(...)},\n",
              "                %\"base_model.features.16.conv.2.weight_bias\"<FLOAT,[160]>{Tensor(...)},\n",
              "                %\"base_model.features.17.conv.0.0.weight_bias\"<FLOAT,[960]>{Tensor(...)},\n",
              "                %\"base_model.features.17.conv.1.0.weight_bias\"<FLOAT,[960]>{Tensor(...)},\n",
              "                %\"base_model.features.17.conv.2.weight_bias\"<FLOAT,[320]>{Tensor(...)},\n",
              "                %\"base_model.features.18.0.weight_bias\"<FLOAT,[1280]>{Tensor(...)},\n",
              "                %\"val_477\"<INT64,[1]>{Tensor<INT64,[1]>(array([1280]), name='val_477')}\n",
              "            ),\n",
              "        ) {\n",
              "              0 |  # node_Shape_0\n",
              "                   %\"val_0\"<INT64,[1]> ⬅️ ::Shape(%\"input\") {end=1, start=0}\n",
              "              1 |  # node_Conv_706\n",
              "                   %\"getitem\"<FLOAT,[s77,32,112,112]> ⬅️ ::Conv(%\"input\", %\"base_model.features.0.0.weight\"{...}, %\"base_model.features.0.0.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "              2 |  # n4\n",
              "                   %\"hardtanh\"<FLOAT,[s77,32,112,112]> ⬅️ ::Clip(%\"getitem\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "              3 |  # node_Conv_708\n",
              "                   %\"getitem_3\"<FLOAT,[s77,32,112,112]> ⬅️ ::Conv(%\"hardtanh\", %\"base_model.features.1.conv.0.0.weight\"{...}, %\"base_model.features.1.conv.0.0.weight_bias\"{...}) {group=32, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              4 |  # n4_2\n",
              "                   %\"hardtanh_1\"<FLOAT,[s77,32,112,112]> ⬅️ ::Clip(%\"getitem_3\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "              5 |  # node_Conv_710\n",
              "                   %\"getitem_6\"<FLOAT,[s77,16,112,112]> ⬅️ ::Conv(%\"hardtanh_1\", %\"base_model.features.1.conv.1.weight\"{...}, %\"base_model.features.1.conv.1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              6 |  # node_Conv_712\n",
              "                   %\"getitem_9\"<FLOAT,[s77,96,112,112]> ⬅️ ::Conv(%\"getitem_6\", %\"base_model.features.2.conv.0.0.weight\"{...}, %\"base_model.features.2.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              7 |  # n4_3\n",
              "                   %\"hardtanh_2\"<FLOAT,[s77,96,112,112]> ⬅️ ::Clip(%\"getitem_9\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "              8 |  # node_Conv_714\n",
              "                   %\"getitem_12\"<FLOAT,[s77,96,56,56]> ⬅️ ::Conv(%\"hardtanh_2\", %\"base_model.features.2.conv.1.0.weight\"{...}, %\"base_model.features.2.conv.1.0.weight_bias\"{...}) {group=96, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "              9 |  # n4_4\n",
              "                   %\"hardtanh_3\"<FLOAT,[s77,96,56,56]> ⬅️ ::Clip(%\"getitem_12\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             10 |  # node_Conv_716\n",
              "                   %\"getitem_15\"<FLOAT,[s77,24,56,56]> ⬅️ ::Conv(%\"hardtanh_3\", %\"base_model.features.2.conv.2.weight\"{...}, %\"base_model.features.2.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             11 |  # node_Conv_718\n",
              "                   %\"getitem_18\"<FLOAT,[s77,144,56,56]> ⬅️ ::Conv(%\"getitem_15\", %\"base_model.features.3.conv.0.0.weight\"{...}, %\"base_model.features.3.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             12 |  # n4_5\n",
              "                   %\"hardtanh_4\"<FLOAT,[s77,144,56,56]> ⬅️ ::Clip(%\"getitem_18\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             13 |  # node_Conv_720\n",
              "                   %\"getitem_21\"<FLOAT,[s77,144,56,56]> ⬅️ ::Conv(%\"hardtanh_4\", %\"base_model.features.3.conv.1.0.weight\"{...}, %\"base_model.features.3.conv.1.0.weight_bias\"{...}) {group=144, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             14 |  # n4_6\n",
              "                   %\"hardtanh_5\"<FLOAT,[s77,144,56,56]> ⬅️ ::Clip(%\"getitem_21\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             15 |  # node_Conv_722\n",
              "                   %\"getitem_24\"<FLOAT,[s77,24,56,56]> ⬅️ ::Conv(%\"hardtanh_5\", %\"base_model.features.3.conv.2.weight\"{...}, %\"base_model.features.3.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             16 |  # node_add_247\n",
              "                   %\"add_247\"<FLOAT,[s77,24,56,56]> ⬅️ ::Add(%\"getitem_15\", %\"getitem_24\")\n",
              "             17 |  # node_Conv_724\n",
              "                   %\"getitem_27\"<FLOAT,[s77,144,56,56]> ⬅️ ::Conv(%\"add_247\", %\"base_model.features.4.conv.0.0.weight\"{...}, %\"base_model.features.4.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             18 |  # n4_7\n",
              "                   %\"hardtanh_6\"<FLOAT,[s77,144,56,56]> ⬅️ ::Clip(%\"getitem_27\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             19 |  # node_Conv_726\n",
              "                   %\"getitem_30\"<FLOAT,[s77,144,28,28]> ⬅️ ::Conv(%\"hardtanh_6\", %\"base_model.features.4.conv.1.0.weight\"{...}, %\"base_model.features.4.conv.1.0.weight_bias\"{...}) {group=144, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             20 |  # n4_8\n",
              "                   %\"hardtanh_7\"<FLOAT,[s77,144,28,28]> ⬅️ ::Clip(%\"getitem_30\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             21 |  # node_Conv_728\n",
              "                   %\"getitem_33\"<FLOAT,[s77,32,28,28]> ⬅️ ::Conv(%\"hardtanh_7\", %\"base_model.features.4.conv.2.weight\"{...}, %\"base_model.features.4.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             22 |  # node_Conv_730\n",
              "                   %\"getitem_36\"<FLOAT,[s77,192,28,28]> ⬅️ ::Conv(%\"getitem_33\", %\"base_model.features.5.conv.0.0.weight\"{...}, %\"base_model.features.5.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             23 |  # n4_9\n",
              "                   %\"hardtanh_8\"<FLOAT,[s77,192,28,28]> ⬅️ ::Clip(%\"getitem_36\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             24 |  # node_Conv_732\n",
              "                   %\"getitem_39\"<FLOAT,[s77,192,28,28]> ⬅️ ::Conv(%\"hardtanh_8\", %\"base_model.features.5.conv.1.0.weight\"{...}, %\"base_model.features.5.conv.1.0.weight_bias\"{...}) {group=192, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             25 |  # n4_10\n",
              "                   %\"hardtanh_9\"<FLOAT,[s77,192,28,28]> ⬅️ ::Clip(%\"getitem_39\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             26 |  # node_Conv_734\n",
              "                   %\"getitem_42\"<FLOAT,[s77,32,28,28]> ⬅️ ::Conv(%\"hardtanh_9\", %\"base_model.features.5.conv.2.weight\"{...}, %\"base_model.features.5.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             27 |  # node_add_385\n",
              "                   %\"add_385\"<FLOAT,[s77,32,28,28]> ⬅️ ::Add(%\"getitem_33\", %\"getitem_42\")\n",
              "             28 |  # node_Conv_736\n",
              "                   %\"getitem_45\"<FLOAT,[s77,192,28,28]> ⬅️ ::Conv(%\"add_385\", %\"base_model.features.6.conv.0.0.weight\"{...}, %\"base_model.features.6.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             29 |  # n4_11\n",
              "                   %\"hardtanh_10\"<FLOAT,[s77,192,28,28]> ⬅️ ::Clip(%\"getitem_45\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             30 |  # node_Conv_738\n",
              "                   %\"getitem_48\"<FLOAT,[s77,192,28,28]> ⬅️ ::Conv(%\"hardtanh_10\", %\"base_model.features.6.conv.1.0.weight\"{...}, %\"base_model.features.6.conv.1.0.weight_bias\"{...}) {group=192, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             31 |  # n4_12\n",
              "                   %\"hardtanh_11\"<FLOAT,[s77,192,28,28]> ⬅️ ::Clip(%\"getitem_48\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             32 |  # node_Conv_740\n",
              "                   %\"getitem_51\"<FLOAT,[s77,32,28,28]> ⬅️ ::Conv(%\"hardtanh_11\", %\"base_model.features.6.conv.2.weight\"{...}, %\"base_model.features.6.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             33 |  # node_add_457\n",
              "                   %\"add_457\"<FLOAT,[s77,32,28,28]> ⬅️ ::Add(%\"add_385\", %\"getitem_51\")\n",
              "             34 |  # node_Conv_742\n",
              "                   %\"getitem_54\"<FLOAT,[s77,192,28,28]> ⬅️ ::Conv(%\"add_457\", %\"base_model.features.7.conv.0.0.weight\"{...}, %\"base_model.features.7.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             35 |  # n4_13\n",
              "                   %\"hardtanh_12\"<FLOAT,[s77,192,28,28]> ⬅️ ::Clip(%\"getitem_54\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             36 |  # node_Conv_744\n",
              "                   %\"getitem_57\"<FLOAT,[s77,192,14,14]> ⬅️ ::Conv(%\"hardtanh_12\", %\"base_model.features.7.conv.1.0.weight\"{...}, %\"base_model.features.7.conv.1.0.weight_bias\"{...}) {group=192, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             37 |  # n4_14\n",
              "                   %\"hardtanh_13\"<FLOAT,[s77,192,14,14]> ⬅️ ::Clip(%\"getitem_57\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             38 |  # node_Conv_746\n",
              "                   %\"getitem_60\"<FLOAT,[s77,64,14,14]> ⬅️ ::Conv(%\"hardtanh_13\", %\"base_model.features.7.conv.2.weight\"{...}, %\"base_model.features.7.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             39 |  # node_Conv_748\n",
              "                   %\"getitem_63\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"getitem_60\", %\"base_model.features.8.conv.0.0.weight\"{...}, %\"base_model.features.8.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             40 |  # n4_15\n",
              "                   %\"hardtanh_14\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_63\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             41 |  # node_Conv_750\n",
              "                   %\"getitem_66\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"hardtanh_14\", %\"base_model.features.8.conv.1.0.weight\"{...}, %\"base_model.features.8.conv.1.0.weight_bias\"{...}) {group=384, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             42 |  # n4_16\n",
              "                   %\"hardtanh_15\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_66\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             43 |  # node_Conv_752\n",
              "                   %\"getitem_69\"<FLOAT,[s77,64,14,14]> ⬅️ ::Conv(%\"hardtanh_15\", %\"base_model.features.8.conv.2.weight\"{...}, %\"base_model.features.8.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             44 |  # node_add_595\n",
              "                   %\"add_595\"<FLOAT,[s77,64,14,14]> ⬅️ ::Add(%\"getitem_60\", %\"getitem_69\")\n",
              "             45 |  # node_Conv_754\n",
              "                   %\"getitem_72\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"add_595\", %\"base_model.features.9.conv.0.0.weight\"{...}, %\"base_model.features.9.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             46 |  # n4_17\n",
              "                   %\"hardtanh_16\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_72\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             47 |  # node_Conv_756\n",
              "                   %\"getitem_75\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"hardtanh_16\", %\"base_model.features.9.conv.1.0.weight\"{...}, %\"base_model.features.9.conv.1.0.weight_bias\"{...}) {group=384, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             48 |  # n4_18\n",
              "                   %\"hardtanh_17\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_75\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             49 |  # node_Conv_758\n",
              "                   %\"getitem_78\"<FLOAT,[s77,64,14,14]> ⬅️ ::Conv(%\"hardtanh_17\", %\"base_model.features.9.conv.2.weight\"{...}, %\"base_model.features.9.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             50 |  # node_add_667\n",
              "                   %\"add_667\"<FLOAT,[s77,64,14,14]> ⬅️ ::Add(%\"add_595\", %\"getitem_78\")\n",
              "             51 |  # node_Conv_760\n",
              "                   %\"getitem_81\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"add_667\", %\"base_model.features.10.conv.0.0.weight\"{...}, %\"base_model.features.10.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             52 |  # n4_19\n",
              "                   %\"hardtanh_18\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_81\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             53 |  # node_Conv_762\n",
              "                   %\"getitem_84\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"hardtanh_18\", %\"base_model.features.10.conv.1.0.weight\"{...}, %\"base_model.features.10.conv.1.0.weight_bias\"{...}) {group=384, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             54 |  # n4_20\n",
              "                   %\"hardtanh_19\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_84\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             55 |  # node_Conv_764\n",
              "                   %\"getitem_87\"<FLOAT,[s77,64,14,14]> ⬅️ ::Conv(%\"hardtanh_19\", %\"base_model.features.10.conv.2.weight\"{...}, %\"base_model.features.10.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             56 |  # node_add_739\n",
              "                   %\"add_739\"<FLOAT,[s77,64,14,14]> ⬅️ ::Add(%\"add_667\", %\"getitem_87\")\n",
              "             57 |  # node_Conv_766\n",
              "                   %\"getitem_90\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"add_739\", %\"base_model.features.11.conv.0.0.weight\"{...}, %\"base_model.features.11.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             58 |  # n4_21\n",
              "                   %\"hardtanh_20\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_90\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             59 |  # node_Conv_768\n",
              "                   %\"getitem_93\"<FLOAT,[s77,384,14,14]> ⬅️ ::Conv(%\"hardtanh_20\", %\"base_model.features.11.conv.1.0.weight\"{...}, %\"base_model.features.11.conv.1.0.weight_bias\"{...}) {group=384, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             60 |  # n4_22\n",
              "                   %\"hardtanh_21\"<FLOAT,[s77,384,14,14]> ⬅️ ::Clip(%\"getitem_93\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             61 |  # node_Conv_770\n",
              "                   %\"getitem_96\"<FLOAT,[s77,96,14,14]> ⬅️ ::Conv(%\"hardtanh_21\", %\"base_model.features.11.conv.2.weight\"{...}, %\"base_model.features.11.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             62 |  # node_Conv_772\n",
              "                   %\"getitem_99\"<FLOAT,[s77,576,14,14]> ⬅️ ::Conv(%\"getitem_96\", %\"base_model.features.12.conv.0.0.weight\"{...}, %\"base_model.features.12.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             63 |  # n4_23\n",
              "                   %\"hardtanh_22\"<FLOAT,[s77,576,14,14]> ⬅️ ::Clip(%\"getitem_99\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             64 |  # node_Conv_774\n",
              "                   %\"getitem_102\"<FLOAT,[s77,576,14,14]> ⬅️ ::Conv(%\"hardtanh_22\", %\"base_model.features.12.conv.1.0.weight\"{...}, %\"base_model.features.12.conv.1.0.weight_bias\"{...}) {group=576, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             65 |  # n4_24\n",
              "                   %\"hardtanh_23\"<FLOAT,[s77,576,14,14]> ⬅️ ::Clip(%\"getitem_102\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             66 |  # node_Conv_776\n",
              "                   %\"getitem_105\"<FLOAT,[s77,96,14,14]> ⬅️ ::Conv(%\"hardtanh_23\", %\"base_model.features.12.conv.2.weight\"{...}, %\"base_model.features.12.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             67 |  # node_add_877\n",
              "                   %\"add_877\"<FLOAT,[s77,96,14,14]> ⬅️ ::Add(%\"getitem_96\", %\"getitem_105\")\n",
              "             68 |  # node_Conv_778\n",
              "                   %\"getitem_108\"<FLOAT,[s77,576,14,14]> ⬅️ ::Conv(%\"add_877\", %\"base_model.features.13.conv.0.0.weight\"{...}, %\"base_model.features.13.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             69 |  # n4_25\n",
              "                   %\"hardtanh_24\"<FLOAT,[s77,576,14,14]> ⬅️ ::Clip(%\"getitem_108\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             70 |  # node_Conv_780\n",
              "                   %\"getitem_111\"<FLOAT,[s77,576,14,14]> ⬅️ ::Conv(%\"hardtanh_24\", %\"base_model.features.13.conv.1.0.weight\"{...}, %\"base_model.features.13.conv.1.0.weight_bias\"{...}) {group=576, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             71 |  # n4_26\n",
              "                   %\"hardtanh_25\"<FLOAT,[s77,576,14,14]> ⬅️ ::Clip(%\"getitem_111\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             72 |  # node_Conv_782\n",
              "                   %\"getitem_114\"<FLOAT,[s77,96,14,14]> ⬅️ ::Conv(%\"hardtanh_25\", %\"base_model.features.13.conv.2.weight\"{...}, %\"base_model.features.13.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             73 |  # node_add_949\n",
              "                   %\"add_949\"<FLOAT,[s77,96,14,14]> ⬅️ ::Add(%\"add_877\", %\"getitem_114\")\n",
              "             74 |  # node_Conv_784\n",
              "                   %\"getitem_117\"<FLOAT,[s77,576,14,14]> ⬅️ ::Conv(%\"add_949\", %\"base_model.features.14.conv.0.0.weight\"{...}, %\"base_model.features.14.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             75 |  # n4_27\n",
              "                   %\"hardtanh_26\"<FLOAT,[s77,576,14,14]> ⬅️ ::Clip(%\"getitem_117\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             76 |  # node_Conv_786\n",
              "                   %\"getitem_120\"<FLOAT,[s77,576,7,7]> ⬅️ ::Conv(%\"hardtanh_26\", %\"base_model.features.14.conv.1.0.weight\"{...}, %\"base_model.features.14.conv.1.0.weight_bias\"{...}) {group=576, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             77 |  # n4_28\n",
              "                   %\"hardtanh_27\"<FLOAT,[s77,576,7,7]> ⬅️ ::Clip(%\"getitem_120\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             78 |  # node_Conv_788\n",
              "                   %\"getitem_123\"<FLOAT,[s77,160,7,7]> ⬅️ ::Conv(%\"hardtanh_27\", %\"base_model.features.14.conv.2.weight\"{...}, %\"base_model.features.14.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             79 |  # node_Conv_790\n",
              "                   %\"getitem_126\"<FLOAT,[s77,960,7,7]> ⬅️ ::Conv(%\"getitem_123\", %\"base_model.features.15.conv.0.0.weight\"{...}, %\"base_model.features.15.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             80 |  # n4_29\n",
              "                   %\"hardtanh_28\"<FLOAT,[s77,960,7,7]> ⬅️ ::Clip(%\"getitem_126\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             81 |  # node_Conv_792\n",
              "                   %\"getitem_129\"<FLOAT,[s77,960,7,7]> ⬅️ ::Conv(%\"hardtanh_28\", %\"base_model.features.15.conv.1.0.weight\"{...}, %\"base_model.features.15.conv.1.0.weight_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             82 |  # n4_30\n",
              "                   %\"hardtanh_29\"<FLOAT,[s77,960,7,7]> ⬅️ ::Clip(%\"getitem_129\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             83 |  # node_Conv_794\n",
              "                   %\"getitem_132\"<FLOAT,[s77,160,7,7]> ⬅️ ::Conv(%\"hardtanh_29\", %\"base_model.features.15.conv.2.weight\"{...}, %\"base_model.features.15.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             84 |  # node_add_1087\n",
              "                   %\"add_1087\"<FLOAT,[s77,160,7,7]> ⬅️ ::Add(%\"getitem_123\", %\"getitem_132\")\n",
              "             85 |  # node_Conv_796\n",
              "                   %\"getitem_135\"<FLOAT,[s77,960,7,7]> ⬅️ ::Conv(%\"add_1087\", %\"base_model.features.16.conv.0.0.weight\"{...}, %\"base_model.features.16.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             86 |  # n4_31\n",
              "                   %\"hardtanh_30\"<FLOAT,[s77,960,7,7]> ⬅️ ::Clip(%\"getitem_135\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             87 |  # node_Conv_798\n",
              "                   %\"getitem_138\"<FLOAT,[s77,960,7,7]> ⬅️ ::Conv(%\"hardtanh_30\", %\"base_model.features.16.conv.1.0.weight\"{...}, %\"base_model.features.16.conv.1.0.weight_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             88 |  # n4_32\n",
              "                   %\"hardtanh_31\"<FLOAT,[s77,960,7,7]> ⬅️ ::Clip(%\"getitem_138\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             89 |  # node_Conv_800\n",
              "                   %\"getitem_141\"<FLOAT,[s77,160,7,7]> ⬅️ ::Conv(%\"hardtanh_31\", %\"base_model.features.16.conv.2.weight\"{...}, %\"base_model.features.16.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             90 |  # node_add_1159\n",
              "                   %\"add_1159\"<FLOAT,[s77,160,7,7]> ⬅️ ::Add(%\"add_1087\", %\"getitem_141\")\n",
              "             91 |  # node_Conv_802\n",
              "                   %\"getitem_144\"<FLOAT,[s77,960,7,7]> ⬅️ ::Conv(%\"add_1159\", %\"base_model.features.17.conv.0.0.weight\"{...}, %\"base_model.features.17.conv.0.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             92 |  # n4_33\n",
              "                   %\"hardtanh_32\"<FLOAT,[s77,960,7,7]> ⬅️ ::Clip(%\"getitem_144\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             93 |  # node_Conv_804\n",
              "                   %\"getitem_147\"<FLOAT,[s77,960,7,7]> ⬅️ ::Conv(%\"hardtanh_32\", %\"base_model.features.17.conv.1.0.weight\"{...}, %\"base_model.features.17.conv.1.0.weight_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             94 |  # n4_34\n",
              "                   %\"hardtanh_33\"<FLOAT,[s77,960,7,7]> ⬅️ ::Clip(%\"getitem_147\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             95 |  # node_Conv_806\n",
              "                   %\"getitem_150\"<FLOAT,[s77,320,7,7]> ⬅️ ::Conv(%\"hardtanh_33\", %\"base_model.features.17.conv.2.weight\"{...}, %\"base_model.features.17.conv.2.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             96 |  # node_Conv_808\n",
              "                   %\"getitem_153\"<FLOAT,[s77,1280,7,7]> ⬅️ ::Conv(%\"getitem_150\", %\"base_model.features.18.0.weight\"{...}, %\"base_model.features.18.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             97 |  # n4_35\n",
              "                   %\"hardtanh_34\"<FLOAT,[s77,1280,7,7]> ⬅️ ::Clip(%\"getitem_153\", %\"min_val_cast\"{0.0}, %\"max_val_cast\"{6.0})\n",
              "             98 |  # node_mean\n",
              "                   %\"mean\"<FLOAT,[s77,1280,1,1]> ⬅️ ::ReduceMean(%\"hardtanh_34\", %\"val_474\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
              "             99 |  # node_Concat_478\n",
              "                   %\"val_478\"<INT64,[2]> ⬅️ ::Concat(%\"val_0\", %\"val_477\"{[1280]}) {axis=0}\n",
              "            100 |  # node_view\n",
              "                   %\"view\"<FLOAT,[s77,1280]> ⬅️ ::Reshape(%\"mean\", %\"val_478\") {allowzero=1}\n",
              "            101 |  # node_linear\n",
              "                   %\"output\"<FLOAT,[s77,5]> ⬅️ ::Gemm(%\"view\", %\"output_layer.weight\"{...}, %\"output_layer.bias\"{[0.01869003288447857, -0.0861923024058342, 0.008248218335211277, 0.038042228668928146, -0.027126554399728775]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            return %\"output\"<FLOAT,[s77,5]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_base_model_features_0_0_weight: \"f32[32, 3, 3, 3]\", p_base_model_features_0_1_weight: \"f32[32]\", p_base_model_features_0_1_bias: \"f32[32]\", p_base_model_features_1_conv_0_0_weight: \"f32[32, 1, 3, 3]\", p_base_model_features_1_conv_0_1_weight: \"f32[32]\", p_base_model_features_1_conv_0_1_bias: \"f32[32]\", p_base_model_features_1_conv_1_weight: \"f32[16, 32, 1, 1]\", p_base_model_features_1_conv_2_weight: \"f32[16]\", p_base_model_features_1_conv_2_bias: \"f32[16]\", p_base_model_features_2_conv_0_0_weight: \"f32[96, 16, 1, 1]\", p_base_model_features_2_conv_0_1_weight: \"f32[96]\", p_base_model_features_2_conv_0_1_bias: \"f32[96]\", p_base_model_features_2_conv_1_0_weight: \"f32[96, 1, 3, 3]\", p_base_model_features_2_conv_1_1_weight: \"f32[96]\", p_base_model_features_2_conv_1_1_bias: \"f32[96]\", p_base_model_features_2_conv_2_weight: \"f32[24, 96, 1, 1]\", p_base_model_features_2_conv_3_weight: \"f32[24]\", p_base_model_features_2_conv_3_bias: \"f32[24]\", p_base_model_features_3_conv_0_0_weight: \"f32[144, 24, 1, 1]\", p_base_model_features_3_conv_0_1_weight: \"f32[144]\", p_base_model_features_3_conv_0_1_bias: \"f32[144]\", p_base_model_features_3_conv_1_0_weight: \"f32[144, 1, 3, 3]\", p_base_model_features_3_conv_1_1_weight: \"f32[144]\", p_base_model_features_3_conv_1_1_bias: \"f32[144]\", p_base_model_features_3_conv_2_weight: \"f32[24, 144, 1, 1]\", p_base_model_features_3_conv_3_weight: \"f32[24]\", p_base_model_features_3_conv_3_bias: \"f32[24]\", p_base_model_features_4_conv_0_0_weight: \"f32[144, 24, 1, 1]\", p_base_model_features_4_conv_0_1_weight: \"f32[144]\", p_base_model_features_4_conv_0_1_bias: \"f32[144]\", p_base_model_features_4_conv_1_0_weight: \"f32[144, 1, 3, 3]\", p_base_model_features_4_conv_1_1_weight: \"f32[144]\", p_base_model_features_4_conv_1_1_bias: \"f32[144]\", p_base_model_features_4_conv_2_weight: \"f32[32, 144, 1, 1]\", p_base_model_features_4_conv_3_weight: \"f32[32]\", p_base_model_features_4_conv_3_bias: \"f32[32]\", p_base_model_features_5_conv_0_0_weight: \"f32[192, 32, 1, 1]\", p_base_model_features_5_conv_0_1_weight: \"f32[192]\", p_base_model_features_5_conv_0_1_bias: \"f32[192]\", p_base_model_features_5_conv_1_0_weight: \"f32[192, 1, 3, 3]\", p_base_model_features_5_conv_1_1_weight: \"f32[192]\", p_base_model_features_5_conv_1_1_bias: \"f32[192]\", p_base_model_features_5_conv_2_weight: \"f32[32, 192, 1, 1]\", p_base_model_features_5_conv_3_weight: \"f32[32]\", p_base_model_features_5_conv_3_bias: \"f32[32]\", p_base_model_features_6_conv_0_0_weight: \"f32[192, 32, 1, 1]\", p_base_model_features_6_conv_0_1_weight: \"f32[192]\", p_base_model_features_6_conv_0_1_bias: \"f32[192]\", p_base_model_features_6_conv_1_0_weight: \"f32[192, 1, 3, 3]\", p_base_model_features_6_conv_1_1_weight: \"f32[192]\", p_base_model_features_6_conv_1_1_bias: \"f32[192]\", p_base_model_features_6_conv_2_weight: \"f32[32, 192, 1, 1]\", p_base_model_features_6_conv_3_weight: \"f32[32]\", p_base_model_features_6_conv_3_bias: \"f32[32]\", p_base_model_features_7_conv_0_0_weight: \"f32[192, 32, 1, 1]\", p_base_model_features_7_conv_0_1_weight: \"f32[192]\", p_base_model_features_7_conv_0_1_bias: \"f32[192]\", p_base_model_features_7_conv_1_0_weight: \"f32[192, 1, 3, 3]\", p_base_model_features_7_conv_1_1_weight: \"f32[192]\", p_base_model_features_7_conv_1_1_bias: \"f32[192]\", p_base_model_features_7_conv_2_weight: \"f32[64, 192, 1, 1]\", p_base_model_features_7_conv_3_weight: \"f32[64]\", p_base_model_features_7_conv_3_bias: \"f32[64]\", p_base_model_features_8_conv_0_0_weight: \"f32[384, 64, 1, 1]\", p_base_model_features_8_conv_0_1_weight: \"f32[384]\", p_base_model_features_8_conv_0_1_bias: \"f32[384]\", p_base_model_features_8_conv_1_0_weight: \"f32[384, 1, 3, 3]\", p_base_model_features_8_conv_1_1_weight: \"f32[384]\", p_base_model_features_8_conv_1_1_bias: \"f32[384]\", p_base_model_features_8_conv_2_weight: \"f32[64, 384, 1, 1]\", p_base_model_features_8_conv_3_weight: \"f32[64]\", p_base_model_features_8_conv_3_bias: \"f32[64]\", p_base_model_features_9_conv_0_0_weight: \"f32[384, 64, 1, 1]\", p_base_model_features_9_conv_0_1_weight: \"f32[384]\", p_base_model_features_9_conv_0_1_bias: \"f32[384]\", p_base_model_features_9_conv_1_0_weight: \"f32[384, 1, 3, 3]\", p_base_model_features_9_conv_1_1_weight: \"f32[384]\", p_base_model_features_9_conv_1_1_bias: \"f32[384]\", p_base_model_features_9_conv_2_weight: \"f32[64, 384, 1, 1]\", p_base_model_features_9_conv_3_weight: \"f32[64]\", p_base_model_features_9_conv_3_bias: \"f32[64]\", p_base_model_features_10_conv_0_0_weight: \"f32[384, 64, 1, 1]\", p_base_model_features_10_conv_0_1_weight: \"f32[384]\", p_base_model_features_10_conv_0_1_bias: \"f32[384]\", p_base_model_features_10_conv_1_0_weight: \"f32[384, 1, 3, 3]\", p_base_model_features_10_conv_1_1_weight: \"f32[384]\", p_base_model_features_10_conv_1_1_bias: \"f32[384]\", p_base_model_features_10_conv_2_weight: \"f32[64, 384, 1, 1]\", p_base_model_features_10_conv_3_weight: \"f32[64]\", p_base_model_features_10_conv_3_bias: \"f32[64]\", p_base_model_features_11_conv_0_0_weight: \"f32[384, 64, 1, 1]\", p_base_model_features_11_conv_0_1_weight: \"f32[384]\", p_base_model_features_11_conv_0_1_bias: \"f32[384]\", p_base_model_features_11_conv_1_0_weight: \"f32[384, 1, 3, 3]\", p_base_model_features_11_conv_1_1_weight: \"f32[384]\", p_base_model_features_11_conv_1_1_bias: \"f32[384]\", p_base_model_features_11_conv_2_weight: \"f32[96, 384, 1, 1]\", p_base_model_features_11_conv_3_weight: \"f32[96]\", p_base_model_features_11_conv_3_bias: \"f32[96]\", p_base_model_features_12_conv_0_0_weight: \"f32[576, 96, 1, 1]\", p_base_model_features_12_conv_0_1_weight: \"f32[576]\", p_base_model_features_12_conv_0_1_bias: \"f32[576]\", p_base_model_features_12_conv_1_0_weight: \"f32[576, 1, 3, 3]\", p_base_model_features_12_conv_1_1_weight: \"f32[576]\", p_base_model_features_12_conv_1_1_bias: \"f32[576]\", p_base_model_features_12_conv_2_weight: \"f32[96, 576, 1, 1]\", p_base_model_features_12_conv_3_weight: \"f32[96]\", p_base_model_features_12_conv_3_bias: \"f32[96]\", p_base_model_features_13_conv_0_0_weight: \"f32[576, 96, 1, 1]\", p_base_model_features_13_conv_0_1_weight: \"f32[576]\", p_base_model_features_13_conv_0_1_bias: \"f32[576]\", p_base_model_features_13_conv_1_0_weight: \"f32[576, 1, 3, 3]\", p_base_model_features_13_conv_1_1_weight: \"f32[576]\", p_base_model_features_13_conv_1_1_bias: \"f32[576]\", p_base_model_features_13_conv_2_weight: \"f32[96, 576, 1, 1]\", p_base_model_features_13_conv_3_weight: \"f32[96]\", p_base_model_features_13_conv_3_bias: \"f32[96]\", p_base_model_features_14_conv_0_0_weight: \"f32[576, 96, 1, 1]\", p_base_model_features_14_conv_0_1_weight: \"f32[576]\", p_base_model_features_14_conv_0_1_bias: \"f32[576]\", p_base_model_features_14_conv_1_0_weight: \"f32[576, 1, 3, 3]\", p_base_model_features_14_conv_1_1_weight: \"f32[576]\", p_base_model_features_14_conv_1_1_bias: \"f32[576]\", p_base_model_features_14_conv_2_weight: \"f32[160, 576, 1, 1]\", p_base_model_features_14_conv_3_weight: \"f32[160]\", p_base_model_features_14_conv_3_bias: \"f32[160]\", p_base_model_features_15_conv_0_0_weight: \"f32[960, 160, 1, 1]\", p_base_model_features_15_conv_0_1_weight: \"f32[960]\", p_base_model_features_15_conv_0_1_bias: \"f32[960]\", p_base_model_features_15_conv_1_0_weight: \"f32[960, 1, 3, 3]\", p_base_model_features_15_conv_1_1_weight: \"f32[960]\", p_base_model_features_15_conv_1_1_bias: \"f32[960]\", p_base_model_features_15_conv_2_weight: \"f32[160, 960, 1, 1]\", p_base_model_features_15_conv_3_weight: \"f32[160]\", p_base_model_features_15_conv_3_bias: \"f32[160]\", p_base_model_features_16_conv_0_0_weight: \"f32[960, 160, 1, 1]\", p_base_model_features_16_conv_0_1_weight: \"f32[960]\", p_base_model_features_16_conv_0_1_bias: \"f32[960]\", p_base_model_features_16_conv_1_0_weight: \"f32[960, 1, 3, 3]\", p_base_model_features_16_conv_1_1_weight: \"f32[960]\", p_base_model_features_16_conv_1_1_bias: \"f32[960]\", p_base_model_features_16_conv_2_weight: \"f32[160, 960, 1, 1]\", p_base_model_features_16_conv_3_weight: \"f32[160]\", p_base_model_features_16_conv_3_bias: \"f32[160]\", p_base_model_features_17_conv_0_0_weight: \"f32[960, 160, 1, 1]\", p_base_model_features_17_conv_0_1_weight: \"f32[960]\", p_base_model_features_17_conv_0_1_bias: \"f32[960]\", p_base_model_features_17_conv_1_0_weight: \"f32[960, 1, 3, 3]\", p_base_model_features_17_conv_1_1_weight: \"f32[960]\", p_base_model_features_17_conv_1_1_bias: \"f32[960]\", p_base_model_features_17_conv_2_weight: \"f32[320, 960, 1, 1]\", p_base_model_features_17_conv_3_weight: \"f32[320]\", p_base_model_features_17_conv_3_bias: \"f32[320]\", p_base_model_features_18_0_weight: \"f32[1280, 320, 1, 1]\", p_base_model_features_18_1_weight: \"f32[1280]\", p_base_model_features_18_1_bias: \"f32[1280]\", p_output_layer_weight: \"f32[5, 1280]\", p_output_layer_bias: \"f32[5]\", b_base_model_features_0_1_running_mean: \"f32[32]\", b_base_model_features_0_1_running_var: \"f32[32]\", b_base_model_features_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_1_conv_0_1_running_mean: \"f32[32]\", b_base_model_features_1_conv_0_1_running_var: \"f32[32]\", b_base_model_features_1_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_1_conv_2_running_mean: \"f32[16]\", b_base_model_features_1_conv_2_running_var: \"f32[16]\", b_base_model_features_1_conv_2_num_batches_tracked: \"i64[]\", b_base_model_features_2_conv_0_1_running_mean: \"f32[96]\", b_base_model_features_2_conv_0_1_running_var: \"f32[96]\", b_base_model_features_2_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_2_conv_1_1_running_mean: \"f32[96]\", b_base_model_features_2_conv_1_1_running_var: \"f32[96]\", b_base_model_features_2_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_2_conv_3_running_mean: \"f32[24]\", b_base_model_features_2_conv_3_running_var: \"f32[24]\", b_base_model_features_2_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_3_conv_0_1_running_mean: \"f32[144]\", b_base_model_features_3_conv_0_1_running_var: \"f32[144]\", b_base_model_features_3_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_3_conv_1_1_running_mean: \"f32[144]\", b_base_model_features_3_conv_1_1_running_var: \"f32[144]\", b_base_model_features_3_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_3_conv_3_running_mean: \"f32[24]\", b_base_model_features_3_conv_3_running_var: \"f32[24]\", b_base_model_features_3_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_4_conv_0_1_running_mean: \"f32[144]\", b_base_model_features_4_conv_0_1_running_var: \"f32[144]\", b_base_model_features_4_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_4_conv_1_1_running_mean: \"f32[144]\", b_base_model_features_4_conv_1_1_running_var: \"f32[144]\", b_base_model_features_4_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_4_conv_3_running_mean: \"f32[32]\", b_base_model_features_4_conv_3_running_var: \"f32[32]\", b_base_model_features_4_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_5_conv_0_1_running_mean: \"f32[192]\", b_base_model_features_5_conv_0_1_running_var: \"f32[192]\", b_base_model_features_5_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_5_conv_1_1_running_mean: \"f32[192]\", b_base_model_features_5_conv_1_1_running_var: \"f32[192]\", b_base_model_features_5_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_5_conv_3_running_mean: \"f32[32]\", b_base_model_features_5_conv_3_running_var: \"f32[32]\", b_base_model_features_5_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_6_conv_0_1_running_mean: \"f32[192]\", b_base_model_features_6_conv_0_1_running_var: \"f32[192]\", b_base_model_features_6_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_6_conv_1_1_running_mean: \"f32[192]\", b_base_model_features_6_conv_1_1_running_var: \"f32[192]\", b_base_model_features_6_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_6_conv_3_running_mean: \"f32[32]\", b_base_model_features_6_conv_3_running_var: \"f32[32]\", b_base_model_features_6_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_7_conv_0_1_running_mean: \"f32[192]\", b_base_model_features_7_conv_0_1_running_var: \"f32[192]\", b_base_model_features_7_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_7_conv_1_1_running_mean: \"f32[192]\", b_base_model_features_7_conv_1_1_running_var: \"f32[192]\", b_base_model_features_7_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_7_conv_3_running_mean: \"f32[64]\", b_base_model_features_7_conv_3_running_var: \"f32[64]\", b_base_model_features_7_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_8_conv_0_1_running_mean: \"f32[384]\", b_base_model_features_8_conv_0_1_running_var: \"f32[384]\", b_base_model_features_8_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_8_conv_1_1_running_mean: \"f32[384]\", b_base_model_features_8_conv_1_1_running_var: \"f32[384]\", b_base_model_features_8_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_8_conv_3_running_mean: \"f32[64]\", b_base_model_features_8_conv_3_running_var: \"f32[64]\", b_base_model_features_8_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_9_conv_0_1_running_mean: \"f32[384]\", b_base_model_features_9_conv_0_1_running_var: \"f32[384]\", b_base_model_features_9_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_9_conv_1_1_running_mean: \"f32[384]\", b_base_model_features_9_conv_1_1_running_var: \"f32[384]\", b_base_model_features_9_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_9_conv_3_running_mean: \"f32[64]\", b_base_model_features_9_conv_3_running_var: \"f32[64]\", b_base_model_features_9_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_10_conv_0_1_running_mean: \"f32[384]\", b_base_model_features_10_conv_0_1_running_var: \"f32[384]\", b_base_model_features_10_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_10_conv_1_1_running_mean: \"f32[384]\", b_base_model_features_10_conv_1_1_running_var: \"f32[384]\", b_base_model_features_10_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_10_conv_3_running_mean: \"f32[64]\", b_base_model_features_10_conv_3_running_var: \"f32[64]\", b_base_model_features_10_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_11_conv_0_1_running_mean: \"f32[384]\", b_base_model_features_11_conv_0_1_running_var: \"f32[384]\", b_base_model_features_11_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_11_conv_1_1_running_mean: \"f32[384]\", b_base_model_features_11_conv_1_1_running_var: \"f32[384]\", b_base_model_features_11_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_11_conv_3_running_mean: \"f32[96]\", b_base_model_features_11_conv_3_running_var: \"f32[96]\", b_base_model_features_11_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_12_conv_0_1_running_mean: \"f32[576]\", b_base_model_features_12_conv_0_1_running_var: \"f32[576]\", b_base_model_features_12_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_12_conv_1_1_running_mean: \"f32[576]\", b_base_model_features_12_conv_1_1_running_var: \"f32[576]\", b_base_model_features_12_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_12_conv_3_running_mean: \"f32[96]\", b_base_model_features_12_conv_3_running_var: \"f32[96]\", b_base_model_features_12_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_13_conv_0_1_running_mean: \"f32[576]\", b_base_model_features_13_conv_0_1_running_var: \"f32[576]\", b_base_model_features_13_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_13_conv_1_1_running_mean: \"f32[576]\", b_base_model_features_13_conv_1_1_running_var: \"f32[576]\", b_base_model_features_13_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_13_conv_3_running_mean: \"f32[96]\", b_base_model_features_13_conv_3_running_var: \"f32[96]\", b_base_model_features_13_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_14_conv_0_1_running_mean: \"f32[576]\", b_base_model_features_14_conv_0_1_running_var: \"f32[576]\", b_base_model_features_14_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_14_conv_1_1_running_mean: \"f32[576]\", b_base_model_features_14_conv_1_1_running_var: \"f32[576]\", b_base_model_features_14_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_14_conv_3_running_mean: \"f32[160]\", b_base_model_features_14_conv_3_running_var: \"f32[160]\", b_base_model_features_14_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_15_conv_0_1_running_mean: \"f32[960]\", b_base_model_features_15_conv_0_1_running_var: \"f32[960]\", b_base_model_features_15_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_15_conv_1_1_running_mean: \"f32[960]\", b_base_model_features_15_conv_1_1_running_var: \"f32[960]\", b_base_model_features_15_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_15_conv_3_running_mean: \"f32[160]\", b_base_model_features_15_conv_3_running_var: \"f32[160]\", b_base_model_features_15_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_16_conv_0_1_running_mean: \"f32[960]\", b_base_model_features_16_conv_0_1_running_var: \"f32[960]\", b_base_model_features_16_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_16_conv_1_1_running_mean: \"f32[960]\", b_base_model_features_16_conv_1_1_running_var: \"f32[960]\", b_base_model_features_16_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_16_conv_3_running_mean: \"f32[160]\", b_base_model_features_16_conv_3_running_var: \"f32[160]\", b_base_model_features_16_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_17_conv_0_1_running_mean: \"f32[960]\", b_base_model_features_17_conv_0_1_running_var: \"f32[960]\", b_base_model_features_17_conv_0_1_num_batches_tracked: \"i64[]\", b_base_model_features_17_conv_1_1_running_mean: \"f32[960]\", b_base_model_features_17_conv_1_1_running_var: \"f32[960]\", b_base_model_features_17_conv_1_1_num_batches_tracked: \"i64[]\", b_base_model_features_17_conv_3_running_mean: \"f32[320]\", b_base_model_features_17_conv_3_running_var: \"f32[320]\", b_base_model_features_17_conv_3_num_batches_tracked: \"i64[]\", b_base_model_features_18_1_running_mean: \"f32[1280]\", b_base_model_features_18_1_running_var: \"f32[1280]\", b_base_model_features_18_1_num_batches_tracked: \"i64[]\", x: \"f32[s77, 3, 224, 224]\"):\n",
              "                     # \n",
              "                    sym_size_int_1: \"Sym(s77)\" = torch.ops.aten.sym_size.int(x, 0)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d: \"f32[s77, 32, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_base_model_features_0_0_weight, None, [2, 2], [1, 1]);  x = p_base_model_features_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_base_model_features_0_1_weight, p_base_model_features_0_1_bias, b_base_model_features_0_1_running_mean, b_base_model_features_0_1_running_var, 0.1, 1e-05);  conv2d = p_base_model_features_0_1_weight = p_base_model_features_0_1_bias = b_base_model_features_0_1_running_mean = b_base_model_features_0_1_running_var = None\n",
              "                    getitem: \"f32[s77, 32, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh: \"f32[s77, 32, 112, 112]\" = torch.ops.aten.hardtanh.default(getitem, 0.0, 6.0);  getitem = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_1: \"f32[s77, 32, 112, 112]\" = torch.ops.aten.conv2d.default(hardtanh, p_base_model_features_1_conv_0_0_weight, None, [1, 1], [1, 1], [1, 1], 32);  hardtanh = p_base_model_features_1_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_base_model_features_1_conv_0_1_weight, p_base_model_features_1_conv_0_1_bias, b_base_model_features_1_conv_0_1_running_mean, b_base_model_features_1_conv_0_1_running_var, 0.1, 1e-05);  conv2d_1 = p_base_model_features_1_conv_0_1_weight = p_base_model_features_1_conv_0_1_bias = b_base_model_features_1_conv_0_1_running_mean = b_base_model_features_1_conv_0_1_running_var = None\n",
              "                    getitem_3: \"f32[s77, 32, 112, 112]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_1: \"f32[s77, 32, 112, 112]\" = torch.ops.aten.hardtanh.default(getitem_3, 0.0, 6.0);  getitem_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_2: \"f32[s77, 16, 112, 112]\" = torch.ops.aten.conv2d.default(hardtanh_1, p_base_model_features_1_conv_1_weight);  hardtanh_1 = p_base_model_features_1_conv_1_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_base_model_features_1_conv_2_weight, p_base_model_features_1_conv_2_bias, b_base_model_features_1_conv_2_running_mean, b_base_model_features_1_conv_2_running_var, 0.1, 1e-05);  conv2d_2 = p_base_model_features_1_conv_2_weight = p_base_model_features_1_conv_2_bias = b_base_model_features_1_conv_2_running_mean = b_base_model_features_1_conv_2_running_var = None\n",
              "                    getitem_6: \"f32[s77, 16, 112, 112]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_3: \"f32[s77, 96, 112, 112]\" = torch.ops.aten.conv2d.default(getitem_6, p_base_model_features_2_conv_0_0_weight);  getitem_6 = p_base_model_features_2_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_base_model_features_2_conv_0_1_weight, p_base_model_features_2_conv_0_1_bias, b_base_model_features_2_conv_0_1_running_mean, b_base_model_features_2_conv_0_1_running_var, 0.1, 1e-05);  conv2d_3 = p_base_model_features_2_conv_0_1_weight = p_base_model_features_2_conv_0_1_bias = b_base_model_features_2_conv_0_1_running_mean = b_base_model_features_2_conv_0_1_running_var = None\n",
              "                    getitem_9: \"f32[s77, 96, 112, 112]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_2: \"f32[s77, 96, 112, 112]\" = torch.ops.aten.hardtanh.default(getitem_9, 0.0, 6.0);  getitem_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_4: \"f32[s77, 96, 56, 56]\" = torch.ops.aten.conv2d.default(hardtanh_2, p_base_model_features_2_conv_1_0_weight, None, [2, 2], [1, 1], [1, 1], 96);  hardtanh_2 = p_base_model_features_2_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_base_model_features_2_conv_1_1_weight, p_base_model_features_2_conv_1_1_bias, b_base_model_features_2_conv_1_1_running_mean, b_base_model_features_2_conv_1_1_running_var, 0.1, 1e-05);  conv2d_4 = p_base_model_features_2_conv_1_1_weight = p_base_model_features_2_conv_1_1_bias = b_base_model_features_2_conv_1_1_running_mean = b_base_model_features_2_conv_1_1_running_var = None\n",
              "                    getitem_12: \"f32[s77, 96, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_3: \"f32[s77, 96, 56, 56]\" = torch.ops.aten.hardtanh.default(getitem_12, 0.0, 6.0);  getitem_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_5: \"f32[s77, 24, 56, 56]\" = torch.ops.aten.conv2d.default(hardtanh_3, p_base_model_features_2_conv_2_weight);  hardtanh_3 = p_base_model_features_2_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_base_model_features_2_conv_3_weight, p_base_model_features_2_conv_3_bias, b_base_model_features_2_conv_3_running_mean, b_base_model_features_2_conv_3_running_var, 0.1, 1e-05);  conv2d_5 = p_base_model_features_2_conv_3_weight = p_base_model_features_2_conv_3_bias = b_base_model_features_2_conv_3_running_mean = b_base_model_features_2_conv_3_running_var = None\n",
              "                    getitem_15: \"f32[s77, 24, 56, 56]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_6: \"f32[s77, 144, 56, 56]\" = torch.ops.aten.conv2d.default(getitem_15, p_base_model_features_3_conv_0_0_weight);  p_base_model_features_3_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_base_model_features_3_conv_0_1_weight, p_base_model_features_3_conv_0_1_bias, b_base_model_features_3_conv_0_1_running_mean, b_base_model_features_3_conv_0_1_running_var, 0.1, 1e-05);  conv2d_6 = p_base_model_features_3_conv_0_1_weight = p_base_model_features_3_conv_0_1_bias = b_base_model_features_3_conv_0_1_running_mean = b_base_model_features_3_conv_0_1_running_var = None\n",
              "                    getitem_18: \"f32[s77, 144, 56, 56]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_4: \"f32[s77, 144, 56, 56]\" = torch.ops.aten.hardtanh.default(getitem_18, 0.0, 6.0);  getitem_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_7: \"f32[s77, 144, 56, 56]\" = torch.ops.aten.conv2d.default(hardtanh_4, p_base_model_features_3_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 144);  hardtanh_4 = p_base_model_features_3_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_base_model_features_3_conv_1_1_weight, p_base_model_features_3_conv_1_1_bias, b_base_model_features_3_conv_1_1_running_mean, b_base_model_features_3_conv_1_1_running_var, 0.1, 1e-05);  conv2d_7 = p_base_model_features_3_conv_1_1_weight = p_base_model_features_3_conv_1_1_bias = b_base_model_features_3_conv_1_1_running_mean = b_base_model_features_3_conv_1_1_running_var = None\n",
              "                    getitem_21: \"f32[s77, 144, 56, 56]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_5: \"f32[s77, 144, 56, 56]\" = torch.ops.aten.hardtanh.default(getitem_21, 0.0, 6.0);  getitem_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_8: \"f32[s77, 24, 56, 56]\" = torch.ops.aten.conv2d.default(hardtanh_5, p_base_model_features_3_conv_2_weight);  hardtanh_5 = p_base_model_features_3_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_base_model_features_3_conv_3_weight, p_base_model_features_3_conv_3_bias, b_base_model_features_3_conv_3_running_mean, b_base_model_features_3_conv_3_running_var, 0.1, 1e-05);  conv2d_8 = p_base_model_features_3_conv_3_weight = p_base_model_features_3_conv_3_bias = b_base_model_features_3_conv_3_running_mean = b_base_model_features_3_conv_3_running_var = None\n",
              "                    getitem_24: \"f32[s77, 24, 56, 56]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_247: \"f32[s77, 24, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_15, getitem_24);  getitem_15 = getitem_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_9: \"f32[s77, 144, 56, 56]\" = torch.ops.aten.conv2d.default(add_247, p_base_model_features_4_conv_0_0_weight);  add_247 = p_base_model_features_4_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_base_model_features_4_conv_0_1_weight, p_base_model_features_4_conv_0_1_bias, b_base_model_features_4_conv_0_1_running_mean, b_base_model_features_4_conv_0_1_running_var, 0.1, 1e-05);  conv2d_9 = p_base_model_features_4_conv_0_1_weight = p_base_model_features_4_conv_0_1_bias = b_base_model_features_4_conv_0_1_running_mean = b_base_model_features_4_conv_0_1_running_var = None\n",
              "                    getitem_27: \"f32[s77, 144, 56, 56]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_6: \"f32[s77, 144, 56, 56]\" = torch.ops.aten.hardtanh.default(getitem_27, 0.0, 6.0);  getitem_27 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_10: \"f32[s77, 144, 28, 28]\" = torch.ops.aten.conv2d.default(hardtanh_6, p_base_model_features_4_conv_1_0_weight, None, [2, 2], [1, 1], [1, 1], 144);  hardtanh_6 = p_base_model_features_4_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_base_model_features_4_conv_1_1_weight, p_base_model_features_4_conv_1_1_bias, b_base_model_features_4_conv_1_1_running_mean, b_base_model_features_4_conv_1_1_running_var, 0.1, 1e-05);  conv2d_10 = p_base_model_features_4_conv_1_1_weight = p_base_model_features_4_conv_1_1_bias = b_base_model_features_4_conv_1_1_running_mean = b_base_model_features_4_conv_1_1_running_var = None\n",
              "                    getitem_30: \"f32[s77, 144, 28, 28]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_7: \"f32[s77, 144, 28, 28]\" = torch.ops.aten.hardtanh.default(getitem_30, 0.0, 6.0);  getitem_30 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_11: \"f32[s77, 32, 28, 28]\" = torch.ops.aten.conv2d.default(hardtanh_7, p_base_model_features_4_conv_2_weight);  hardtanh_7 = p_base_model_features_4_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_base_model_features_4_conv_3_weight, p_base_model_features_4_conv_3_bias, b_base_model_features_4_conv_3_running_mean, b_base_model_features_4_conv_3_running_var, 0.1, 1e-05);  conv2d_11 = p_base_model_features_4_conv_3_weight = p_base_model_features_4_conv_3_bias = b_base_model_features_4_conv_3_running_mean = b_base_model_features_4_conv_3_running_var = None\n",
              "                    getitem_33: \"f32[s77, 32, 28, 28]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_12: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.conv2d.default(getitem_33, p_base_model_features_5_conv_0_0_weight);  p_base_model_features_5_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_base_model_features_5_conv_0_1_weight, p_base_model_features_5_conv_0_1_bias, b_base_model_features_5_conv_0_1_running_mean, b_base_model_features_5_conv_0_1_running_var, 0.1, 1e-05);  conv2d_12 = p_base_model_features_5_conv_0_1_weight = p_base_model_features_5_conv_0_1_bias = b_base_model_features_5_conv_0_1_running_mean = b_base_model_features_5_conv_0_1_running_var = None\n",
              "                    getitem_36: \"f32[s77, 192, 28, 28]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_8: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.hardtanh.default(getitem_36, 0.0, 6.0);  getitem_36 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_13: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.conv2d.default(hardtanh_8, p_base_model_features_5_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 192);  hardtanh_8 = p_base_model_features_5_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_base_model_features_5_conv_1_1_weight, p_base_model_features_5_conv_1_1_bias, b_base_model_features_5_conv_1_1_running_mean, b_base_model_features_5_conv_1_1_running_var, 0.1, 1e-05);  conv2d_13 = p_base_model_features_5_conv_1_1_weight = p_base_model_features_5_conv_1_1_bias = b_base_model_features_5_conv_1_1_running_mean = b_base_model_features_5_conv_1_1_running_var = None\n",
              "                    getitem_39: \"f32[s77, 192, 28, 28]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_9: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.hardtanh.default(getitem_39, 0.0, 6.0);  getitem_39 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_14: \"f32[s77, 32, 28, 28]\" = torch.ops.aten.conv2d.default(hardtanh_9, p_base_model_features_5_conv_2_weight);  hardtanh_9 = p_base_model_features_5_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_base_model_features_5_conv_3_weight, p_base_model_features_5_conv_3_bias, b_base_model_features_5_conv_3_running_mean, b_base_model_features_5_conv_3_running_var, 0.1, 1e-05);  conv2d_14 = p_base_model_features_5_conv_3_weight = p_base_model_features_5_conv_3_bias = b_base_model_features_5_conv_3_running_mean = b_base_model_features_5_conv_3_running_var = None\n",
              "                    getitem_42: \"f32[s77, 32, 28, 28]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_385: \"f32[s77, 32, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_33, getitem_42);  getitem_33 = getitem_42 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_15: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.conv2d.default(add_385, p_base_model_features_6_conv_0_0_weight);  p_base_model_features_6_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_base_model_features_6_conv_0_1_weight, p_base_model_features_6_conv_0_1_bias, b_base_model_features_6_conv_0_1_running_mean, b_base_model_features_6_conv_0_1_running_var, 0.1, 1e-05);  conv2d_15 = p_base_model_features_6_conv_0_1_weight = p_base_model_features_6_conv_0_1_bias = b_base_model_features_6_conv_0_1_running_mean = b_base_model_features_6_conv_0_1_running_var = None\n",
              "                    getitem_45: \"f32[s77, 192, 28, 28]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_10: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.hardtanh.default(getitem_45, 0.0, 6.0);  getitem_45 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_16: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.conv2d.default(hardtanh_10, p_base_model_features_6_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 192);  hardtanh_10 = p_base_model_features_6_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_base_model_features_6_conv_1_1_weight, p_base_model_features_6_conv_1_1_bias, b_base_model_features_6_conv_1_1_running_mean, b_base_model_features_6_conv_1_1_running_var, 0.1, 1e-05);  conv2d_16 = p_base_model_features_6_conv_1_1_weight = p_base_model_features_6_conv_1_1_bias = b_base_model_features_6_conv_1_1_running_mean = b_base_model_features_6_conv_1_1_running_var = None\n",
              "                    getitem_48: \"f32[s77, 192, 28, 28]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_11: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.hardtanh.default(getitem_48, 0.0, 6.0);  getitem_48 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_17: \"f32[s77, 32, 28, 28]\" = torch.ops.aten.conv2d.default(hardtanh_11, p_base_model_features_6_conv_2_weight);  hardtanh_11 = p_base_model_features_6_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_base_model_features_6_conv_3_weight, p_base_model_features_6_conv_3_bias, b_base_model_features_6_conv_3_running_mean, b_base_model_features_6_conv_3_running_var, 0.1, 1e-05);  conv2d_17 = p_base_model_features_6_conv_3_weight = p_base_model_features_6_conv_3_bias = b_base_model_features_6_conv_3_running_mean = b_base_model_features_6_conv_3_running_var = None\n",
              "                    getitem_51: \"f32[s77, 32, 28, 28]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_457: \"f32[s77, 32, 28, 28]\" = torch.ops.aten.add.Tensor(add_385, getitem_51);  add_385 = getitem_51 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_18: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.conv2d.default(add_457, p_base_model_features_7_conv_0_0_weight);  add_457 = p_base_model_features_7_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_base_model_features_7_conv_0_1_weight, p_base_model_features_7_conv_0_1_bias, b_base_model_features_7_conv_0_1_running_mean, b_base_model_features_7_conv_0_1_running_var, 0.1, 1e-05);  conv2d_18 = p_base_model_features_7_conv_0_1_weight = p_base_model_features_7_conv_0_1_bias = b_base_model_features_7_conv_0_1_running_mean = b_base_model_features_7_conv_0_1_running_var = None\n",
              "                    getitem_54: \"f32[s77, 192, 28, 28]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_12: \"f32[s77, 192, 28, 28]\" = torch.ops.aten.hardtanh.default(getitem_54, 0.0, 6.0);  getitem_54 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_19: \"f32[s77, 192, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_12, p_base_model_features_7_conv_1_0_weight, None, [2, 2], [1, 1], [1, 1], 192);  hardtanh_12 = p_base_model_features_7_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_base_model_features_7_conv_1_1_weight, p_base_model_features_7_conv_1_1_bias, b_base_model_features_7_conv_1_1_running_mean, b_base_model_features_7_conv_1_1_running_var, 0.1, 1e-05);  conv2d_19 = p_base_model_features_7_conv_1_1_weight = p_base_model_features_7_conv_1_1_bias = b_base_model_features_7_conv_1_1_running_mean = b_base_model_features_7_conv_1_1_running_var = None\n",
              "                    getitem_57: \"f32[s77, 192, 14, 14]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_13: \"f32[s77, 192, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_57, 0.0, 6.0);  getitem_57 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_20: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_13, p_base_model_features_7_conv_2_weight);  hardtanh_13 = p_base_model_features_7_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_20, p_base_model_features_7_conv_3_weight, p_base_model_features_7_conv_3_bias, b_base_model_features_7_conv_3_running_mean, b_base_model_features_7_conv_3_running_var, 0.1, 1e-05);  conv2d_20 = p_base_model_features_7_conv_3_weight = p_base_model_features_7_conv_3_bias = b_base_model_features_7_conv_3_running_mean = b_base_model_features_7_conv_3_running_var = None\n",
              "                    getitem_60: \"f32[s77, 64, 14, 14]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_21: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(getitem_60, p_base_model_features_8_conv_0_0_weight);  p_base_model_features_8_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_21, p_base_model_features_8_conv_0_1_weight, p_base_model_features_8_conv_0_1_bias, b_base_model_features_8_conv_0_1_running_mean, b_base_model_features_8_conv_0_1_running_var, 0.1, 1e-05);  conv2d_21 = p_base_model_features_8_conv_0_1_weight = p_base_model_features_8_conv_0_1_bias = b_base_model_features_8_conv_0_1_running_mean = b_base_model_features_8_conv_0_1_running_var = None\n",
              "                    getitem_63: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_21[0];  _native_batch_norm_legit_no_training_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_14: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_63, 0.0, 6.0);  getitem_63 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_22: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_14, p_base_model_features_8_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 384);  hardtanh_14 = p_base_model_features_8_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_22, p_base_model_features_8_conv_1_1_weight, p_base_model_features_8_conv_1_1_bias, b_base_model_features_8_conv_1_1_running_mean, b_base_model_features_8_conv_1_1_running_var, 0.1, 1e-05);  conv2d_22 = p_base_model_features_8_conv_1_1_weight = p_base_model_features_8_conv_1_1_bias = b_base_model_features_8_conv_1_1_running_mean = b_base_model_features_8_conv_1_1_running_var = None\n",
              "                    getitem_66: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_15: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_66, 0.0, 6.0);  getitem_66 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_23: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_15, p_base_model_features_8_conv_2_weight);  hardtanh_15 = p_base_model_features_8_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_23, p_base_model_features_8_conv_3_weight, p_base_model_features_8_conv_3_bias, b_base_model_features_8_conv_3_running_mean, b_base_model_features_8_conv_3_running_var, 0.1, 1e-05);  conv2d_23 = p_base_model_features_8_conv_3_weight = p_base_model_features_8_conv_3_bias = b_base_model_features_8_conv_3_running_mean = b_base_model_features_8_conv_3_running_var = None\n",
              "                    getitem_69: \"f32[s77, 64, 14, 14]\" = _native_batch_norm_legit_no_training_23[0];  _native_batch_norm_legit_no_training_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_595: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_60, getitem_69);  getitem_60 = getitem_69 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_24: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(add_595, p_base_model_features_9_conv_0_0_weight);  p_base_model_features_9_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_24, p_base_model_features_9_conv_0_1_weight, p_base_model_features_9_conv_0_1_bias, b_base_model_features_9_conv_0_1_running_mean, b_base_model_features_9_conv_0_1_running_var, 0.1, 1e-05);  conv2d_24 = p_base_model_features_9_conv_0_1_weight = p_base_model_features_9_conv_0_1_bias = b_base_model_features_9_conv_0_1_running_mean = b_base_model_features_9_conv_0_1_running_var = None\n",
              "                    getitem_72: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_16: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_72, 0.0, 6.0);  getitem_72 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_25: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_16, p_base_model_features_9_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 384);  hardtanh_16 = p_base_model_features_9_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_25, p_base_model_features_9_conv_1_1_weight, p_base_model_features_9_conv_1_1_bias, b_base_model_features_9_conv_1_1_running_mean, b_base_model_features_9_conv_1_1_running_var, 0.1, 1e-05);  conv2d_25 = p_base_model_features_9_conv_1_1_weight = p_base_model_features_9_conv_1_1_bias = b_base_model_features_9_conv_1_1_running_mean = b_base_model_features_9_conv_1_1_running_var = None\n",
              "                    getitem_75: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_25[0];  _native_batch_norm_legit_no_training_25 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_17: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_75, 0.0, 6.0);  getitem_75 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_26: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_17, p_base_model_features_9_conv_2_weight);  hardtanh_17 = p_base_model_features_9_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_26, p_base_model_features_9_conv_3_weight, p_base_model_features_9_conv_3_bias, b_base_model_features_9_conv_3_running_mean, b_base_model_features_9_conv_3_running_var, 0.1, 1e-05);  conv2d_26 = p_base_model_features_9_conv_3_weight = p_base_model_features_9_conv_3_bias = b_base_model_features_9_conv_3_running_mean = b_base_model_features_9_conv_3_running_var = None\n",
              "                    getitem_78: \"f32[s77, 64, 14, 14]\" = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_667: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.add.Tensor(add_595, getitem_78);  add_595 = getitem_78 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_27: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(add_667, p_base_model_features_10_conv_0_0_weight);  p_base_model_features_10_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_27, p_base_model_features_10_conv_0_1_weight, p_base_model_features_10_conv_0_1_bias, b_base_model_features_10_conv_0_1_running_mean, b_base_model_features_10_conv_0_1_running_var, 0.1, 1e-05);  conv2d_27 = p_base_model_features_10_conv_0_1_weight = p_base_model_features_10_conv_0_1_bias = b_base_model_features_10_conv_0_1_running_mean = b_base_model_features_10_conv_0_1_running_var = None\n",
              "                    getitem_81: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_27[0];  _native_batch_norm_legit_no_training_27 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_18: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_81, 0.0, 6.0);  getitem_81 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_28: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_18, p_base_model_features_10_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 384);  hardtanh_18 = p_base_model_features_10_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_28, p_base_model_features_10_conv_1_1_weight, p_base_model_features_10_conv_1_1_bias, b_base_model_features_10_conv_1_1_running_mean, b_base_model_features_10_conv_1_1_running_var, 0.1, 1e-05);  conv2d_28 = p_base_model_features_10_conv_1_1_weight = p_base_model_features_10_conv_1_1_bias = b_base_model_features_10_conv_1_1_running_mean = b_base_model_features_10_conv_1_1_running_var = None\n",
              "                    getitem_84: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_19: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_84, 0.0, 6.0);  getitem_84 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_29: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_19, p_base_model_features_10_conv_2_weight);  hardtanh_19 = p_base_model_features_10_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_29, p_base_model_features_10_conv_3_weight, p_base_model_features_10_conv_3_bias, b_base_model_features_10_conv_3_running_mean, b_base_model_features_10_conv_3_running_var, 0.1, 1e-05);  conv2d_29 = p_base_model_features_10_conv_3_weight = p_base_model_features_10_conv_3_bias = b_base_model_features_10_conv_3_running_mean = b_base_model_features_10_conv_3_running_var = None\n",
              "                    getitem_87: \"f32[s77, 64, 14, 14]\" = _native_batch_norm_legit_no_training_29[0];  _native_batch_norm_legit_no_training_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_739: \"f32[s77, 64, 14, 14]\" = torch.ops.aten.add.Tensor(add_667, getitem_87);  add_667 = getitem_87 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_30: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(add_739, p_base_model_features_11_conv_0_0_weight);  add_739 = p_base_model_features_11_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_30, p_base_model_features_11_conv_0_1_weight, p_base_model_features_11_conv_0_1_bias, b_base_model_features_11_conv_0_1_running_mean, b_base_model_features_11_conv_0_1_running_var, 0.1, 1e-05);  conv2d_30 = p_base_model_features_11_conv_0_1_weight = p_base_model_features_11_conv_0_1_bias = b_base_model_features_11_conv_0_1_running_mean = b_base_model_features_11_conv_0_1_running_var = None\n",
              "                    getitem_90: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_20: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_90, 0.0, 6.0);  getitem_90 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_31: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_20, p_base_model_features_11_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 384);  hardtanh_20 = p_base_model_features_11_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_31, p_base_model_features_11_conv_1_1_weight, p_base_model_features_11_conv_1_1_bias, b_base_model_features_11_conv_1_1_running_mean, b_base_model_features_11_conv_1_1_running_var, 0.1, 1e-05);  conv2d_31 = p_base_model_features_11_conv_1_1_weight = p_base_model_features_11_conv_1_1_bias = b_base_model_features_11_conv_1_1_running_mean = b_base_model_features_11_conv_1_1_running_var = None\n",
              "                    getitem_93: \"f32[s77, 384, 14, 14]\" = _native_batch_norm_legit_no_training_31[0];  _native_batch_norm_legit_no_training_31 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_21: \"f32[s77, 384, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_93, 0.0, 6.0);  getitem_93 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_32: \"f32[s77, 96, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_21, p_base_model_features_11_conv_2_weight);  hardtanh_21 = p_base_model_features_11_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_32, p_base_model_features_11_conv_3_weight, p_base_model_features_11_conv_3_bias, b_base_model_features_11_conv_3_running_mean, b_base_model_features_11_conv_3_running_var, 0.1, 1e-05);  conv2d_32 = p_base_model_features_11_conv_3_weight = p_base_model_features_11_conv_3_bias = b_base_model_features_11_conv_3_running_mean = b_base_model_features_11_conv_3_running_var = None\n",
              "                    getitem_96: \"f32[s77, 96, 14, 14]\" = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_33: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.conv2d.default(getitem_96, p_base_model_features_12_conv_0_0_weight);  p_base_model_features_12_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_33, p_base_model_features_12_conv_0_1_weight, p_base_model_features_12_conv_0_1_bias, b_base_model_features_12_conv_0_1_running_mean, b_base_model_features_12_conv_0_1_running_var, 0.1, 1e-05);  conv2d_33 = p_base_model_features_12_conv_0_1_weight = p_base_model_features_12_conv_0_1_bias = b_base_model_features_12_conv_0_1_running_mean = b_base_model_features_12_conv_0_1_running_var = None\n",
              "                    getitem_99: \"f32[s77, 576, 14, 14]\" = _native_batch_norm_legit_no_training_33[0];  _native_batch_norm_legit_no_training_33 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_22: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_99, 0.0, 6.0);  getitem_99 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_34: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_22, p_base_model_features_12_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 576);  hardtanh_22 = p_base_model_features_12_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_34, p_base_model_features_12_conv_1_1_weight, p_base_model_features_12_conv_1_1_bias, b_base_model_features_12_conv_1_1_running_mean, b_base_model_features_12_conv_1_1_running_var, 0.1, 1e-05);  conv2d_34 = p_base_model_features_12_conv_1_1_weight = p_base_model_features_12_conv_1_1_bias = b_base_model_features_12_conv_1_1_running_mean = b_base_model_features_12_conv_1_1_running_var = None\n",
              "                    getitem_102: \"f32[s77, 576, 14, 14]\" = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_23: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_102, 0.0, 6.0);  getitem_102 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_35: \"f32[s77, 96, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_23, p_base_model_features_12_conv_2_weight);  hardtanh_23 = p_base_model_features_12_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_35, p_base_model_features_12_conv_3_weight, p_base_model_features_12_conv_3_bias, b_base_model_features_12_conv_3_running_mean, b_base_model_features_12_conv_3_running_var, 0.1, 1e-05);  conv2d_35 = p_base_model_features_12_conv_3_weight = p_base_model_features_12_conv_3_bias = b_base_model_features_12_conv_3_running_mean = b_base_model_features_12_conv_3_running_var = None\n",
              "                    getitem_105: \"f32[s77, 96, 14, 14]\" = _native_batch_norm_legit_no_training_35[0];  _native_batch_norm_legit_no_training_35 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_877: \"f32[s77, 96, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_96, getitem_105);  getitem_96 = getitem_105 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_36: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.conv2d.default(add_877, p_base_model_features_13_conv_0_0_weight);  p_base_model_features_13_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_36, p_base_model_features_13_conv_0_1_weight, p_base_model_features_13_conv_0_1_bias, b_base_model_features_13_conv_0_1_running_mean, b_base_model_features_13_conv_0_1_running_var, 0.1, 1e-05);  conv2d_36 = p_base_model_features_13_conv_0_1_weight = p_base_model_features_13_conv_0_1_bias = b_base_model_features_13_conv_0_1_running_mean = b_base_model_features_13_conv_0_1_running_var = None\n",
              "                    getitem_108: \"f32[s77, 576, 14, 14]\" = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_24: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_108, 0.0, 6.0);  getitem_108 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_37: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_24, p_base_model_features_13_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 576);  hardtanh_24 = p_base_model_features_13_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_37, p_base_model_features_13_conv_1_1_weight, p_base_model_features_13_conv_1_1_bias, b_base_model_features_13_conv_1_1_running_mean, b_base_model_features_13_conv_1_1_running_var, 0.1, 1e-05);  conv2d_37 = p_base_model_features_13_conv_1_1_weight = p_base_model_features_13_conv_1_1_bias = b_base_model_features_13_conv_1_1_running_mean = b_base_model_features_13_conv_1_1_running_var = None\n",
              "                    getitem_111: \"f32[s77, 576, 14, 14]\" = _native_batch_norm_legit_no_training_37[0];  _native_batch_norm_legit_no_training_37 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_25: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_111, 0.0, 6.0);  getitem_111 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_38: \"f32[s77, 96, 14, 14]\" = torch.ops.aten.conv2d.default(hardtanh_25, p_base_model_features_13_conv_2_weight);  hardtanh_25 = p_base_model_features_13_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_38, p_base_model_features_13_conv_3_weight, p_base_model_features_13_conv_3_bias, b_base_model_features_13_conv_3_running_mean, b_base_model_features_13_conv_3_running_var, 0.1, 1e-05);  conv2d_38 = p_base_model_features_13_conv_3_weight = p_base_model_features_13_conv_3_bias = b_base_model_features_13_conv_3_running_mean = b_base_model_features_13_conv_3_running_var = None\n",
              "                    getitem_114: \"f32[s77, 96, 14, 14]\" = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_949: \"f32[s77, 96, 14, 14]\" = torch.ops.aten.add.Tensor(add_877, getitem_114);  add_877 = getitem_114 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_39: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.conv2d.default(add_949, p_base_model_features_14_conv_0_0_weight);  add_949 = p_base_model_features_14_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_39, p_base_model_features_14_conv_0_1_weight, p_base_model_features_14_conv_0_1_bias, b_base_model_features_14_conv_0_1_running_mean, b_base_model_features_14_conv_0_1_running_var, 0.1, 1e-05);  conv2d_39 = p_base_model_features_14_conv_0_1_weight = p_base_model_features_14_conv_0_1_bias = b_base_model_features_14_conv_0_1_running_mean = b_base_model_features_14_conv_0_1_running_var = None\n",
              "                    getitem_117: \"f32[s77, 576, 14, 14]\" = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_26: \"f32[s77, 576, 14, 14]\" = torch.ops.aten.hardtanh.default(getitem_117, 0.0, 6.0);  getitem_117 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_40: \"f32[s77, 576, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_26, p_base_model_features_14_conv_1_0_weight, None, [2, 2], [1, 1], [1, 1], 576);  hardtanh_26 = p_base_model_features_14_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_40, p_base_model_features_14_conv_1_1_weight, p_base_model_features_14_conv_1_1_bias, b_base_model_features_14_conv_1_1_running_mean, b_base_model_features_14_conv_1_1_running_var, 0.1, 1e-05);  conv2d_40 = p_base_model_features_14_conv_1_1_weight = p_base_model_features_14_conv_1_1_bias = b_base_model_features_14_conv_1_1_running_mean = b_base_model_features_14_conv_1_1_running_var = None\n",
              "                    getitem_120: \"f32[s77, 576, 7, 7]\" = _native_batch_norm_legit_no_training_40[0];  _native_batch_norm_legit_no_training_40 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_27: \"f32[s77, 576, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_120, 0.0, 6.0);  getitem_120 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_41: \"f32[s77, 160, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_27, p_base_model_features_14_conv_2_weight);  hardtanh_27 = p_base_model_features_14_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_41, p_base_model_features_14_conv_3_weight, p_base_model_features_14_conv_3_bias, b_base_model_features_14_conv_3_running_mean, b_base_model_features_14_conv_3_running_var, 0.1, 1e-05);  conv2d_41 = p_base_model_features_14_conv_3_weight = p_base_model_features_14_conv_3_bias = b_base_model_features_14_conv_3_running_mean = b_base_model_features_14_conv_3_running_var = None\n",
              "                    getitem_123: \"f32[s77, 160, 7, 7]\" = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_42: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.conv2d.default(getitem_123, p_base_model_features_15_conv_0_0_weight);  p_base_model_features_15_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_42, p_base_model_features_15_conv_0_1_weight, p_base_model_features_15_conv_0_1_bias, b_base_model_features_15_conv_0_1_running_mean, b_base_model_features_15_conv_0_1_running_var, 0.1, 1e-05);  conv2d_42 = p_base_model_features_15_conv_0_1_weight = p_base_model_features_15_conv_0_1_bias = b_base_model_features_15_conv_0_1_running_mean = b_base_model_features_15_conv_0_1_running_var = None\n",
              "                    getitem_126: \"f32[s77, 960, 7, 7]\" = _native_batch_norm_legit_no_training_42[0];  _native_batch_norm_legit_no_training_42 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_28: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_126, 0.0, 6.0);  getitem_126 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_43: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_28, p_base_model_features_15_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  hardtanh_28 = p_base_model_features_15_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_43, p_base_model_features_15_conv_1_1_weight, p_base_model_features_15_conv_1_1_bias, b_base_model_features_15_conv_1_1_running_mean, b_base_model_features_15_conv_1_1_running_var, 0.1, 1e-05);  conv2d_43 = p_base_model_features_15_conv_1_1_weight = p_base_model_features_15_conv_1_1_bias = b_base_model_features_15_conv_1_1_running_mean = b_base_model_features_15_conv_1_1_running_var = None\n",
              "                    getitem_129: \"f32[s77, 960, 7, 7]\" = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_29: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_129, 0.0, 6.0);  getitem_129 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_44: \"f32[s77, 160, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_29, p_base_model_features_15_conv_2_weight);  hardtanh_29 = p_base_model_features_15_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_44 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_44, p_base_model_features_15_conv_3_weight, p_base_model_features_15_conv_3_bias, b_base_model_features_15_conv_3_running_mean, b_base_model_features_15_conv_3_running_var, 0.1, 1e-05);  conv2d_44 = p_base_model_features_15_conv_3_weight = p_base_model_features_15_conv_3_bias = b_base_model_features_15_conv_3_running_mean = b_base_model_features_15_conv_3_running_var = None\n",
              "                    getitem_132: \"f32[s77, 160, 7, 7]\" = _native_batch_norm_legit_no_training_44[0];  _native_batch_norm_legit_no_training_44 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_1087: \"f32[s77, 160, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_123, getitem_132);  getitem_123 = getitem_132 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_45: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.conv2d.default(add_1087, p_base_model_features_16_conv_0_0_weight);  p_base_model_features_16_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_45, p_base_model_features_16_conv_0_1_weight, p_base_model_features_16_conv_0_1_bias, b_base_model_features_16_conv_0_1_running_mean, b_base_model_features_16_conv_0_1_running_var, 0.1, 1e-05);  conv2d_45 = p_base_model_features_16_conv_0_1_weight = p_base_model_features_16_conv_0_1_bias = b_base_model_features_16_conv_0_1_running_mean = b_base_model_features_16_conv_0_1_running_var = None\n",
              "                    getitem_135: \"f32[s77, 960, 7, 7]\" = _native_batch_norm_legit_no_training_45[0];  _native_batch_norm_legit_no_training_45 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_30: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_135, 0.0, 6.0);  getitem_135 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_46: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_30, p_base_model_features_16_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  hardtanh_30 = p_base_model_features_16_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_46 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_46, p_base_model_features_16_conv_1_1_weight, p_base_model_features_16_conv_1_1_bias, b_base_model_features_16_conv_1_1_running_mean, b_base_model_features_16_conv_1_1_running_var, 0.1, 1e-05);  conv2d_46 = p_base_model_features_16_conv_1_1_weight = p_base_model_features_16_conv_1_1_bias = b_base_model_features_16_conv_1_1_running_mean = b_base_model_features_16_conv_1_1_running_var = None\n",
              "                    getitem_138: \"f32[s77, 960, 7, 7]\" = _native_batch_norm_legit_no_training_46[0];  _native_batch_norm_legit_no_training_46 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_31: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_138, 0.0, 6.0);  getitem_138 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_47: \"f32[s77, 160, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_31, p_base_model_features_16_conv_2_weight);  hardtanh_31 = p_base_model_features_16_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_47, p_base_model_features_16_conv_3_weight, p_base_model_features_16_conv_3_bias, b_base_model_features_16_conv_3_running_mean, b_base_model_features_16_conv_3_running_var, 0.1, 1e-05);  conv2d_47 = p_base_model_features_16_conv_3_weight = p_base_model_features_16_conv_3_bias = b_base_model_features_16_conv_3_running_mean = b_base_model_features_16_conv_3_running_var = None\n",
              "                    getitem_141: \"f32[s77, 160, 7, 7]\" = _native_batch_norm_legit_no_training_47[0];  _native_batch_norm_legit_no_training_47 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torchvision/models/mobilenetv2.py:62 in forward, code: return x + self.conv(x)\n",
              "                    add_1159: \"f32[s77, 160, 7, 7]\" = torch.ops.aten.add.Tensor(add_1087, getitem_141);  add_1087 = getitem_141 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_48: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.conv2d.default(add_1159, p_base_model_features_17_conv_0_0_weight);  add_1159 = p_base_model_features_17_conv_0_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_48 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_48, p_base_model_features_17_conv_0_1_weight, p_base_model_features_17_conv_0_1_bias, b_base_model_features_17_conv_0_1_running_mean, b_base_model_features_17_conv_0_1_running_var, 0.1, 1e-05);  conv2d_48 = p_base_model_features_17_conv_0_1_weight = p_base_model_features_17_conv_0_1_bias = b_base_model_features_17_conv_0_1_running_mean = b_base_model_features_17_conv_0_1_running_var = None\n",
              "                    getitem_144: \"f32[s77, 960, 7, 7]\" = _native_batch_norm_legit_no_training_48[0];  _native_batch_norm_legit_no_training_48 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_32: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_144, 0.0, 6.0);  getitem_144 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_49: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_32, p_base_model_features_17_conv_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  hardtanh_32 = p_base_model_features_17_conv_1_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_49, p_base_model_features_17_conv_1_1_weight, p_base_model_features_17_conv_1_1_bias, b_base_model_features_17_conv_1_1_running_mean, b_base_model_features_17_conv_1_1_running_var, 0.1, 1e-05);  conv2d_49 = p_base_model_features_17_conv_1_1_weight = p_base_model_features_17_conv_1_1_bias = b_base_model_features_17_conv_1_1_running_mean = b_base_model_features_17_conv_1_1_running_var = None\n",
              "                    getitem_147: \"f32[s77, 960, 7, 7]\" = _native_batch_norm_legit_no_training_49[0];  _native_batch_norm_legit_no_training_49 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_33: \"f32[s77, 960, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_147, 0.0, 6.0);  getitem_147 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_50: \"f32[s77, 320, 7, 7]\" = torch.ops.aten.conv2d.default(hardtanh_33, p_base_model_features_17_conv_2_weight);  hardtanh_33 = p_base_model_features_17_conv_2_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_50 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_50, p_base_model_features_17_conv_3_weight, p_base_model_features_17_conv_3_bias, b_base_model_features_17_conv_3_running_mean, b_base_model_features_17_conv_3_running_var, 0.1, 1e-05);  conv2d_50 = p_base_model_features_17_conv_3_weight = p_base_model_features_17_conv_3_bias = b_base_model_features_17_conv_3_running_mean = b_base_model_features_17_conv_3_running_var = None\n",
              "                    getitem_150: \"f32[s77, 320, 7, 7]\" = _native_batch_norm_legit_no_training_50[0];  _native_batch_norm_legit_no_training_50 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_51: \"f32[s77, 1280, 7, 7]\" = torch.ops.aten.conv2d.default(getitem_150, p_base_model_features_18_0_weight);  getitem_150 = p_base_model_features_18_0_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_51, p_base_model_features_18_1_weight, p_base_model_features_18_1_bias, b_base_model_features_18_1_running_mean, b_base_model_features_18_1_running_var, 0.1, 1e-05);  conv2d_51 = p_base_model_features_18_1_weight = p_base_model_features_18_1_bias = b_base_model_features_18_1_running_mean = b_base_model_features_18_1_running_var = None\n",
              "                    getitem_153: \"f32[s77, 1280, 7, 7]\" = _native_batch_norm_legit_no_training_51[0];  _native_batch_norm_legit_no_training_51 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:292 in forward, code: return F.hardtanh(input, self.min_val, self.max_val, self.inplace)\n",
              "                    hardtanh_34: \"f32[s77, 1280, 7, 7]\" = torch.ops.aten.hardtanh.default(getitem_153, 0.0, 6.0);  getitem_153 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
              "                    mean: \"f32[s77, 1280, 1, 1]\" = torch.ops.aten.mean.dim(hardtanh_34, [-1, -2], True);  hardtanh_34 = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-470444479.py:28 in forward, code: x = torch.flatten(x, 1)\n",
              "                    view: \"f32[s77, 1280]\" = torch.ops.aten.view.default(mean, [sym_size_int_1, 1280]);  mean = sym_size_int_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone: \"f32[s77, 1280]\" = torch.ops.aten.clone.default(view);  view = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[s77, 5]\" = torch.ops.aten.linear.default(clone, p_output_layer_weight, p_output_layer_bias);  clone = p_output_layer_weight = p_output_layer_bias = None\n",
              "                    return (linear,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_base_model_features_0_0_weight: PARAMETER target='base_model.features.0.0.weight'\n",
              "            p_base_model_features_0_1_weight: PARAMETER target='base_model.features.0.1.weight'\n",
              "            p_base_model_features_0_1_bias: PARAMETER target='base_model.features.0.1.bias'\n",
              "            p_base_model_features_1_conv_0_0_weight: PARAMETER target='base_model.features.1.conv.0.0.weight'\n",
              "            p_base_model_features_1_conv_0_1_weight: PARAMETER target='base_model.features.1.conv.0.1.weight'\n",
              "            p_base_model_features_1_conv_0_1_bias: PARAMETER target='base_model.features.1.conv.0.1.bias'\n",
              "            p_base_model_features_1_conv_1_weight: PARAMETER target='base_model.features.1.conv.1.weight'\n",
              "            p_base_model_features_1_conv_2_weight: PARAMETER target='base_model.features.1.conv.2.weight'\n",
              "            p_base_model_features_1_conv_2_bias: PARAMETER target='base_model.features.1.conv.2.bias'\n",
              "            p_base_model_features_2_conv_0_0_weight: PARAMETER target='base_model.features.2.conv.0.0.weight'\n",
              "            p_base_model_features_2_conv_0_1_weight: PARAMETER target='base_model.features.2.conv.0.1.weight'\n",
              "            p_base_model_features_2_conv_0_1_bias: PARAMETER target='base_model.features.2.conv.0.1.bias'\n",
              "            p_base_model_features_2_conv_1_0_weight: PARAMETER target='base_model.features.2.conv.1.0.weight'\n",
              "            p_base_model_features_2_conv_1_1_weight: PARAMETER target='base_model.features.2.conv.1.1.weight'\n",
              "            p_base_model_features_2_conv_1_1_bias: PARAMETER target='base_model.features.2.conv.1.1.bias'\n",
              "            p_base_model_features_2_conv_2_weight: PARAMETER target='base_model.features.2.conv.2.weight'\n",
              "            p_base_model_features_2_conv_3_weight: PARAMETER target='base_model.features.2.conv.3.weight'\n",
              "            p_base_model_features_2_conv_3_bias: PARAMETER target='base_model.features.2.conv.3.bias'\n",
              "            p_base_model_features_3_conv_0_0_weight: PARAMETER target='base_model.features.3.conv.0.0.weight'\n",
              "            p_base_model_features_3_conv_0_1_weight: PARAMETER target='base_model.features.3.conv.0.1.weight'\n",
              "            p_base_model_features_3_conv_0_1_bias: PARAMETER target='base_model.features.3.conv.0.1.bias'\n",
              "            p_base_model_features_3_conv_1_0_weight: PARAMETER target='base_model.features.3.conv.1.0.weight'\n",
              "            p_base_model_features_3_conv_1_1_weight: PARAMETER target='base_model.features.3.conv.1.1.weight'\n",
              "            p_base_model_features_3_conv_1_1_bias: PARAMETER target='base_model.features.3.conv.1.1.bias'\n",
              "            p_base_model_features_3_conv_2_weight: PARAMETER target='base_model.features.3.conv.2.weight'\n",
              "            p_base_model_features_3_conv_3_weight: PARAMETER target='base_model.features.3.conv.3.weight'\n",
              "            p_base_model_features_3_conv_3_bias: PARAMETER target='base_model.features.3.conv.3.bias'\n",
              "            p_base_model_features_4_conv_0_0_weight: PARAMETER target='base_model.features.4.conv.0.0.weight'\n",
              "            p_base_model_features_4_conv_0_1_weight: PARAMETER target='base_model.features.4.conv.0.1.weight'\n",
              "            p_base_model_features_4_conv_0_1_bias: PARAMETER target='base_model.features.4.conv.0.1.bias'\n",
              "            p_base_model_features_4_conv_1_0_weight: PARAMETER target='base_model.features.4.conv.1.0.weight'\n",
              "            p_base_model_features_4_conv_1_1_weight: PARAMETER target='base_model.features.4.conv.1.1.weight'\n",
              "            p_base_model_features_4_conv_1_1_bias: PARAMETER target='base_model.features.4.conv.1.1.bias'\n",
              "            p_base_model_features_4_conv_2_weight: PARAMETER target='base_model.features.4.conv.2.weight'\n",
              "            p_base_model_features_4_conv_3_weight: PARAMETER target='base_model.features.4.conv.3.weight'\n",
              "            p_base_model_features_4_conv_3_bias: PARAMETER target='base_model.features.4.conv.3.bias'\n",
              "            p_base_model_features_5_conv_0_0_weight: PARAMETER target='base_model.features.5.conv.0.0.weight'\n",
              "            p_base_model_features_5_conv_0_1_weight: PARAMETER target='base_model.features.5.conv.0.1.weight'\n",
              "            p_base_model_features_5_conv_0_1_bias: PARAMETER target='base_model.features.5.conv.0.1.bias'\n",
              "            p_base_model_features_5_conv_1_0_weight: PARAMETER target='base_model.features.5.conv.1.0.weight'\n",
              "            p_base_model_features_5_conv_1_1_weight: PARAMETER target='base_model.features.5.conv.1.1.weight'\n",
              "            p_base_model_features_5_conv_1_1_bias: PARAMETER target='base_model.features.5.conv.1.1.bias'\n",
              "            p_base_model_features_5_conv_2_weight: PARAMETER target='base_model.features.5.conv.2.weight'\n",
              "            p_base_model_features_5_conv_3_weight: PARAMETER target='base_model.features.5.conv.3.weight'\n",
              "            p_base_model_features_5_conv_3_bias: PARAMETER target='base_model.features.5.conv.3.bias'\n",
              "            p_base_model_features_6_conv_0_0_weight: PARAMETER target='base_model.features.6.conv.0.0.weight'\n",
              "            p_base_model_features_6_conv_0_1_weight: PARAMETER target='base_model.features.6.conv.0.1.weight'\n",
              "            p_base_model_features_6_conv_0_1_bias: PARAMETER target='base_model.features.6.conv.0.1.bias'\n",
              "            p_base_model_features_6_conv_1_0_weight: PARAMETER target='base_model.features.6.conv.1.0.weight'\n",
              "            p_base_model_features_6_conv_1_1_weight: PARAMETER target='base_model.features.6.conv.1.1.weight'\n",
              "            p_base_model_features_6_conv_1_1_bias: PARAMETER target='base_model.features.6.conv.1.1.bias'\n",
              "            p_base_model_features_6_conv_2_weight: PARAMETER target='base_model.features.6.conv.2.weight'\n",
              "            p_base_model_features_6_conv_3_weight: PARAMETER target='base_model.features.6.conv.3.weight'\n",
              "            p_base_model_features_6_conv_3_bias: PARAMETER target='base_model.features.6.conv.3.bias'\n",
              "            p_base_model_features_7_conv_0_0_weight: PARAMETER target='base_model.features.7.conv.0.0.weight'\n",
              "            p_base_model_features_7_conv_0_1_weight: PARAMETER target='base_model.features.7.conv.0.1.weight'\n",
              "            p_base_model_features_7_conv_0_1_bias: PARAMETER target='base_model.features.7.conv.0.1.bias'\n",
              "            p_base_model_features_7_conv_1_0_weight: PARAMETER target='base_model.features.7.conv.1.0.weight'\n",
              "            p_base_model_features_7_conv_1_1_weight: PARAMETER target='base_model.features.7.conv.1.1.weight'\n",
              "            p_base_model_features_7_conv_1_1_bias: PARAMETER target='base_model.features.7.conv.1.1.bias'\n",
              "            p_base_model_features_7_conv_2_weight: PARAMETER target='base_model.features.7.conv.2.weight'\n",
              "            p_base_model_features_7_conv_3_weight: PARAMETER target='base_model.features.7.conv.3.weight'\n",
              "            p_base_model_features_7_conv_3_bias: PARAMETER target='base_model.features.7.conv.3.bias'\n",
              "            p_base_model_features_8_conv_0_0_weight: PARAMETER target='base_model.features.8.conv.0.0.weight'\n",
              "            p_base_model_features_8_conv_0_1_weight: PARAMETER target='base_model.features.8.conv.0.1.weight'\n",
              "            p_base_model_features_8_conv_0_1_bias: PARAMETER target='base_model.features.8.conv.0.1.bias'\n",
              "            p_base_model_features_8_conv_1_0_weight: PARAMETER target='base_model.features.8.conv.1.0.weight'\n",
              "            p_base_model_features_8_conv_1_1_weight: PARAMETER target='base_model.features.8.conv.1.1.weight'\n",
              "            p_base_model_features_8_conv_1_1_bias: PARAMETER target='base_model.features.8.conv.1.1.bias'\n",
              "            p_base_model_features_8_conv_2_weight: PARAMETER target='base_model.features.8.conv.2.weight'\n",
              "            p_base_model_features_8_conv_3_weight: PARAMETER target='base_model.features.8.conv.3.weight'\n",
              "            p_base_model_features_8_conv_3_bias: PARAMETER target='base_model.features.8.conv.3.bias'\n",
              "            p_base_model_features_9_conv_0_0_weight: PARAMETER target='base_model.features.9.conv.0.0.weight'\n",
              "            p_base_model_features_9_conv_0_1_weight: PARAMETER target='base_model.features.9.conv.0.1.weight'\n",
              "            p_base_model_features_9_conv_0_1_bias: PARAMETER target='base_model.features.9.conv.0.1.bias'\n",
              "            p_base_model_features_9_conv_1_0_weight: PARAMETER target='base_model.features.9.conv.1.0.weight'\n",
              "            p_base_model_features_9_conv_1_1_weight: PARAMETER target='base_model.features.9.conv.1.1.weight'\n",
              "            p_base_model_features_9_conv_1_1_bias: PARAMETER target='base_model.features.9.conv.1.1.bias'\n",
              "            p_base_model_features_9_conv_2_weight: PARAMETER target='base_model.features.9.conv.2.weight'\n",
              "            p_base_model_features_9_conv_3_weight: PARAMETER target='base_model.features.9.conv.3.weight'\n",
              "            p_base_model_features_9_conv_3_bias: PARAMETER target='base_model.features.9.conv.3.bias'\n",
              "            p_base_model_features_10_conv_0_0_weight: PARAMETER target='base_model.features.10.conv.0.0.weight'\n",
              "            p_base_model_features_10_conv_0_1_weight: PARAMETER target='base_model.features.10.conv.0.1.weight'\n",
              "            p_base_model_features_10_conv_0_1_bias: PARAMETER target='base_model.features.10.conv.0.1.bias'\n",
              "            p_base_model_features_10_conv_1_0_weight: PARAMETER target='base_model.features.10.conv.1.0.weight'\n",
              "            p_base_model_features_10_conv_1_1_weight: PARAMETER target='base_model.features.10.conv.1.1.weight'\n",
              "            p_base_model_features_10_conv_1_1_bias: PARAMETER target='base_model.features.10.conv.1.1.bias'\n",
              "            p_base_model_features_10_conv_2_weight: PARAMETER target='base_model.features.10.conv.2.weight'\n",
              "            p_base_model_features_10_conv_3_weight: PARAMETER target='base_model.features.10.conv.3.weight'\n",
              "            p_base_model_features_10_conv_3_bias: PARAMETER target='base_model.features.10.conv.3.bias'\n",
              "            p_base_model_features_11_conv_0_0_weight: PARAMETER target='base_model.features.11.conv.0.0.weight'\n",
              "            p_base_model_features_11_conv_0_1_weight: PARAMETER target='base_model.features.11.conv.0.1.weight'\n",
              "            p_base_model_features_11_conv_0_1_bias: PARAMETER target='base_model.features.11.conv.0.1.bias'\n",
              "            p_base_model_features_11_conv_1_0_weight: PARAMETER target='base_model.features.11.conv.1.0.weight'\n",
              "            p_base_model_features_11_conv_1_1_weight: PARAMETER target='base_model.features.11.conv.1.1.weight'\n",
              "            p_base_model_features_11_conv_1_1_bias: PARAMETER target='base_model.features.11.conv.1.1.bias'\n",
              "            p_base_model_features_11_conv_2_weight: PARAMETER target='base_model.features.11.conv.2.weight'\n",
              "            p_base_model_features_11_conv_3_weight: PARAMETER target='base_model.features.11.conv.3.weight'\n",
              "            p_base_model_features_11_conv_3_bias: PARAMETER target='base_model.features.11.conv.3.bias'\n",
              "            p_base_model_features_12_conv_0_0_weight: PARAMETER target='base_model.features.12.conv.0.0.weight'\n",
              "            p_base_model_features_12_conv_0_1_weight: PARAMETER target='base_model.features.12.conv.0.1.weight'\n",
              "            p_base_model_features_12_conv_0_1_bias: PARAMETER target='base_model.features.12.conv.0.1.bias'\n",
              "            p_base_model_features_12_conv_1_0_weight: PARAMETER target='base_model.features.12.conv.1.0.weight'\n",
              "            p_base_model_features_12_conv_1_1_weight: PARAMETER target='base_model.features.12.conv.1.1.weight'\n",
              "            p_base_model_features_12_conv_1_1_bias: PARAMETER target='base_model.features.12.conv.1.1.bias'\n",
              "            p_base_model_features_12_conv_2_weight: PARAMETER target='base_model.features.12.conv.2.weight'\n",
              "            p_base_model_features_12_conv_3_weight: PARAMETER target='base_model.features.12.conv.3.weight'\n",
              "            p_base_model_features_12_conv_3_bias: PARAMETER target='base_model.features.12.conv.3.bias'\n",
              "            p_base_model_features_13_conv_0_0_weight: PARAMETER target='base_model.features.13.conv.0.0.weight'\n",
              "            p_base_model_features_13_conv_0_1_weight: PARAMETER target='base_model.features.13.conv.0.1.weight'\n",
              "            p_base_model_features_13_conv_0_1_bias: PARAMETER target='base_model.features.13.conv.0.1.bias'\n",
              "            p_base_model_features_13_conv_1_0_weight: PARAMETER target='base_model.features.13.conv.1.0.weight'\n",
              "            p_base_model_features_13_conv_1_1_weight: PARAMETER target='base_model.features.13.conv.1.1.weight'\n",
              "            p_base_model_features_13_conv_1_1_bias: PARAMETER target='base_model.features.13.conv.1.1.bias'\n",
              "            p_base_model_features_13_conv_2_weight: PARAMETER target='base_model.features.13.conv.2.weight'\n",
              "            p_base_model_features_13_conv_3_weight: PARAMETER target='base_model.features.13.conv.3.weight'\n",
              "            p_base_model_features_13_conv_3_bias: PARAMETER target='base_model.features.13.conv.3.bias'\n",
              "            p_base_model_features_14_conv_0_0_weight: PARAMETER target='base_model.features.14.conv.0.0.weight'\n",
              "            p_base_model_features_14_conv_0_1_weight: PARAMETER target='base_model.features.14.conv.0.1.weight'\n",
              "            p_base_model_features_14_conv_0_1_bias: PARAMETER target='base_model.features.14.conv.0.1.bias'\n",
              "            p_base_model_features_14_conv_1_0_weight: PARAMETER target='base_model.features.14.conv.1.0.weight'\n",
              "            p_base_model_features_14_conv_1_1_weight: PARAMETER target='base_model.features.14.conv.1.1.weight'\n",
              "            p_base_model_features_14_conv_1_1_bias: PARAMETER target='base_model.features.14.conv.1.1.bias'\n",
              "            p_base_model_features_14_conv_2_weight: PARAMETER target='base_model.features.14.conv.2.weight'\n",
              "            p_base_model_features_14_conv_3_weight: PARAMETER target='base_model.features.14.conv.3.weight'\n",
              "            p_base_model_features_14_conv_3_bias: PARAMETER target='base_model.features.14.conv.3.bias'\n",
              "            p_base_model_features_15_conv_0_0_weight: PARAMETER target='base_model.features.15.conv.0.0.weight'\n",
              "            p_base_model_features_15_conv_0_1_weight: PARAMETER target='base_model.features.15.conv.0.1.weight'\n",
              "            p_base_model_features_15_conv_0_1_bias: PARAMETER target='base_model.features.15.conv.0.1.bias'\n",
              "            p_base_model_features_15_conv_1_0_weight: PARAMETER target='base_model.features.15.conv.1.0.weight'\n",
              "            p_base_model_features_15_conv_1_1_weight: PARAMETER target='base_model.features.15.conv.1.1.weight'\n",
              "            p_base_model_features_15_conv_1_1_bias: PARAMETER target='base_model.features.15.conv.1.1.bias'\n",
              "            p_base_model_features_15_conv_2_weight: PARAMETER target='base_model.features.15.conv.2.weight'\n",
              "            p_base_model_features_15_conv_3_weight: PARAMETER target='base_model.features.15.conv.3.weight'\n",
              "            p_base_model_features_15_conv_3_bias: PARAMETER target='base_model.features.15.conv.3.bias'\n",
              "            p_base_model_features_16_conv_0_0_weight: PARAMETER target='base_model.features.16.conv.0.0.weight'\n",
              "            p_base_model_features_16_conv_0_1_weight: PARAMETER target='base_model.features.16.conv.0.1.weight'\n",
              "            p_base_model_features_16_conv_0_1_bias: PARAMETER target='base_model.features.16.conv.0.1.bias'\n",
              "            p_base_model_features_16_conv_1_0_weight: PARAMETER target='base_model.features.16.conv.1.0.weight'\n",
              "            p_base_model_features_16_conv_1_1_weight: PARAMETER target='base_model.features.16.conv.1.1.weight'\n",
              "            p_base_model_features_16_conv_1_1_bias: PARAMETER target='base_model.features.16.conv.1.1.bias'\n",
              "            p_base_model_features_16_conv_2_weight: PARAMETER target='base_model.features.16.conv.2.weight'\n",
              "            p_base_model_features_16_conv_3_weight: PARAMETER target='base_model.features.16.conv.3.weight'\n",
              "            p_base_model_features_16_conv_3_bias: PARAMETER target='base_model.features.16.conv.3.bias'\n",
              "            p_base_model_features_17_conv_0_0_weight: PARAMETER target='base_model.features.17.conv.0.0.weight'\n",
              "            p_base_model_features_17_conv_0_1_weight: PARAMETER target='base_model.features.17.conv.0.1.weight'\n",
              "            p_base_model_features_17_conv_0_1_bias: PARAMETER target='base_model.features.17.conv.0.1.bias'\n",
              "            p_base_model_features_17_conv_1_0_weight: PARAMETER target='base_model.features.17.conv.1.0.weight'\n",
              "            p_base_model_features_17_conv_1_1_weight: PARAMETER target='base_model.features.17.conv.1.1.weight'\n",
              "            p_base_model_features_17_conv_1_1_bias: PARAMETER target='base_model.features.17.conv.1.1.bias'\n",
              "            p_base_model_features_17_conv_2_weight: PARAMETER target='base_model.features.17.conv.2.weight'\n",
              "            p_base_model_features_17_conv_3_weight: PARAMETER target='base_model.features.17.conv.3.weight'\n",
              "            p_base_model_features_17_conv_3_bias: PARAMETER target='base_model.features.17.conv.3.bias'\n",
              "            p_base_model_features_18_0_weight: PARAMETER target='base_model.features.18.0.weight'\n",
              "            p_base_model_features_18_1_weight: PARAMETER target='base_model.features.18.1.weight'\n",
              "            p_base_model_features_18_1_bias: PARAMETER target='base_model.features.18.1.bias'\n",
              "            p_output_layer_weight: PARAMETER target='output_layer.weight'\n",
              "            p_output_layer_bias: PARAMETER target='output_layer.bias'\n",
              "            b_base_model_features_0_1_running_mean: BUFFER target='base_model.features.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_0_1_running_var: BUFFER target='base_model.features.0.1.running_var' persistent=True\n",
              "            b_base_model_features_0_1_num_batches_tracked: BUFFER target='base_model.features.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_1_conv_0_1_running_mean: BUFFER target='base_model.features.1.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_1_conv_0_1_running_var: BUFFER target='base_model.features.1.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_1_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.1.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_1_conv_2_running_mean: BUFFER target='base_model.features.1.conv.2.running_mean' persistent=True\n",
              "            b_base_model_features_1_conv_2_running_var: BUFFER target='base_model.features.1.conv.2.running_var' persistent=True\n",
              "            b_base_model_features_1_conv_2_num_batches_tracked: BUFFER target='base_model.features.1.conv.2.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_2_conv_0_1_running_mean: BUFFER target='base_model.features.2.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_2_conv_0_1_running_var: BUFFER target='base_model.features.2.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_2_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.2.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_2_conv_1_1_running_mean: BUFFER target='base_model.features.2.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_2_conv_1_1_running_var: BUFFER target='base_model.features.2.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_2_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.2.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_2_conv_3_running_mean: BUFFER target='base_model.features.2.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_2_conv_3_running_var: BUFFER target='base_model.features.2.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_2_conv_3_num_batches_tracked: BUFFER target='base_model.features.2.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_3_conv_0_1_running_mean: BUFFER target='base_model.features.3.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_3_conv_0_1_running_var: BUFFER target='base_model.features.3.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_3_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.3.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_3_conv_1_1_running_mean: BUFFER target='base_model.features.3.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_3_conv_1_1_running_var: BUFFER target='base_model.features.3.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_3_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.3.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_3_conv_3_running_mean: BUFFER target='base_model.features.3.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_3_conv_3_running_var: BUFFER target='base_model.features.3.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_3_conv_3_num_batches_tracked: BUFFER target='base_model.features.3.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_4_conv_0_1_running_mean: BUFFER target='base_model.features.4.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_4_conv_0_1_running_var: BUFFER target='base_model.features.4.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_4_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.4.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_4_conv_1_1_running_mean: BUFFER target='base_model.features.4.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_4_conv_1_1_running_var: BUFFER target='base_model.features.4.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_4_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.4.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_4_conv_3_running_mean: BUFFER target='base_model.features.4.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_4_conv_3_running_var: BUFFER target='base_model.features.4.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_4_conv_3_num_batches_tracked: BUFFER target='base_model.features.4.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_5_conv_0_1_running_mean: BUFFER target='base_model.features.5.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_5_conv_0_1_running_var: BUFFER target='base_model.features.5.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_5_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.5.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_5_conv_1_1_running_mean: BUFFER target='base_model.features.5.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_5_conv_1_1_running_var: BUFFER target='base_model.features.5.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_5_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.5.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_5_conv_3_running_mean: BUFFER target='base_model.features.5.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_5_conv_3_running_var: BUFFER target='base_model.features.5.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_5_conv_3_num_batches_tracked: BUFFER target='base_model.features.5.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_6_conv_0_1_running_mean: BUFFER target='base_model.features.6.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_6_conv_0_1_running_var: BUFFER target='base_model.features.6.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_6_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.6.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_6_conv_1_1_running_mean: BUFFER target='base_model.features.6.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_6_conv_1_1_running_var: BUFFER target='base_model.features.6.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_6_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.6.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_6_conv_3_running_mean: BUFFER target='base_model.features.6.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_6_conv_3_running_var: BUFFER target='base_model.features.6.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_6_conv_3_num_batches_tracked: BUFFER target='base_model.features.6.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_7_conv_0_1_running_mean: BUFFER target='base_model.features.7.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_7_conv_0_1_running_var: BUFFER target='base_model.features.7.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_7_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.7.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_7_conv_1_1_running_mean: BUFFER target='base_model.features.7.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_7_conv_1_1_running_var: BUFFER target='base_model.features.7.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_7_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.7.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_7_conv_3_running_mean: BUFFER target='base_model.features.7.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_7_conv_3_running_var: BUFFER target='base_model.features.7.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_7_conv_3_num_batches_tracked: BUFFER target='base_model.features.7.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_8_conv_0_1_running_mean: BUFFER target='base_model.features.8.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_8_conv_0_1_running_var: BUFFER target='base_model.features.8.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_8_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.8.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_8_conv_1_1_running_mean: BUFFER target='base_model.features.8.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_8_conv_1_1_running_var: BUFFER target='base_model.features.8.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_8_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.8.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_8_conv_3_running_mean: BUFFER target='base_model.features.8.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_8_conv_3_running_var: BUFFER target='base_model.features.8.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_8_conv_3_num_batches_tracked: BUFFER target='base_model.features.8.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_9_conv_0_1_running_mean: BUFFER target='base_model.features.9.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_9_conv_0_1_running_var: BUFFER target='base_model.features.9.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_9_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.9.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_9_conv_1_1_running_mean: BUFFER target='base_model.features.9.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_9_conv_1_1_running_var: BUFFER target='base_model.features.9.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_9_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.9.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_9_conv_3_running_mean: BUFFER target='base_model.features.9.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_9_conv_3_running_var: BUFFER target='base_model.features.9.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_9_conv_3_num_batches_tracked: BUFFER target='base_model.features.9.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_10_conv_0_1_running_mean: BUFFER target='base_model.features.10.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_10_conv_0_1_running_var: BUFFER target='base_model.features.10.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_10_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.10.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_10_conv_1_1_running_mean: BUFFER target='base_model.features.10.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_10_conv_1_1_running_var: BUFFER target='base_model.features.10.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_10_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.10.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_10_conv_3_running_mean: BUFFER target='base_model.features.10.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_10_conv_3_running_var: BUFFER target='base_model.features.10.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_10_conv_3_num_batches_tracked: BUFFER target='base_model.features.10.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_11_conv_0_1_running_mean: BUFFER target='base_model.features.11.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_11_conv_0_1_running_var: BUFFER target='base_model.features.11.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_11_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.11.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_11_conv_1_1_running_mean: BUFFER target='base_model.features.11.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_11_conv_1_1_running_var: BUFFER target='base_model.features.11.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_11_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.11.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_11_conv_3_running_mean: BUFFER target='base_model.features.11.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_11_conv_3_running_var: BUFFER target='base_model.features.11.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_11_conv_3_num_batches_tracked: BUFFER target='base_model.features.11.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_12_conv_0_1_running_mean: BUFFER target='base_model.features.12.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_12_conv_0_1_running_var: BUFFER target='base_model.features.12.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_12_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.12.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_12_conv_1_1_running_mean: BUFFER target='base_model.features.12.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_12_conv_1_1_running_var: BUFFER target='base_model.features.12.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_12_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.12.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_12_conv_3_running_mean: BUFFER target='base_model.features.12.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_12_conv_3_running_var: BUFFER target='base_model.features.12.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_12_conv_3_num_batches_tracked: BUFFER target='base_model.features.12.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_13_conv_0_1_running_mean: BUFFER target='base_model.features.13.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_13_conv_0_1_running_var: BUFFER target='base_model.features.13.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_13_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.13.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_13_conv_1_1_running_mean: BUFFER target='base_model.features.13.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_13_conv_1_1_running_var: BUFFER target='base_model.features.13.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_13_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.13.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_13_conv_3_running_mean: BUFFER target='base_model.features.13.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_13_conv_3_running_var: BUFFER target='base_model.features.13.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_13_conv_3_num_batches_tracked: BUFFER target='base_model.features.13.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_14_conv_0_1_running_mean: BUFFER target='base_model.features.14.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_14_conv_0_1_running_var: BUFFER target='base_model.features.14.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_14_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.14.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_14_conv_1_1_running_mean: BUFFER target='base_model.features.14.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_14_conv_1_1_running_var: BUFFER target='base_model.features.14.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_14_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.14.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_14_conv_3_running_mean: BUFFER target='base_model.features.14.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_14_conv_3_running_var: BUFFER target='base_model.features.14.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_14_conv_3_num_batches_tracked: BUFFER target='base_model.features.14.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_15_conv_0_1_running_mean: BUFFER target='base_model.features.15.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_15_conv_0_1_running_var: BUFFER target='base_model.features.15.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_15_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.15.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_15_conv_1_1_running_mean: BUFFER target='base_model.features.15.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_15_conv_1_1_running_var: BUFFER target='base_model.features.15.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_15_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.15.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_15_conv_3_running_mean: BUFFER target='base_model.features.15.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_15_conv_3_running_var: BUFFER target='base_model.features.15.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_15_conv_3_num_batches_tracked: BUFFER target='base_model.features.15.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_16_conv_0_1_running_mean: BUFFER target='base_model.features.16.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_16_conv_0_1_running_var: BUFFER target='base_model.features.16.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_16_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.16.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_16_conv_1_1_running_mean: BUFFER target='base_model.features.16.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_16_conv_1_1_running_var: BUFFER target='base_model.features.16.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_16_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.16.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_16_conv_3_running_mean: BUFFER target='base_model.features.16.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_16_conv_3_running_var: BUFFER target='base_model.features.16.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_16_conv_3_num_batches_tracked: BUFFER target='base_model.features.16.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_17_conv_0_1_running_mean: BUFFER target='base_model.features.17.conv.0.1.running_mean' persistent=True\n",
              "            b_base_model_features_17_conv_0_1_running_var: BUFFER target='base_model.features.17.conv.0.1.running_var' persistent=True\n",
              "            b_base_model_features_17_conv_0_1_num_batches_tracked: BUFFER target='base_model.features.17.conv.0.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_17_conv_1_1_running_mean: BUFFER target='base_model.features.17.conv.1.1.running_mean' persistent=True\n",
              "            b_base_model_features_17_conv_1_1_running_var: BUFFER target='base_model.features.17.conv.1.1.running_var' persistent=True\n",
              "            b_base_model_features_17_conv_1_1_num_batches_tracked: BUFFER target='base_model.features.17.conv.1.1.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_17_conv_3_running_mean: BUFFER target='base_model.features.17.conv.3.running_mean' persistent=True\n",
              "            b_base_model_features_17_conv_3_running_var: BUFFER target='base_model.features.17.conv.3.running_var' persistent=True\n",
              "            b_base_model_features_17_conv_3_num_batches_tracked: BUFFER target='base_model.features.17.conv.3.num_batches_tracked' persistent=True\n",
              "            b_base_model_features_18_1_running_mean: BUFFER target='base_model.features.18.1.running_mean' persistent=True\n",
              "            b_base_model_features_18_1_running_var: BUFFER target='base_model.features.18.1.running_var' persistent=True\n",
              "            b_base_model_features_18_1_num_batches_tracked: BUFFER target='base_model.features.18.1.num_batches_tracked' persistent=True\n",
              "            x: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            linear: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {s77: VR[0, 65535]}\n",
              "\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    }
  ]
}